<!-- Search file for "CHANGE" for my own changes -->
<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>dapper.xp_launch API documentation</title>
<meta name="description" content="Tools (notably `xpList`) for setup and running of experiments (known as `xp`s) …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<link rel="preconnect" href="https://www.google.com">
<script async src="https://cse.google.com/cse.js?cx=017837193012385208679:pey8ky8gdqw"></script>
<style>
.gsc-control-cse {padding:0 !important;margin-top:1em}
body.gsc-overflow-hidden #sidebar {overflow: visible;}
</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo.png">
<!-- Dont work coz pdoc already defines these:
<title>DAPPER doc</title>
<meta name="description" content="Data Assimilation with Python: a Package for Experimental Research" />
-->
<a href="https://github.com/nansencenter/DAPPER" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dapper.xp_launch</code></h1>
</header>
<section id="section-intro">
<p>Tools (notably <code><a title="dapper.xp_launch.xpList" href="#dapper.xp_launch.xpList">xpList</a></code>) for setup and running of experiments (known as <code>xp</code>s).</p>
<p>See <code><a title="dapper.da_methods.da_method" href="da_methods/index.html#dapper.da_methods.da_method">da_method()</a></code> for the strict definition of <code>xp</code>s.</p>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_launch.py#L1-L608" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34;Tools (notably `xpList`) for setup and running of experiments (known as `xp`s).

See `dapper.da_methods.da_method` for the strict definition of `xp`s.
&#34;&#34;&#34;

import copy
import dataclasses as dcs
import os
import re
import shutil
import sys
from datetime import datetime
from functools import wraps
from pathlib import Path
from textwrap import dedent

import dill
import numpy as np
import struct_tools
import tabulate as _tabulate
from tabulate import tabulate
from tqdm.auto import tqdm

import dapper.stats
import dapper.tools.progressbar as pb
from dapper.dpr_config import rc
from dapper.tools.remote.uplink import submit_job_GCP
from dapper.tools.seeding import set_seed

_tabulate.MIN_PADDING = 0
XP_TIMESTAMP_TEMPLATE = &#34;run_%Y-%m-%d__%H-%M-%S&#34;


def seed_and_simulate(HMM, xp):
    &#34;&#34;&#34;Default experiment setup (sets seed and simulates truth and obs).

    Used by `xpList.launch` via `run_experiment`.

    Parameters
    ----------
    HMM: HiddenMarkovModel
        Container defining the system.
    xp: object
        Type: a `dapper.da_methods.da_method`-decorated class.

        .. note:: `xp.seed` should be an integer. Otherwise:
            If there is no `xp.seed` then then the seed is not set.
            Although different `xp`s will then use different seeds
            (unless you do some funky hacking),
            reproducibility for your script as a whole would still be obtained
            by setting the seed at the outset (i.e. in the script).
            On the other hand, if `xp.seed in [None, &#34;clock&#34;]`
            then the seed is from the clock (for each xp),
            which would not provide exact reproducibility.

    Returns
    -------
    tuple (xx, yy)
        The simulated truth and observations.
    &#34;&#34;&#34;
    set_seed(getattr(xp, &#39;seed&#39;, False))
    xx, yy = HMM.simulate()
    return HMM, xx, yy


def run_experiment(xp, label, savedir, HMM, setup=seed_and_simulate, free=True,
                   statkeys=False, fail_gently=False, **stat_kwargs):
    &#34;&#34;&#34;Used by `xpList.launch` to run each single (DA) experiment (&#34;xp&#34;).

    This involves steps similar to `examples/basic_1.py`, i.e.:

    - `setup`                    : Initialize experiment.
    - `xp.assimilate`            : run DA, pass on exception if fail_gently
    - `xp.stats.average_in_time` : result averaging
    - `xp.avrgs.tabulate`        : result printing
    - `dill.dump`                : result storage

    Parameters
    ----------
    xp: object
        Type: a `dapper.da_methods.da_method`-decorated class.
    label: str
        Name attached to progressbar during assimilation.
    savedir: str
        Path of folder wherein to store the experiment data.
    HMM: HiddenMarkovModel
        Container defining the system.
    setup: function
        This function must take two arguments: `HMM` and `xp`,
        and return the `HMM` to be used by the DA methods
        (typically the same as the input `HMM`, but could be modified),
        and the (typically synthetic) truth and obs time series.

        This gives you the ability to customize almost any aspect of the
        individual experiments within a batch launch of experiments.
        Typically you will grab one or more parameter values
        stored in the `xp` (see `dapper.da_methods.da_method`) and act on them,
        or set them in some other object that impacts the experiment.
        Thus, by generating a new `xp` for each such parameter value you can
        investigate the impact/sensitivity of the results to this parameter.
        Examples include:

        - Setting the seed. See the default `setup`, namely `seed_and_simulate`,
          for how this is done.
        - Setting some aspect of the `HMM` such as the observation noise,
          or the interval between observations.
        - Setting some parameter of the model (not otherwise detailed in the `HMM`).
          For example, the `Force` parameter of `dapper.mods.Lorenz96`, as done in
          see `examples/basic_3`.
        - Using a different `HMM` entirely for the truth/obs (`xx`/`yy`) generation,
          than the one that will be used by the DA. Or loading the truth/obs
          time series from file. In both cases, you might also have to do some
          cropping or slicing of `xx` and `yy` before returning them.
    free: bool
        Whether (or not) to `del xp.stats` after the experiment is done,
        so as to free up memory and/or not save this data
        (just keeping `xp.avrgs`).
    statkeys: list
        A list of names (possibly in the form of abbreviations) of the
        statistical averages that should be printed immediately afther
        this xp.
    fail_gently: bool
        Whether (or not) to propagate exceptions.
    &#34;&#34;&#34;
    # We should copy HMM so as not to cause any nasty surprises such as
    # expecting param=1 when param=2 (coz it&#39;s not been reset).
    # NB: won&#39;t copy implicitly ref&#39;d obj&#39;s (like L96&#39;s core). =&gt; bug w/ MP?
    hmm = copy.deepcopy(HMM)

    # GENERATE TRUTH/OBS
    hmm, xx, yy = setup(hmm, xp)

    # ASSIMILATE
    xp.assimilate(hmm, xx, yy, label, fail_gently=fail_gently, **stat_kwargs)

    # Clear references to mpl (for pickling purposes)
    if hasattr(xp.stats, &#34;LP_instance&#34;):
        del xp.stats.LP_instance

    # AVERAGE
    xp.stats.average_in_time(free=free)

    # PRINT
    if statkeys:
        statkeys = () if statkeys is True else statkeys
        print(xp.avrgs.tabulate(statkeys))

    # SAVE
    if savedir:
        with open(Path(savedir)/&#34;xp&#34;, &#34;wb&#34;) as FILE:
            dill.dump({&#39;xp&#39;: xp}, FILE)


def collapse_str(string, length=6):
    &#34;&#34;&#34;Truncate a string (in the middle) to the given `length`&#34;&#34;&#34;
    if len(string) &lt;= length:
        return string
    else:
        return string[:length-2]+&#39;~&#39;+string[-1]


class xpList(list):
    &#34;&#34;&#34;Subclass of `list` specialized for experiment (&#34;xp&#34;) objects.

    Main use: administrate experiment launches.

    Modifications to `list`:

    - `xpList.append` supports `unique` to enable lazy `xp` declaration.
    - `__iadd__` (`+=`) supports adding single `xp`s.
      this is hackey, but convenience is king.
    - `__getitem__` supports lists, similar to `np.ndarray`
    - `__repr__`: prints the list as rows of a table,
      where the columns represent attributes whose value is not shared among all `xp`s.
      Refer to `xpList.squeeze` for more information.

    Add-ons:

    - `xpList.launch`: run the experiments in current list.
    - `xpList.squeeze`: find all attributes of the `xp`s in the list;
      classify as distinct, redundant, or common.
    - `xpList.gen_names`: use `xpList.squeeze` to generate
      a short &amp; unique name for each `xp` in the list.
    - `xpList.tabulate_avrgs`: tabulate time-averaged results.
    - `xpList.inds` to search by kw-attrs.

    Parameters
    ----------
    args: entries
        Nothing, or a list of `xp`s.

    unique: bool
        Duplicates won&#39;t get appended. Makes `append` (and `__iadd__`) relatively slow.
        Use `extend` or `__add__` or `combinator` to bypass this validation.

    Also see
    --------
    - Examples: `examples/basic_2`, `examples/basic_3`
    - `dapper.xp_process.xpSpace`, which is used for experient result **presentation**,
      as opposed to this class (`xpList`), which handles **launching** experiments.
    &#34;&#34;&#34;

    def __init__(self, *args, unique=False):
        self.unique = unique
        super().__init__(*args)

    def __iadd__(self, xp):
        if not hasattr(xp, &#39;__iter__&#39;):
            xp = [xp]
        for item in xp:
            self.append(item)
        return self

    def append(self, xp):
        &#34;&#34;&#34;Append **if** not `self.unique` &amp; present.&#34;&#34;&#34;
        if not (self.unique and xp in self):
            super().append(xp)

    def __getitem__(self, keys):
        &#34;&#34;&#34;Indexing, also by a list&#34;&#34;&#34;
        try:
            B = [self[k] for k in keys]    # if keys is list
        except TypeError:
            B = super().__getitem__(keys)  # if keys is int, slice
        if hasattr(B, &#39;__len__&#39;):
            B = xpList(B)                  # Cast
        return B

    def inds(self, strict=True, missingval=&#34;NONSENSE&#34;, **kws):
        &#34;&#34;&#34;Find (all) indices of `xps` whose attributes match kws.

        If strict, then `xp`s lacking a requested attr will not match,
        unless the missingval (e.g. `None`) matches the required value.
        &#34;&#34;&#34;
        def match(xp):
            def missing(v): return missingval if strict else v
            matches = [getattr(xp, k, missing(v)) == v for k, v in kws.items()]
            return all(matches)

        return [i for i, xp in enumerate(self) if match(xp)]

    @property
    def da_methods(self):
        &#34;&#34;&#34;List `da_method` attributes in this list.&#34;&#34;&#34;
        return [xp.da_method for xp in self]

    def squeeze(self, nomerge=()):
        &#34;&#34;&#34;Classify all attrs. of all `xp`s as `distinct`, `redundant`, or `common`.

        An attribute of the `xp`s is inserted in one of the 3 dicts as follows:
        The attribute names become dict keys. If the values of an attribute
        (collected from all of the `xp`s) are all __equal__, then the attribute
        is inserted in `common`, but only with **a single value**.
        If they are all the same **or missing**, then it is inserted in `redundant`
        **with a single value**. Otherwise, it is inserted in `distinct`,
        with **its full list of values** (filling with `None` where the attribute
        was missing in the corresponding `xp`).

        The function gets its name from the fact that the attrs in `distinct` are
        sufficient to (but not generally necessary, since there might exist a subset of
        attributes that) uniquely identify each `xp` in the list (the `redundant` and
        `common` can be &#34;squeezed&#34; out).  Thus, the `repr` (which is a table of the
        `xp`s and their attributes) does not need to print all of the attributes.
        This function also does the heavy lifting for `xpSpace.squeeze`.

        Parameters
        ----------
        nomerge: list
            Attributes that should always be seen as distinct.
        &#34;&#34;&#34;
        def _aggregate_keys():
            &#34;&#34;&#34;Aggregate keys from all `xp`&#34;&#34;&#34;
            if len(self) == 0:
                return []

            # Start with da_method
            aggregate = [&#39;da_method&#39;]

            # Aggregate all other keys
            for xp in self:

                # Get dataclass fields
                try:
                    dc_fields = dcs.fields(xp.__class__)
                    dc_names = [F.name for F in dc_fields]
                    keys = xp.__dict__.keys()
                except TypeError:
                    # Assume namedtuple
                    dc_names = []
                    keys = xp._fields

                # For all potential keys:
                for k in keys:
                    # If not already present:
                    if k not in aggregate:

                        # If dataclass, check repr:
                        if k in dc_names:
                            if dc_fields[dc_names.index(k)].repr:
                                aggregate.append(k)
                        # Else, just append
                        else:
                            aggregate.append(k)

            # Remove unwanted
            excluded  = [re.compile(&#39;^_&#39;), &#39;avrgs&#39;, &#39;stats&#39;, &#39;HMM&#39;, &#39;duration&#39;]
            aggregate = struct_tools.complement(aggregate, excluded)
            return aggregate

        def _getattr_safe(xp, key):
            # Don&#39;t use None, to avoid mixing with actual None&#39;s
            # TODO 4: use an object yet more likely to be unique.
            missing = &#34;N/A&#34;
            a = getattr(xp, key, missing)

            # Replace ndarray by its id, since o/w it will
            # complain that you must use all().
            # Alternative: replace all == (and !=) below by &#34;is&#34;.
            #     Tabulation with multi-line params actually works,
            #     (though it&#39;s still likely to take up too much space,
            #     unless we set np.printoptions...).
            #     However, then python (since 3.8) will complain about
            #     comparison to literal.
            if isinstance(a, np.ndarray):
                shorten = 6
                a = f&#34;arr(&lt;id {id(a)//10**shorten}&gt;)&#34;
            # TODO 3: leave formatting to sub() below?
            # TODO 4: do similar formatting for other non-trivial params?
            # TODO 4: document alternative way to specify non-trivial params:
            #         use key to be looked up in some globally accessible dct.
            #         Advantage: names are meaningful, rather than ids.
            return a

        def replace_NA_by_None(vals):
            &#34;&#34;&#34;Supports different types of `vals`.&#34;&#34;&#34;
            def sub(v):
                return None if v == &#34;N/A&#34; else v

            if isinstance(vals, str):
                vals = sub(vals)
            else:
                try:
                    vals = [sub(v) for v in vals]
                except TypeError:
                    vals = sub(vals)
            return vals

        # Main
        distinct, redundant, common = {}, {}, {}
        for key in _aggregate_keys():
            vals = [_getattr_safe(xp, key) for xp in self]

            if struct_tools.flexcomp(key, *nomerge):
                dct, vals = distinct, vals

            elif all(vals[0] == v for v in vals):
                dct, vals = common, vals[0]

            else:
                nonNA = next(v for v in vals if &#34;N/A&#34; != v)
                if all(v == &#34;N/A&#34; or v == nonNA for v in vals):
                    dct, vals = redundant, nonNA

                else:
                    dct, vals = distinct, vals

            dct[key] = replace_NA_by_None(vals)

        return distinct, redundant, common

    def __repr__(self):
        distinct, redundant, common = self.squeeze()
        s = &#39;&lt;xpList&gt; of length %d with attributes:\n&#39; % len(self)
        s += tabulate(distinct, headers=&#34;keys&#34;, showindex=True)
        s += &#34;\nOther attributes:\n&#34;
        s += str(struct_tools.AlignedDict({**redundant, **common}))
        return s

    def gen_names(self, abbrev=6, tab=False):
        &#34;&#34;&#34;Similiar to `self.__repr__()`, but:

        - returns *list* of names
        - tabulation is optional
        - attaches (abbreviated) labels to each attribute
        &#34;&#34;&#34;
        distinct, redundant, common = self.squeeze(nomerge=[&#34;da_method&#34;])
        labels = distinct.keys()
        values = distinct.values()

        # Label abbreviation
        labels = [collapse_str(k, abbrev) for k in labels]

        # Make label columns: insert None or lbl+&#34;:&#34;, depending on value
        def column(lbl, vals):
            return [None if v is None else lbl+&#34;:&#34; for v in vals]
        labels = [column(lbl, vals) for lbl, vals in zip(labels, values)]

        # Interlace labels and values
        table = [x for (a, b) in zip(labels, values) for x in (a, b)]

        # Rm da_method label (but keep value)
        table.pop(0)

        # Transpose
        table = list(map(list, zip(*table)))

        # Tabulate
        table = tabulate(table, tablefmt=&#34;plain&#34;)

        # Rm space between lbls/vals
        table = re.sub(&#39;:  +&#39;, &#39;:&#39;, table)

        # Rm alignment
        if not tab:
            table = re.sub(r&#39; +&#39;, r&#39; &#39;, table)

        return table.splitlines()

    @wraps(dapper.stats.tabulate_avrgs)
    def tabulate_avrgs(self, *args, **kwargs):
        distinct, redundant, common = self.squeeze()
        averages = dapper.stats.tabulate_avrgs([C.avrgs for C in self], *args, **kwargs)
        columns = {**distinct, &#39;|&#39;: [&#39;|&#39;]*len(self), **averages}  # merge
        return tabulate(columns, headers=&#34;keys&#34;, showindex=True).replace(&#39;␣&#39;, &#39; &#39;)

    def launch(self, HMM, save_as=&#34;noname&#34;, mp=False, fail_gently=None, **kwargs):
        &#34;&#34;&#34;Essentially: `for xp in self: run_experiment(xp, ..., **kwargs)`.

        See `run_experiment` for documentation on the `kwargs` and `fail_gently`.

        The results are saved in `rc.dirs.data / save_as`,
        unless `save_as` is `False`/`None`.
        Note: multiprocessing (locally or in the cloud) requires saving/loading data.

        Depending on `mp`, `run_experiment` is delegated as follows:

        - `False`: caller process (no parallelisation)
        - `True` or `&#34;MP&#34;` or an `int`: multiprocessing on this host
        - `&#34;GCP&#34;` or `&#34;Google&#34;` or `dict(server=&#34;GCP&#34;)`: the DAPPER server
          (Google Cloud Computing with HTCondor).
            - Specify a list of files as `mp[&#34;files&#34;]` to include them
              in working directory of the server workers.
            - In order to use absolute paths, the list should cosist
              of tuples, where the first item is relative to the second
              (which is an absolute path). The root is then not included
              in the working directory of the server.
            - If this dict field is empty, then all python files
              in `sys.path[0]` are uploaded.

        See `examples/basic_2.py` and `examples/basic_3.py` for example use.
        &#34;&#34;&#34;
        # Parse mp option
        if not mp:
            mp = dict()
        elif mp in [True, &#34;MP&#34;]:
            mp = dict(server=&#34;local&#34;)
        elif isinstance(mp, int):
            mp = dict(server=&#34;local&#34;, NPROC=mp)
        elif mp in [&#34;GCP&#34;, &#34;Google&#34;]:
            mp = dict(server=&#34;GCP&#34;, files=[], code=&#34;&#34;)

        # Parse fail_gently
        if fail_gently is None:
            if mp and mp[&#34;server&#34;] == &#34;GCP&#34;:
                fail_gently = False
                # coz cloud processing is entirely de-coupled anyways
            else:
                fail_gently = True
                # True unless otherwise requested
        kwargs[&#34;fail_gently&#34;] = fail_gently

        # Bundle HMM with kwargs
        kwargs[&#39;HMM&#39;] = HMM

        # Parse save_as
        if save_as in [None, False]:
            assert not mp, &#34;Multiprocessing requires saving data.&#34;
            # Parallelization w/o storing is possible, especially w/ threads.
            # But it involves more complicated communication set-up.
            def xpi_dir(*args): return None
        else:
            save_as = rc.dirs.data / Path(save_as).stem
            save_as /= datetime.now().strftime(XP_TIMESTAMP_TEMPLATE)
            os.makedirs(save_as)
            print(f&#34;Experiment stored at {save_as}&#34;)

            def xpi_dir(i):
                path = save_as / str(i)
                os.mkdir(path)
                return path

        # No parallelization
        if not mp:
            for ixp, (xp, label) in enumerate(zip(self, self.gen_names())):
                run_experiment(xp, label, xpi_dir(ixp), **kwargs)

        # Local multiprocessing
        elif mp[&#34;server&#34;].lower() == &#34;local&#34;:
            def run_with_fixed_args(arg):
                xp, ixp = arg
                run_experiment(xp, None, xpi_dir(ixp), **kwargs)
            args = zip(self, range(len(self)))

            pb.disable_progbar          = True
            pb.disable_user_interaction = True
            NPROC = mp.get(&#34;NPROC&#34;, None)  # None =&gt; mp.cpu_count()
            from dapper.tools.multiproc import mpd  # will fail on GCP
            with mpd.Pool(NPROC) as pool:
                list(tqdm(
                    pool.imap(
                        run_with_fixed_args, args),
                    total=len(self),
                    desc=&#34;Parallel experim&#39;s&#34;,
                    smoothing=0.1))
            pb.disable_progbar          = False
            pb.disable_user_interaction = False

        # Google cloud platform, multiprocessing
        elif mp[&#34;server&#34;] == &#34;GCP&#34;:
            for ixp, xp in enumerate(self):
                with open(xpi_dir(ixp)/&#34;xp.var&#34;, &#34;wb&#34;) as f:
                    dill.dump(dict(xp=xp), f)

            with open(save_as/&#34;xp.com&#34;, &#34;wb&#34;) as f:
                dill.dump(kwargs, f)

            # mkdir extra_files
            extra_files = save_as / &#34;extra_files&#34;
            os.mkdir(extra_files)
            # Default files: .py files in sys.path[0] (main script&#39;s path)
            if not mp.get(&#34;files&#34;, []):
                ff = os.listdir(sys.path[0])
                mp[&#34;files&#34;] = [f for f in ff if f.endswith(&#34;.py&#34;)]
            # Copy files into extra_files
            for f in mp[&#34;files&#34;]:
                if isinstance(f, (str, Path)):
                    # Example: f = &#34;A.py&#34;
                    path = Path(sys.path[0]) / f
                    dst = f
                else:  # instance of tuple(path, root)
                    # Example: f = (&#34;~/E/G/A.py&#34;, &#34;G&#34;)
                    path, root = f
                    dst = Path(path).relative_to(root)
                dst = extra_files / dst
                os.makedirs(dst.parent, exist_ok=True)
                try:
                    shutil.copytree(path, dst)  # dir -r
                except OSError:
                    shutil.copy2(path, dst)  # file

            # Loads PWD/xp_{var,com} and calls run_experiment()
            with open(extra_files/&#34;load_and_run.py&#34;, &#34;w&#34;) as f:
                f.write(dedent(&#34;&#34;&#34;\
                import dill
                from dapper.xp_launch import run_experiment

                # Load
                with open(&#34;xp.com&#34;, &#34;rb&#34;) as f: com = dill.load(f)
                with open(&#34;xp.var&#34;, &#34;rb&#34;) as f: var = dill.load(f)

                # User-defined code
                %s

                # Run
                result = run_experiment(var[&#39;xp&#39;], None, &#34;.&#34;, **com)
                &#34;&#34;&#34;) % dedent(mp[&#34;code&#34;]))

            with open(extra_files/&#34;dpr_config.yaml&#34;, &#34;w&#34;) as f:
                f.write(&#34;\n&#34;.join([
                    &#34;data_root: &#39;$cwd&#39;&#34;,
                    &#34;liveplotting: no&#34;,
                    &#34;welcome_message: no&#34;]))
            submit_job_GCP(save_as)

        return save_as


def combinator(param_dict, **glob_dict):
    &#34;&#34;&#34;Mass creation of `xp`&#39;s by combining the value lists in the `param_dict`.

    Returns a function (`for_params`) that creates all possible combinations
    of parameters (from their value list) for a given `dapper.da_methods.da_method`.
    This is a good deal more efficient than relying on `xpList`&#39;s `unique`. Parameters

    - not found among the args of the given DA method are ignored by `for_params`.
    - specified as keywords to the `for_params` fix the value
      preventing using the corresponding (if any) value list in the `param_dict`.

    .. caution::
        Beware! If, eg., `infl` or `rot` are in `param_dict`, aimed at the `EnKF`,
        but you forget that they are also attributes some method where you don&#39;t
        actually want to use them (eg. `SVGDF`),
        then you&#39;ll create many more than you intend.
    &#34;&#34;&#34;
    def for_params(method, **fixed_params):
        dc_fields = [f.name for f in dcs.fields(method)]
        params = struct_tools.intersect(param_dict, dc_fields)
        params = struct_tools.complement(params, fixed_params)
        params = {**glob_dict, **params}  # glob_dict 1st

        def xp1(dct):
            xp = method(**struct_tools.intersect(dct, dc_fields), **fixed_params)
            for key, v in struct_tools.intersect(dct, glob_dict).items():
                setattr(xp, key, v)
            return xp

        return [xp1(dct) for dct in struct_tools.prodct(params)]
    return for_params</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dapper.xp_launch.seed_and_simulate"><code class="name flex">
<span>def <span class="ident">seed_and_simulate</span></span>(<span>HMM, xp)</span>
</code></dt>
<dd>
<div class="desc"><p>Default experiment setup (sets seed and simulates truth and obs).</p>
<p>Used by <code><a title="dapper.xp_launch.xpList.launch" href="#dapper.xp_launch.xpList.launch">xpList.launch()</a></code> via <code><a title="dapper.xp_launch.run_experiment" href="#dapper.xp_launch.run_experiment">run_experiment()</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>HMM</code></strong> :&ensp;<code>HiddenMarkovModel</code></dt>
<dd>Container defining the system.</dd>
<dt><strong><code>xp</code></strong> :&ensp;<code>object</code></dt>
<dd>
<p>Type: a <code><a title="dapper.da_methods.da_method" href="da_methods/index.html#dapper.da_methods.da_method">da_method()</a></code>-decorated class.</p>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;<code>xp.seed</code> should be an integer. Otherwise:</p>
<p>If there is no <code>xp.seed</code> then then the seed is not set.
Although different <code>xp</code>s will then use different seeds
(unless you do some funky hacking),
reproducibility for your script as a whole would still be obtained
by setting the seed at the outset (i.e. in the script).
On the other hand, if <code>xp.seed in [None, "clock"]</code>
then the seed is from the clock (for each xp),
which would not provide exact reproducibility.</p>
</div>
</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple (xx, yy)</code></dt>
<dd>The simulated truth and observations.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_launch.py#L34-L63" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def seed_and_simulate(HMM, xp):
    &#34;&#34;&#34;Default experiment setup (sets seed and simulates truth and obs).

    Used by `xpList.launch` via `run_experiment`.

    Parameters
    ----------
    HMM: HiddenMarkovModel
        Container defining the system.
    xp: object
        Type: a `dapper.da_methods.da_method`-decorated class.

        .. note:: `xp.seed` should be an integer. Otherwise:
            If there is no `xp.seed` then then the seed is not set.
            Although different `xp`s will then use different seeds
            (unless you do some funky hacking),
            reproducibility for your script as a whole would still be obtained
            by setting the seed at the outset (i.e. in the script).
            On the other hand, if `xp.seed in [None, &#34;clock&#34;]`
            then the seed is from the clock (for each xp),
            which would not provide exact reproducibility.

    Returns
    -------
    tuple (xx, yy)
        The simulated truth and observations.
    &#34;&#34;&#34;
    set_seed(getattr(xp, &#39;seed&#39;, False))
    xx, yy = HMM.simulate()
    return HMM, xx, yy</code></pre>
</details>
</dd>
<dt id="dapper.xp_launch.run_experiment"><code class="name flex">
<span>def <span class="ident">run_experiment</span></span>(<span>xp, label, savedir, HMM, setup=&lt;function seed_and_simulate&gt;, free=True, statkeys=False, fail_gently=False, **stat_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Used by <code><a title="dapper.xp_launch.xpList.launch" href="#dapper.xp_launch.xpList.launch">xpList.launch()</a></code> to run each single (DA) experiment ("xp").</p>
<p>This involves steps similar to <code>examples/basic_1.py</code>, i.e.:</p>
<ul>
<li><code>setup</code>
: Initialize experiment.</li>
<li><code>xp.assimilate</code>
: run DA, pass on exception if fail_gently</li>
<li><code>xp.stats.average_in_time</code> : result averaging</li>
<li><code>xp.avrgs.tabulate</code>
: result printing</li>
<li><code>dill.dump</code>
: result storage</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>xp</code></strong> :&ensp;<code>object</code></dt>
<dd>Type: a <code><a title="dapper.da_methods.da_method" href="da_methods/index.html#dapper.da_methods.da_method">da_method()</a></code>-decorated class.</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code></dt>
<dd>Name attached to progressbar during assimilation.</dd>
<dt><strong><code>savedir</code></strong> :&ensp;<code>str</code></dt>
<dd>Path of folder wherein to store the experiment data.</dd>
<dt><strong><code>HMM</code></strong> :&ensp;<code>HiddenMarkovModel</code></dt>
<dd>Container defining the system.</dd>
<dt><strong><code>setup</code></strong> :&ensp;<code>function</code></dt>
<dd>
<p>This function must take two arguments: <code>HMM</code> and <code>xp</code>,
and return the <code>HMM</code> to be used by the DA methods
(typically the same as the input <code>HMM</code>, but could be modified),
and the (typically synthetic) truth and obs time series.</p>
<p>This gives you the ability to customize almost any aspect of the
individual experiments within a batch launch of experiments.
Typically you will grab one or more parameter values
stored in the <code>xp</code> (see <code><a title="dapper.da_methods.da_method" href="da_methods/index.html#dapper.da_methods.da_method">da_method()</a></code>) and act on them,
or set them in some other object that impacts the experiment.
Thus, by generating a new <code>xp</code> for each such parameter value you can
investigate the impact/sensitivity of the results to this parameter.
Examples include:</p>
<ul>
<li>Setting the seed. See the default <code>setup</code>, namely <code><a title="dapper.xp_launch.seed_and_simulate" href="#dapper.xp_launch.seed_and_simulate">seed_and_simulate()</a></code>,
for how this is done.</li>
<li>Setting some aspect of the <code>HMM</code> such as the observation noise,
or the interval between observations.</li>
<li>Setting some parameter of the model (not otherwise detailed in the <code>HMM</code>).
For example, the <code>Force</code> parameter of <code><a title="dapper.mods.Lorenz96" href="mods/Lorenz96/index.html">dapper.mods.Lorenz96</a></code>, as done in
see <code>examples/basic_3</code>.</li>
<li>Using a different <code>HMM</code> entirely for the truth/obs (<code>xx</code>/<code>yy</code>) generation,
than the one that will be used by the DA. Or loading the truth/obs
time series from file. In both cases, you might also have to do some
cropping or slicing of <code>xx</code> and <code>yy</code> before returning them.</li>
</ul>
</dd>
<dt><strong><code>free</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether (or not) to <code>del xp.stats</code> after the experiment is done,
so as to free up memory and/or not save this data
(just keeping <code>xp.avrgs</code>).</dd>
<dt><strong><code>statkeys</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of names (possibly in the form of abbreviations) of the
statistical averages that should be printed immediately afther
this xp.</dd>
<dt><strong><code>fail_gently</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether (or not) to propagate exceptions.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_launch.py#L66-L151" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def run_experiment(xp, label, savedir, HMM, setup=seed_and_simulate, free=True,
                   statkeys=False, fail_gently=False, **stat_kwargs):
    &#34;&#34;&#34;Used by `xpList.launch` to run each single (DA) experiment (&#34;xp&#34;).

    This involves steps similar to `examples/basic_1.py`, i.e.:

    - `setup`                    : Initialize experiment.
    - `xp.assimilate`            : run DA, pass on exception if fail_gently
    - `xp.stats.average_in_time` : result averaging
    - `xp.avrgs.tabulate`        : result printing
    - `dill.dump`                : result storage

    Parameters
    ----------
    xp: object
        Type: a `dapper.da_methods.da_method`-decorated class.
    label: str
        Name attached to progressbar during assimilation.
    savedir: str
        Path of folder wherein to store the experiment data.
    HMM: HiddenMarkovModel
        Container defining the system.
    setup: function
        This function must take two arguments: `HMM` and `xp`,
        and return the `HMM` to be used by the DA methods
        (typically the same as the input `HMM`, but could be modified),
        and the (typically synthetic) truth and obs time series.

        This gives you the ability to customize almost any aspect of the
        individual experiments within a batch launch of experiments.
        Typically you will grab one or more parameter values
        stored in the `xp` (see `dapper.da_methods.da_method`) and act on them,
        or set them in some other object that impacts the experiment.
        Thus, by generating a new `xp` for each such parameter value you can
        investigate the impact/sensitivity of the results to this parameter.
        Examples include:

        - Setting the seed. See the default `setup`, namely `seed_and_simulate`,
          for how this is done.
        - Setting some aspect of the `HMM` such as the observation noise,
          or the interval between observations.
        - Setting some parameter of the model (not otherwise detailed in the `HMM`).
          For example, the `Force` parameter of `dapper.mods.Lorenz96`, as done in
          see `examples/basic_3`.
        - Using a different `HMM` entirely for the truth/obs (`xx`/`yy`) generation,
          than the one that will be used by the DA. Or loading the truth/obs
          time series from file. In both cases, you might also have to do some
          cropping or slicing of `xx` and `yy` before returning them.
    free: bool
        Whether (or not) to `del xp.stats` after the experiment is done,
        so as to free up memory and/or not save this data
        (just keeping `xp.avrgs`).
    statkeys: list
        A list of names (possibly in the form of abbreviations) of the
        statistical averages that should be printed immediately afther
        this xp.
    fail_gently: bool
        Whether (or not) to propagate exceptions.
    &#34;&#34;&#34;
    # We should copy HMM so as not to cause any nasty surprises such as
    # expecting param=1 when param=2 (coz it&#39;s not been reset).
    # NB: won&#39;t copy implicitly ref&#39;d obj&#39;s (like L96&#39;s core). =&gt; bug w/ MP?
    hmm = copy.deepcopy(HMM)

    # GENERATE TRUTH/OBS
    hmm, xx, yy = setup(hmm, xp)

    # ASSIMILATE
    xp.assimilate(hmm, xx, yy, label, fail_gently=fail_gently, **stat_kwargs)

    # Clear references to mpl (for pickling purposes)
    if hasattr(xp.stats, &#34;LP_instance&#34;):
        del xp.stats.LP_instance

    # AVERAGE
    xp.stats.average_in_time(free=free)

    # PRINT
    if statkeys:
        statkeys = () if statkeys is True else statkeys
        print(xp.avrgs.tabulate(statkeys))

    # SAVE
    if savedir:
        with open(Path(savedir)/&#34;xp&#34;, &#34;wb&#34;) as FILE:
            dill.dump({&#39;xp&#39;: xp}, FILE)</code></pre>
</details>
</dd>
<dt id="dapper.xp_launch.collapse_str"><code class="name flex">
<span>def <span class="ident">collapse_str</span></span>(<span>string, length=6)</span>
</code></dt>
<dd>
<div class="desc"><p>Truncate a string (in the middle) to the given <code>length</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_launch.py#L154-L159" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def collapse_str(string, length=6):
    &#34;&#34;&#34;Truncate a string (in the middle) to the given `length`&#34;&#34;&#34;
    if len(string) &lt;= length:
        return string
    else:
        return string[:length-2]+&#39;~&#39;+string[-1]</code></pre>
</details>
</dd>
<dt id="dapper.xp_launch.combinator"><code class="name flex">
<span>def <span class="ident">combinator</span></span>(<span>param_dict, **glob_dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Mass creation of <code>xp</code>'s by combining the value lists in the <code>param_dict</code>.</p>
<p>Returns a function (<code>for_params</code>) that creates all possible combinations
of parameters (from their value list) for a given <code><a title="dapper.da_methods.da_method" href="da_methods/index.html#dapper.da_methods.da_method">da_method()</a></code>.
This is a good deal more efficient than relying on <code><a title="dapper.xp_launch.xpList" href="#dapper.xp_launch.xpList">xpList</a></code>'s <code>unique</code>. Parameters</p>
<ul>
<li>not found among the args of the given DA method are ignored by <code>for_params</code>.</li>
<li>specified as keywords to the <code>for_params</code> fix the value
preventing using the corresponding (if any) value list in the <code>param_dict</code>.</li>
</ul>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Beware! If, eg., <code>infl</code> or <code>rot</code> are in <code>param_dict</code>, aimed at the <code>EnKF</code>,
but you forget that they are also attributes some method where you don't
actually want to use them (eg. <code>SVGDF</code>),
then you'll create many more than you intend.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_launch.py#L578-L608" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def combinator(param_dict, **glob_dict):
    &#34;&#34;&#34;Mass creation of `xp`&#39;s by combining the value lists in the `param_dict`.

    Returns a function (`for_params`) that creates all possible combinations
    of parameters (from their value list) for a given `dapper.da_methods.da_method`.
    This is a good deal more efficient than relying on `xpList`&#39;s `unique`. Parameters

    - not found among the args of the given DA method are ignored by `for_params`.
    - specified as keywords to the `for_params` fix the value
      preventing using the corresponding (if any) value list in the `param_dict`.

    .. caution::
        Beware! If, eg., `infl` or `rot` are in `param_dict`, aimed at the `EnKF`,
        but you forget that they are also attributes some method where you don&#39;t
        actually want to use them (eg. `SVGDF`),
        then you&#39;ll create many more than you intend.
    &#34;&#34;&#34;
    def for_params(method, **fixed_params):
        dc_fields = [f.name for f in dcs.fields(method)]
        params = struct_tools.intersect(param_dict, dc_fields)
        params = struct_tools.complement(params, fixed_params)
        params = {**glob_dict, **params}  # glob_dict 1st

        def xp1(dct):
            xp = method(**struct_tools.intersect(dct, dc_fields), **fixed_params)
            for key, v in struct_tools.intersect(dct, glob_dict).items():
                setattr(xp, key, v)
            return xp

        return [xp1(dct) for dct in struct_tools.prodct(params)]
    return for_params</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dapper.xp_launch.xpList"><code class="flex name class">
<span>class <span class="ident">xpList</span></span>
<span>(</span><span>*args, unique=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Subclass of <code>list</code> specialized for experiment ("xp") objects.</p>
<p>Main use: administrate experiment launches.</p>
<p>Modifications to <code>list</code>:</p>
<ul>
<li><code><a title="dapper.xp_launch.xpList.append" href="#dapper.xp_launch.xpList.append">xpList.append()</a></code> supports <code>unique</code> to enable lazy <code>xp</code> declaration.</li>
<li><code>__iadd__</code> (<code>+=</code>) supports adding single <code>xp</code>s.
this is hackey, but convenience is king.</li>
<li><code>__getitem__</code> supports lists, similar to <code>np.ndarray</code></li>
<li><code>__repr__</code>: prints the list as rows of a table,
where the columns represent attributes whose value is not shared among all <code>xp</code>s.
Refer to <code><a title="dapper.xp_launch.xpList.squeeze" href="#dapper.xp_launch.xpList.squeeze">xpList.squeeze()</a></code> for more information.</li>
</ul>
<p>Add-ons:</p>
<ul>
<li><code><a title="dapper.xp_launch.xpList.launch" href="#dapper.xp_launch.xpList.launch">xpList.launch()</a></code>: run the experiments in current list.</li>
<li><code><a title="dapper.xp_launch.xpList.squeeze" href="#dapper.xp_launch.xpList.squeeze">xpList.squeeze()</a></code>: find all attributes of the <code>xp</code>s in the list;
classify as distinct, redundant, or common.</li>
<li><code><a title="dapper.xp_launch.xpList.gen_names" href="#dapper.xp_launch.xpList.gen_names">xpList.gen_names()</a></code>: use <code><a title="dapper.xp_launch.xpList.squeeze" href="#dapper.xp_launch.xpList.squeeze">xpList.squeeze()</a></code> to generate
a short &amp; unique name for each <code>xp</code> in the list.</li>
<li><code><a title="dapper.xp_launch.xpList.tabulate_avrgs" href="#dapper.xp_launch.xpList.tabulate_avrgs">tabulate_avrgs()</a></code>: tabulate time-averaged results.</li>
<li><code><a title="dapper.xp_launch.xpList.inds" href="#dapper.xp_launch.xpList.inds">xpList.inds()</a></code> to search by kw-attrs.</li>
</ul>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>args</code></strong> :&ensp;<code>entries</code></dt>
<dd>Nothing, or a list of <code>xp</code>s.</dd>
<dt><strong><code>unique</code></strong> :&ensp;<code>bool</code></dt>
<dd>Duplicates won't get appended. Makes <code>append</code> (and <code>__iadd__</code>) relatively slow.
Use <code>extend</code> or <code>__add__</code> or <code><a title="dapper.xp_launch.combinator" href="#dapper.xp_launch.combinator">combinator()</a></code> to bypass this validation.</dd>
</dl>
<h2 id="also-see">Also See</h2>
<ul>
<li>Examples: <code>examples/basic_2</code>, <code>examples/basic_3</code></li>
<li><code><a title="dapper.xp_process.xpSpace" href="xp_process.html#dapper.xp_process.xpSpace">xpSpace</a></code>, which is used for experient result <strong>presentation</strong>,
as opposed to this class (<code><a title="dapper.xp_launch.xpList" href="#dapper.xp_launch.xpList">xpList</a></code>), which handles <strong>launching</strong> experiments.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_launch.py#L162-L575" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class xpList(list):
    &#34;&#34;&#34;Subclass of `list` specialized for experiment (&#34;xp&#34;) objects.

    Main use: administrate experiment launches.

    Modifications to `list`:

    - `xpList.append` supports `unique` to enable lazy `xp` declaration.
    - `__iadd__` (`+=`) supports adding single `xp`s.
      this is hackey, but convenience is king.
    - `__getitem__` supports lists, similar to `np.ndarray`
    - `__repr__`: prints the list as rows of a table,
      where the columns represent attributes whose value is not shared among all `xp`s.
      Refer to `xpList.squeeze` for more information.

    Add-ons:

    - `xpList.launch`: run the experiments in current list.
    - `xpList.squeeze`: find all attributes of the `xp`s in the list;
      classify as distinct, redundant, or common.
    - `xpList.gen_names`: use `xpList.squeeze` to generate
      a short &amp; unique name for each `xp` in the list.
    - `xpList.tabulate_avrgs`: tabulate time-averaged results.
    - `xpList.inds` to search by kw-attrs.

    Parameters
    ----------
    args: entries
        Nothing, or a list of `xp`s.

    unique: bool
        Duplicates won&#39;t get appended. Makes `append` (and `__iadd__`) relatively slow.
        Use `extend` or `__add__` or `combinator` to bypass this validation.

    Also see
    --------
    - Examples: `examples/basic_2`, `examples/basic_3`
    - `dapper.xp_process.xpSpace`, which is used for experient result **presentation**,
      as opposed to this class (`xpList`), which handles **launching** experiments.
    &#34;&#34;&#34;

    def __init__(self, *args, unique=False):
        self.unique = unique
        super().__init__(*args)

    def __iadd__(self, xp):
        if not hasattr(xp, &#39;__iter__&#39;):
            xp = [xp]
        for item in xp:
            self.append(item)
        return self

    def append(self, xp):
        &#34;&#34;&#34;Append **if** not `self.unique` &amp; present.&#34;&#34;&#34;
        if not (self.unique and xp in self):
            super().append(xp)

    def __getitem__(self, keys):
        &#34;&#34;&#34;Indexing, also by a list&#34;&#34;&#34;
        try:
            B = [self[k] for k in keys]    # if keys is list
        except TypeError:
            B = super().__getitem__(keys)  # if keys is int, slice
        if hasattr(B, &#39;__len__&#39;):
            B = xpList(B)                  # Cast
        return B

    def inds(self, strict=True, missingval=&#34;NONSENSE&#34;, **kws):
        &#34;&#34;&#34;Find (all) indices of `xps` whose attributes match kws.

        If strict, then `xp`s lacking a requested attr will not match,
        unless the missingval (e.g. `None`) matches the required value.
        &#34;&#34;&#34;
        def match(xp):
            def missing(v): return missingval if strict else v
            matches = [getattr(xp, k, missing(v)) == v for k, v in kws.items()]
            return all(matches)

        return [i for i, xp in enumerate(self) if match(xp)]

    @property
    def da_methods(self):
        &#34;&#34;&#34;List `da_method` attributes in this list.&#34;&#34;&#34;
        return [xp.da_method for xp in self]

    def squeeze(self, nomerge=()):
        &#34;&#34;&#34;Classify all attrs. of all `xp`s as `distinct`, `redundant`, or `common`.

        An attribute of the `xp`s is inserted in one of the 3 dicts as follows:
        The attribute names become dict keys. If the values of an attribute
        (collected from all of the `xp`s) are all __equal__, then the attribute
        is inserted in `common`, but only with **a single value**.
        If they are all the same **or missing**, then it is inserted in `redundant`
        **with a single value**. Otherwise, it is inserted in `distinct`,
        with **its full list of values** (filling with `None` where the attribute
        was missing in the corresponding `xp`).

        The function gets its name from the fact that the attrs in `distinct` are
        sufficient to (but not generally necessary, since there might exist a subset of
        attributes that) uniquely identify each `xp` in the list (the `redundant` and
        `common` can be &#34;squeezed&#34; out).  Thus, the `repr` (which is a table of the
        `xp`s and their attributes) does not need to print all of the attributes.
        This function also does the heavy lifting for `xpSpace.squeeze`.

        Parameters
        ----------
        nomerge: list
            Attributes that should always be seen as distinct.
        &#34;&#34;&#34;
        def _aggregate_keys():
            &#34;&#34;&#34;Aggregate keys from all `xp`&#34;&#34;&#34;
            if len(self) == 0:
                return []

            # Start with da_method
            aggregate = [&#39;da_method&#39;]

            # Aggregate all other keys
            for xp in self:

                # Get dataclass fields
                try:
                    dc_fields = dcs.fields(xp.__class__)
                    dc_names = [F.name for F in dc_fields]
                    keys = xp.__dict__.keys()
                except TypeError:
                    # Assume namedtuple
                    dc_names = []
                    keys = xp._fields

                # For all potential keys:
                for k in keys:
                    # If not already present:
                    if k not in aggregate:

                        # If dataclass, check repr:
                        if k in dc_names:
                            if dc_fields[dc_names.index(k)].repr:
                                aggregate.append(k)
                        # Else, just append
                        else:
                            aggregate.append(k)

            # Remove unwanted
            excluded  = [re.compile(&#39;^_&#39;), &#39;avrgs&#39;, &#39;stats&#39;, &#39;HMM&#39;, &#39;duration&#39;]
            aggregate = struct_tools.complement(aggregate, excluded)
            return aggregate

        def _getattr_safe(xp, key):
            # Don&#39;t use None, to avoid mixing with actual None&#39;s
            # TODO 4: use an object yet more likely to be unique.
            missing = &#34;N/A&#34;
            a = getattr(xp, key, missing)

            # Replace ndarray by its id, since o/w it will
            # complain that you must use all().
            # Alternative: replace all == (and !=) below by &#34;is&#34;.
            #     Tabulation with multi-line params actually works,
            #     (though it&#39;s still likely to take up too much space,
            #     unless we set np.printoptions...).
            #     However, then python (since 3.8) will complain about
            #     comparison to literal.
            if isinstance(a, np.ndarray):
                shorten = 6
                a = f&#34;arr(&lt;id {id(a)//10**shorten}&gt;)&#34;
            # TODO 3: leave formatting to sub() below?
            # TODO 4: do similar formatting for other non-trivial params?
            # TODO 4: document alternative way to specify non-trivial params:
            #         use key to be looked up in some globally accessible dct.
            #         Advantage: names are meaningful, rather than ids.
            return a

        def replace_NA_by_None(vals):
            &#34;&#34;&#34;Supports different types of `vals`.&#34;&#34;&#34;
            def sub(v):
                return None if v == &#34;N/A&#34; else v

            if isinstance(vals, str):
                vals = sub(vals)
            else:
                try:
                    vals = [sub(v) for v in vals]
                except TypeError:
                    vals = sub(vals)
            return vals

        # Main
        distinct, redundant, common = {}, {}, {}
        for key in _aggregate_keys():
            vals = [_getattr_safe(xp, key) for xp in self]

            if struct_tools.flexcomp(key, *nomerge):
                dct, vals = distinct, vals

            elif all(vals[0] == v for v in vals):
                dct, vals = common, vals[0]

            else:
                nonNA = next(v for v in vals if &#34;N/A&#34; != v)
                if all(v == &#34;N/A&#34; or v == nonNA for v in vals):
                    dct, vals = redundant, nonNA

                else:
                    dct, vals = distinct, vals

            dct[key] = replace_NA_by_None(vals)

        return distinct, redundant, common

    def __repr__(self):
        distinct, redundant, common = self.squeeze()
        s = &#39;&lt;xpList&gt; of length %d with attributes:\n&#39; % len(self)
        s += tabulate(distinct, headers=&#34;keys&#34;, showindex=True)
        s += &#34;\nOther attributes:\n&#34;
        s += str(struct_tools.AlignedDict({**redundant, **common}))
        return s

    def gen_names(self, abbrev=6, tab=False):
        &#34;&#34;&#34;Similiar to `self.__repr__()`, but:

        - returns *list* of names
        - tabulation is optional
        - attaches (abbreviated) labels to each attribute
        &#34;&#34;&#34;
        distinct, redundant, common = self.squeeze(nomerge=[&#34;da_method&#34;])
        labels = distinct.keys()
        values = distinct.values()

        # Label abbreviation
        labels = [collapse_str(k, abbrev) for k in labels]

        # Make label columns: insert None or lbl+&#34;:&#34;, depending on value
        def column(lbl, vals):
            return [None if v is None else lbl+&#34;:&#34; for v in vals]
        labels = [column(lbl, vals) for lbl, vals in zip(labels, values)]

        # Interlace labels and values
        table = [x for (a, b) in zip(labels, values) for x in (a, b)]

        # Rm da_method label (but keep value)
        table.pop(0)

        # Transpose
        table = list(map(list, zip(*table)))

        # Tabulate
        table = tabulate(table, tablefmt=&#34;plain&#34;)

        # Rm space between lbls/vals
        table = re.sub(&#39;:  +&#39;, &#39;:&#39;, table)

        # Rm alignment
        if not tab:
            table = re.sub(r&#39; +&#39;, r&#39; &#39;, table)

        return table.splitlines()

    @wraps(dapper.stats.tabulate_avrgs)
    def tabulate_avrgs(self, *args, **kwargs):
        distinct, redundant, common = self.squeeze()
        averages = dapper.stats.tabulate_avrgs([C.avrgs for C in self], *args, **kwargs)
        columns = {**distinct, &#39;|&#39;: [&#39;|&#39;]*len(self), **averages}  # merge
        return tabulate(columns, headers=&#34;keys&#34;, showindex=True).replace(&#39;␣&#39;, &#39; &#39;)

    def launch(self, HMM, save_as=&#34;noname&#34;, mp=False, fail_gently=None, **kwargs):
        &#34;&#34;&#34;Essentially: `for xp in self: run_experiment(xp, ..., **kwargs)`.

        See `run_experiment` for documentation on the `kwargs` and `fail_gently`.

        The results are saved in `rc.dirs.data / save_as`,
        unless `save_as` is `False`/`None`.
        Note: multiprocessing (locally or in the cloud) requires saving/loading data.

        Depending on `mp`, `run_experiment` is delegated as follows:

        - `False`: caller process (no parallelisation)
        - `True` or `&#34;MP&#34;` or an `int`: multiprocessing on this host
        - `&#34;GCP&#34;` or `&#34;Google&#34;` or `dict(server=&#34;GCP&#34;)`: the DAPPER server
          (Google Cloud Computing with HTCondor).
            - Specify a list of files as `mp[&#34;files&#34;]` to include them
              in working directory of the server workers.
            - In order to use absolute paths, the list should cosist
              of tuples, where the first item is relative to the second
              (which is an absolute path). The root is then not included
              in the working directory of the server.
            - If this dict field is empty, then all python files
              in `sys.path[0]` are uploaded.

        See `examples/basic_2.py` and `examples/basic_3.py` for example use.
        &#34;&#34;&#34;
        # Parse mp option
        if not mp:
            mp = dict()
        elif mp in [True, &#34;MP&#34;]:
            mp = dict(server=&#34;local&#34;)
        elif isinstance(mp, int):
            mp = dict(server=&#34;local&#34;, NPROC=mp)
        elif mp in [&#34;GCP&#34;, &#34;Google&#34;]:
            mp = dict(server=&#34;GCP&#34;, files=[], code=&#34;&#34;)

        # Parse fail_gently
        if fail_gently is None:
            if mp and mp[&#34;server&#34;] == &#34;GCP&#34;:
                fail_gently = False
                # coz cloud processing is entirely de-coupled anyways
            else:
                fail_gently = True
                # True unless otherwise requested
        kwargs[&#34;fail_gently&#34;] = fail_gently

        # Bundle HMM with kwargs
        kwargs[&#39;HMM&#39;] = HMM

        # Parse save_as
        if save_as in [None, False]:
            assert not mp, &#34;Multiprocessing requires saving data.&#34;
            # Parallelization w/o storing is possible, especially w/ threads.
            # But it involves more complicated communication set-up.
            def xpi_dir(*args): return None
        else:
            save_as = rc.dirs.data / Path(save_as).stem
            save_as /= datetime.now().strftime(XP_TIMESTAMP_TEMPLATE)
            os.makedirs(save_as)
            print(f&#34;Experiment stored at {save_as}&#34;)

            def xpi_dir(i):
                path = save_as / str(i)
                os.mkdir(path)
                return path

        # No parallelization
        if not mp:
            for ixp, (xp, label) in enumerate(zip(self, self.gen_names())):
                run_experiment(xp, label, xpi_dir(ixp), **kwargs)

        # Local multiprocessing
        elif mp[&#34;server&#34;].lower() == &#34;local&#34;:
            def run_with_fixed_args(arg):
                xp, ixp = arg
                run_experiment(xp, None, xpi_dir(ixp), **kwargs)
            args = zip(self, range(len(self)))

            pb.disable_progbar          = True
            pb.disable_user_interaction = True
            NPROC = mp.get(&#34;NPROC&#34;, None)  # None =&gt; mp.cpu_count()
            from dapper.tools.multiproc import mpd  # will fail on GCP
            with mpd.Pool(NPROC) as pool:
                list(tqdm(
                    pool.imap(
                        run_with_fixed_args, args),
                    total=len(self),
                    desc=&#34;Parallel experim&#39;s&#34;,
                    smoothing=0.1))
            pb.disable_progbar          = False
            pb.disable_user_interaction = False

        # Google cloud platform, multiprocessing
        elif mp[&#34;server&#34;] == &#34;GCP&#34;:
            for ixp, xp in enumerate(self):
                with open(xpi_dir(ixp)/&#34;xp.var&#34;, &#34;wb&#34;) as f:
                    dill.dump(dict(xp=xp), f)

            with open(save_as/&#34;xp.com&#34;, &#34;wb&#34;) as f:
                dill.dump(kwargs, f)

            # mkdir extra_files
            extra_files = save_as / &#34;extra_files&#34;
            os.mkdir(extra_files)
            # Default files: .py files in sys.path[0] (main script&#39;s path)
            if not mp.get(&#34;files&#34;, []):
                ff = os.listdir(sys.path[0])
                mp[&#34;files&#34;] = [f for f in ff if f.endswith(&#34;.py&#34;)]
            # Copy files into extra_files
            for f in mp[&#34;files&#34;]:
                if isinstance(f, (str, Path)):
                    # Example: f = &#34;A.py&#34;
                    path = Path(sys.path[0]) / f
                    dst = f
                else:  # instance of tuple(path, root)
                    # Example: f = (&#34;~/E/G/A.py&#34;, &#34;G&#34;)
                    path, root = f
                    dst = Path(path).relative_to(root)
                dst = extra_files / dst
                os.makedirs(dst.parent, exist_ok=True)
                try:
                    shutil.copytree(path, dst)  # dir -r
                except OSError:
                    shutil.copy2(path, dst)  # file

            # Loads PWD/xp_{var,com} and calls run_experiment()
            with open(extra_files/&#34;load_and_run.py&#34;, &#34;w&#34;) as f:
                f.write(dedent(&#34;&#34;&#34;\
                import dill
                from dapper.xp_launch import run_experiment

                # Load
                with open(&#34;xp.com&#34;, &#34;rb&#34;) as f: com = dill.load(f)
                with open(&#34;xp.var&#34;, &#34;rb&#34;) as f: var = dill.load(f)

                # User-defined code
                %s

                # Run
                result = run_experiment(var[&#39;xp&#39;], None, &#34;.&#34;, **com)
                &#34;&#34;&#34;) % dedent(mp[&#34;code&#34;]))

            with open(extra_files/&#34;dpr_config.yaml&#34;, &#34;w&#34;) as f:
                f.write(&#34;\n&#34;.join([
                    &#34;data_root: &#39;$cwd&#39;&#34;,
                    &#34;liveplotting: no&#34;,
                    &#34;welcome_message: no&#34;]))
            submit_job_GCP(save_as)

        return save_as</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.list</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="dapper.xp_launch.xpList.da_methods"><code class="name">var <span class="ident">da_methods</span></code></dt>
<dd>
<div class="desc"><p>List <code>da_method</code> attributes in this list.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_launch.py#L242-L245" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@property
def da_methods(self):
    &#34;&#34;&#34;List `da_method` attributes in this list.&#34;&#34;&#34;
    return [xp.da_method for xp in self]</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.xp_launch.xpList.append"><code class="name flex">
<span>def <span class="ident">append</span></span>(<span>self, xp)</span>
</code></dt>
<dd>
<div class="desc"><p>Append <strong>if</strong> not <code>self.unique</code> &amp; present.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_launch.py#L214-L217" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def append(self, xp):
    &#34;&#34;&#34;Append **if** not `self.unique` &amp; present.&#34;&#34;&#34;
    if not (self.unique and xp in self):
        super().append(xp)</code></pre>
</details>
</dd>
<dt id="dapper.xp_launch.xpList.inds"><code class="name flex">
<span>def <span class="ident">inds</span></span>(<span>self, strict=True, missingval='NONSENSE', **kws)</span>
</code></dt>
<dd>
<div class="desc"><p>Find (all) indices of <code>xps</code> whose attributes match kws.</p>
<p>If strict, then <code>xp</code>s lacking a requested attr will not match,
unless the missingval (e.g. <code>None</code>) matches the required value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_launch.py#L229-L240" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def inds(self, strict=True, missingval=&#34;NONSENSE&#34;, **kws):
    &#34;&#34;&#34;Find (all) indices of `xps` whose attributes match kws.

    If strict, then `xp`s lacking a requested attr will not match,
    unless the missingval (e.g. `None`) matches the required value.
    &#34;&#34;&#34;
    def match(xp):
        def missing(v): return missingval if strict else v
        matches = [getattr(xp, k, missing(v)) == v for k, v in kws.items()]
        return all(matches)

    return [i for i, xp in enumerate(self) if match(xp)]</code></pre>
</details>
</dd>
<dt id="dapper.xp_launch.xpList.squeeze"><code class="name flex">
<span>def <span class="ident">squeeze</span></span>(<span>self, nomerge=())</span>
</code></dt>
<dd>
<div class="desc"><p>Classify all attrs. of all <code>xp</code>s as <code>distinct</code>, <code>redundant</code>, or <code>common</code>.</p>
<p>An attribute of the <code>xp</code>s is inserted in one of the 3 dicts as follows:
The attribute names become dict keys. If the values of an attribute
(collected from all of the <code>xp</code>s) are all <strong>equal</strong>, then the attribute
is inserted in <code>common</code>, but only with <strong>a single value</strong>.
If they are all the same <strong>or missing</strong>, then it is inserted in <code>redundant</code>
<strong>with a single value</strong>. Otherwise, it is inserted in <code>distinct</code>,
with <strong>its full list of values</strong> (filling with <code>None</code> where the attribute
was missing in the corresponding <code>xp</code>).</p>
<p>The function gets its name from the fact that the attrs in <code>distinct</code> are
sufficient to (but not generally necessary, since there might exist a subset of
attributes that) uniquely identify each <code>xp</code> in the list (the <code>redundant</code> and
<code>common</code> can be "squeezed" out).
Thus, the <code>repr</code> (which is a table of the
<code>xp</code>s and their attributes) does not need to print all of the attributes.
This function also does the heavy lifting for <code>xpSpace.squeeze</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>nomerge</code></strong> :&ensp;<code>list</code></dt>
<dd>Attributes that should always be seen as distinct.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_launch.py#L247-L369" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def squeeze(self, nomerge=()):
    &#34;&#34;&#34;Classify all attrs. of all `xp`s as `distinct`, `redundant`, or `common`.

    An attribute of the `xp`s is inserted in one of the 3 dicts as follows:
    The attribute names become dict keys. If the values of an attribute
    (collected from all of the `xp`s) are all __equal__, then the attribute
    is inserted in `common`, but only with **a single value**.
    If they are all the same **or missing**, then it is inserted in `redundant`
    **with a single value**. Otherwise, it is inserted in `distinct`,
    with **its full list of values** (filling with `None` where the attribute
    was missing in the corresponding `xp`).

    The function gets its name from the fact that the attrs in `distinct` are
    sufficient to (but not generally necessary, since there might exist a subset of
    attributes that) uniquely identify each `xp` in the list (the `redundant` and
    `common` can be &#34;squeezed&#34; out).  Thus, the `repr` (which is a table of the
    `xp`s and their attributes) does not need to print all of the attributes.
    This function also does the heavy lifting for `xpSpace.squeeze`.

    Parameters
    ----------
    nomerge: list
        Attributes that should always be seen as distinct.
    &#34;&#34;&#34;
    def _aggregate_keys():
        &#34;&#34;&#34;Aggregate keys from all `xp`&#34;&#34;&#34;
        if len(self) == 0:
            return []

        # Start with da_method
        aggregate = [&#39;da_method&#39;]

        # Aggregate all other keys
        for xp in self:

            # Get dataclass fields
            try:
                dc_fields = dcs.fields(xp.__class__)
                dc_names = [F.name for F in dc_fields]
                keys = xp.__dict__.keys()
            except TypeError:
                # Assume namedtuple
                dc_names = []
                keys = xp._fields

            # For all potential keys:
            for k in keys:
                # If not already present:
                if k not in aggregate:

                    # If dataclass, check repr:
                    if k in dc_names:
                        if dc_fields[dc_names.index(k)].repr:
                            aggregate.append(k)
                    # Else, just append
                    else:
                        aggregate.append(k)

        # Remove unwanted
        excluded  = [re.compile(&#39;^_&#39;), &#39;avrgs&#39;, &#39;stats&#39;, &#39;HMM&#39;, &#39;duration&#39;]
        aggregate = struct_tools.complement(aggregate, excluded)
        return aggregate

    def _getattr_safe(xp, key):
        # Don&#39;t use None, to avoid mixing with actual None&#39;s
        # TODO 4: use an object yet more likely to be unique.
        missing = &#34;N/A&#34;
        a = getattr(xp, key, missing)

        # Replace ndarray by its id, since o/w it will
        # complain that you must use all().
        # Alternative: replace all == (and !=) below by &#34;is&#34;.
        #     Tabulation with multi-line params actually works,
        #     (though it&#39;s still likely to take up too much space,
        #     unless we set np.printoptions...).
        #     However, then python (since 3.8) will complain about
        #     comparison to literal.
        if isinstance(a, np.ndarray):
            shorten = 6
            a = f&#34;arr(&lt;id {id(a)//10**shorten}&gt;)&#34;
        # TODO 3: leave formatting to sub() below?
        # TODO 4: do similar formatting for other non-trivial params?
        # TODO 4: document alternative way to specify non-trivial params:
        #         use key to be looked up in some globally accessible dct.
        #         Advantage: names are meaningful, rather than ids.
        return a

    def replace_NA_by_None(vals):
        &#34;&#34;&#34;Supports different types of `vals`.&#34;&#34;&#34;
        def sub(v):
            return None if v == &#34;N/A&#34; else v

        if isinstance(vals, str):
            vals = sub(vals)
        else:
            try:
                vals = [sub(v) for v in vals]
            except TypeError:
                vals = sub(vals)
        return vals

    # Main
    distinct, redundant, common = {}, {}, {}
    for key in _aggregate_keys():
        vals = [_getattr_safe(xp, key) for xp in self]

        if struct_tools.flexcomp(key, *nomerge):
            dct, vals = distinct, vals

        elif all(vals[0] == v for v in vals):
            dct, vals = common, vals[0]

        else:
            nonNA = next(v for v in vals if &#34;N/A&#34; != v)
            if all(v == &#34;N/A&#34; or v == nonNA for v in vals):
                dct, vals = redundant, nonNA

            else:
                dct, vals = distinct, vals

        dct[key] = replace_NA_by_None(vals)

    return distinct, redundant, common</code></pre>
</details>
</dd>
<dt id="dapper.xp_launch.xpList.gen_names"><code class="name flex">
<span>def <span class="ident">gen_names</span></span>(<span>self, abbrev=6, tab=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Similiar to <code>self.__repr__()</code>, but:</p>
<ul>
<li>returns <em>list</em> of names</li>
<li>tabulation is optional</li>
<li>attaches (abbreviated) labels to each attribute</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_launch.py#L379-L417" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def gen_names(self, abbrev=6, tab=False):
    &#34;&#34;&#34;Similiar to `self.__repr__()`, but:

    - returns *list* of names
    - tabulation is optional
    - attaches (abbreviated) labels to each attribute
    &#34;&#34;&#34;
    distinct, redundant, common = self.squeeze(nomerge=[&#34;da_method&#34;])
    labels = distinct.keys()
    values = distinct.values()

    # Label abbreviation
    labels = [collapse_str(k, abbrev) for k in labels]

    # Make label columns: insert None or lbl+&#34;:&#34;, depending on value
    def column(lbl, vals):
        return [None if v is None else lbl+&#34;:&#34; for v in vals]
    labels = [column(lbl, vals) for lbl, vals in zip(labels, values)]

    # Interlace labels and values
    table = [x for (a, b) in zip(labels, values) for x in (a, b)]

    # Rm da_method label (but keep value)
    table.pop(0)

    # Transpose
    table = list(map(list, zip(*table)))

    # Tabulate
    table = tabulate(table, tablefmt=&#34;plain&#34;)

    # Rm space between lbls/vals
    table = re.sub(&#39;:  +&#39;, &#39;:&#39;, table)

    # Rm alignment
    if not tab:
        table = re.sub(r&#39; +&#39;, r&#39; &#39;, table)

    return table.splitlines()</code></pre>
</details>
</dd>
<dt id="dapper.xp_launch.xpList.tabulate_avrgs"><code class="name flex">
<span>def <span class="ident">tabulate_avrgs</span></span>(<span>avrgs_list, statkeys=(), decimals=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Tabulate avrgs (val±prec).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/stats.py#L658-L676" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def tabulate_avrgs(avrgs_list, statkeys=(), decimals=None):
    &#34;&#34;&#34;Tabulate avrgs (val±prec).&#34;&#34;&#34;
    if not statkeys:
        statkeys = [&#39;rmse.a&#39;, &#39;rmv.a&#39;, &#39;rmse.f&#39;]

    columns = {}
    for stat in statkeys:
        column = [getattr(a, stat, None) for a in avrgs_list]
        column = unpack_uqs(column, decimals)
        if not column:
            raise ValueError(f&#34;The stat. key &#39;{stat}&#39; was not&#34;
                             &#34; found among any of the averages.&#34;)
        vals  = align_col([stat] + column[&#34;val&#34;])
        precs = align_col([&#39;1σ&#39;] + column[&#34;prec&#34;], just=&#34;&lt;&#34;)
        headr = vals[0]+&#39;  &#39;+precs[0]
        mattr = [f&#34;{v} ±{c}&#34; for v, c in zip(vals, precs)][1:]
        columns[headr] = mattr

    return columns</code></pre>
</details>
</dd>
<dt id="dapper.xp_launch.xpList.launch"><code class="name flex">
<span>def <span class="ident">launch</span></span>(<span>self, HMM, save_as='noname', mp=False, fail_gently=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Essentially: <code>for xp in self: run_experiment(xp, ..., **kwargs)</code>.</p>
<p>See <code><a title="dapper.xp_launch.run_experiment" href="#dapper.xp_launch.run_experiment">run_experiment()</a></code> for documentation on the <code>kwargs</code> and <code>fail_gently</code>.</p>
<p>The results are saved in <code>rc.dirs.data / save_as</code>,
unless <code>save_as</code> is <code>False</code>/<code>None</code>.
Note: multiprocessing (locally or in the cloud) requires saving/loading data.</p>
<p>Depending on <code>mp</code>, <code><a title="dapper.xp_launch.run_experiment" href="#dapper.xp_launch.run_experiment">run_experiment()</a></code> is delegated as follows:</p>
<ul>
<li><code>False</code>: caller process (no parallelisation)</li>
<li><code>True</code> or <code>"MP"</code> or an <code>int</code>: multiprocessing on this host</li>
<li><code>"GCP"</code> or <code>"Google"</code> or <code>dict(server="GCP")</code>: the DAPPER server
(Google Cloud Computing with HTCondor).<ul>
<li>Specify a list of files as <code>mp["files"]</code> to include them
in working directory of the server workers.</li>
<li>In order to use absolute paths, the list should cosist
of tuples, where the first item is relative to the second
(which is an absolute path). The root is then not included
in the working directory of the server.</li>
<li>If this dict field is empty, then all python files
in <code>sys.path[0]</code> are uploaded.</li>
</ul>
</li>
</ul>
<p>See <code>examples/basic_2.py</code> and <code>examples/basic_3.py</code> for example use.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_launch.py#L426-L575" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def launch(self, HMM, save_as=&#34;noname&#34;, mp=False, fail_gently=None, **kwargs):
    &#34;&#34;&#34;Essentially: `for xp in self: run_experiment(xp, ..., **kwargs)`.

    See `run_experiment` for documentation on the `kwargs` and `fail_gently`.

    The results are saved in `rc.dirs.data / save_as`,
    unless `save_as` is `False`/`None`.
    Note: multiprocessing (locally or in the cloud) requires saving/loading data.

    Depending on `mp`, `run_experiment` is delegated as follows:

    - `False`: caller process (no parallelisation)
    - `True` or `&#34;MP&#34;` or an `int`: multiprocessing on this host
    - `&#34;GCP&#34;` or `&#34;Google&#34;` or `dict(server=&#34;GCP&#34;)`: the DAPPER server
      (Google Cloud Computing with HTCondor).
        - Specify a list of files as `mp[&#34;files&#34;]` to include them
          in working directory of the server workers.
        - In order to use absolute paths, the list should cosist
          of tuples, where the first item is relative to the second
          (which is an absolute path). The root is then not included
          in the working directory of the server.
        - If this dict field is empty, then all python files
          in `sys.path[0]` are uploaded.

    See `examples/basic_2.py` and `examples/basic_3.py` for example use.
    &#34;&#34;&#34;
    # Parse mp option
    if not mp:
        mp = dict()
    elif mp in [True, &#34;MP&#34;]:
        mp = dict(server=&#34;local&#34;)
    elif isinstance(mp, int):
        mp = dict(server=&#34;local&#34;, NPROC=mp)
    elif mp in [&#34;GCP&#34;, &#34;Google&#34;]:
        mp = dict(server=&#34;GCP&#34;, files=[], code=&#34;&#34;)

    # Parse fail_gently
    if fail_gently is None:
        if mp and mp[&#34;server&#34;] == &#34;GCP&#34;:
            fail_gently = False
            # coz cloud processing is entirely de-coupled anyways
        else:
            fail_gently = True
            # True unless otherwise requested
    kwargs[&#34;fail_gently&#34;] = fail_gently

    # Bundle HMM with kwargs
    kwargs[&#39;HMM&#39;] = HMM

    # Parse save_as
    if save_as in [None, False]:
        assert not mp, &#34;Multiprocessing requires saving data.&#34;
        # Parallelization w/o storing is possible, especially w/ threads.
        # But it involves more complicated communication set-up.
        def xpi_dir(*args): return None
    else:
        save_as = rc.dirs.data / Path(save_as).stem
        save_as /= datetime.now().strftime(XP_TIMESTAMP_TEMPLATE)
        os.makedirs(save_as)
        print(f&#34;Experiment stored at {save_as}&#34;)

        def xpi_dir(i):
            path = save_as / str(i)
            os.mkdir(path)
            return path

    # No parallelization
    if not mp:
        for ixp, (xp, label) in enumerate(zip(self, self.gen_names())):
            run_experiment(xp, label, xpi_dir(ixp), **kwargs)

    # Local multiprocessing
    elif mp[&#34;server&#34;].lower() == &#34;local&#34;:
        def run_with_fixed_args(arg):
            xp, ixp = arg
            run_experiment(xp, None, xpi_dir(ixp), **kwargs)
        args = zip(self, range(len(self)))

        pb.disable_progbar          = True
        pb.disable_user_interaction = True
        NPROC = mp.get(&#34;NPROC&#34;, None)  # None =&gt; mp.cpu_count()
        from dapper.tools.multiproc import mpd  # will fail on GCP
        with mpd.Pool(NPROC) as pool:
            list(tqdm(
                pool.imap(
                    run_with_fixed_args, args),
                total=len(self),
                desc=&#34;Parallel experim&#39;s&#34;,
                smoothing=0.1))
        pb.disable_progbar          = False
        pb.disable_user_interaction = False

    # Google cloud platform, multiprocessing
    elif mp[&#34;server&#34;] == &#34;GCP&#34;:
        for ixp, xp in enumerate(self):
            with open(xpi_dir(ixp)/&#34;xp.var&#34;, &#34;wb&#34;) as f:
                dill.dump(dict(xp=xp), f)

        with open(save_as/&#34;xp.com&#34;, &#34;wb&#34;) as f:
            dill.dump(kwargs, f)

        # mkdir extra_files
        extra_files = save_as / &#34;extra_files&#34;
        os.mkdir(extra_files)
        # Default files: .py files in sys.path[0] (main script&#39;s path)
        if not mp.get(&#34;files&#34;, []):
            ff = os.listdir(sys.path[0])
            mp[&#34;files&#34;] = [f for f in ff if f.endswith(&#34;.py&#34;)]
        # Copy files into extra_files
        for f in mp[&#34;files&#34;]:
            if isinstance(f, (str, Path)):
                # Example: f = &#34;A.py&#34;
                path = Path(sys.path[0]) / f
                dst = f
            else:  # instance of tuple(path, root)
                # Example: f = (&#34;~/E/G/A.py&#34;, &#34;G&#34;)
                path, root = f
                dst = Path(path).relative_to(root)
            dst = extra_files / dst
            os.makedirs(dst.parent, exist_ok=True)
            try:
                shutil.copytree(path, dst)  # dir -r
            except OSError:
                shutil.copy2(path, dst)  # file

        # Loads PWD/xp_{var,com} and calls run_experiment()
        with open(extra_files/&#34;load_and_run.py&#34;, &#34;w&#34;) as f:
            f.write(dedent(&#34;&#34;&#34;\
            import dill
            from dapper.xp_launch import run_experiment

            # Load
            with open(&#34;xp.com&#34;, &#34;rb&#34;) as f: com = dill.load(f)
            with open(&#34;xp.var&#34;, &#34;rb&#34;) as f: var = dill.load(f)

            # User-defined code
            %s

            # Run
            result = run_experiment(var[&#39;xp&#39;], None, &#34;.&#34;, **com)
            &#34;&#34;&#34;) % dedent(mp[&#34;code&#34;]))

        with open(extra_files/&#34;dpr_config.yaml&#34;, &#34;w&#34;) as f:
            f.write(&#34;\n&#34;.join([
                &#34;data_root: &#39;$cwd&#39;&#34;,
                &#34;liveplotting: no&#34;,
                &#34;welcome_message: no&#34;]))
        submit_job_GCP(save_as)

    return save_as</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="DAPPER" href="https://nansencenter.github.io/DAPPER">
<img src="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo_wtxt.png" alt="">
<!-- can add style="width:200px;" to img -->
</a>
</header>
<div class="gcse-search" style="height: 70px"
data-as_oq="inurl:github.com/nansencenter/DAPPER site:nansencenter.github.io/DAPPER"
data-gaCategoryParameter="dapper.xp_launch">
</div>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dapper" href="index.html">dapper</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dapper.xp_launch.seed_and_simulate" href="#dapper.xp_launch.seed_and_simulate">seed_and_simulate</a></code></li>
<li><code><a title="dapper.xp_launch.run_experiment" href="#dapper.xp_launch.run_experiment">run_experiment</a></code></li>
<li><code><a title="dapper.xp_launch.collapse_str" href="#dapper.xp_launch.collapse_str">collapse_str</a></code></li>
<li><code><a title="dapper.xp_launch.combinator" href="#dapper.xp_launch.combinator">combinator</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dapper.xp_launch.xpList" href="#dapper.xp_launch.xpList">xpList</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.xp_launch.xpList.append" href="#dapper.xp_launch.xpList.append">append</a></code></li>
<li><code><a title="dapper.xp_launch.xpList.inds" href="#dapper.xp_launch.xpList.inds">inds</a></code></li>
<li><code><a title="dapper.xp_launch.xpList.squeeze" href="#dapper.xp_launch.xpList.squeeze">squeeze</a></code></li>
<li><code><a title="dapper.xp_launch.xpList.gen_names" href="#dapper.xp_launch.xpList.gen_names">gen_names</a></code></li>
<li><code><a title="dapper.xp_launch.xpList.tabulate_avrgs" href="#dapper.xp_launch.xpList.tabulate_avrgs">tabulate_avrgs</a></code></li>
<li><code><a title="dapper.xp_launch.xpList.launch" href="#dapper.xp_launch.xpList.launch">launch</a></code></li>
<li><code><a title="dapper.xp_launch.xpList.da_methods" href="#dapper.xp_launch.xpList.da_methods">da_methods</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>