<!-- Search file for "CHANGE" for my own changes -->
<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>dapper.xp_process API documentation</title>
<meta name="description" content="Tools (notably `xpSpace`) for processing and presenting experiment data." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<link rel="preconnect" href="https://www.google.com">
<script async src="https://cse.google.com/cse.js?cx=017837193012385208679:pey8ky8gdqw"></script>
<style>
.gsc-control-cse {padding:0 !important;margin-top:1em}
body.gsc-overflow-hidden #sidebar {overflow: visible;}
</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo.png">
<!-- Dont work coz pdoc already defines these:
<title>DAPPER doc</title>
<meta name="description" content="Data Assimilation with Python: a Package for Experimental Research" />
-->
<a href="https://github.com/nansencenter/DAPPER" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dapper.xp_process</code></h1>
</header>
<section id="section-intro">
<p>Tools (notably <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code>) for processing and presenting experiment data.</p>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L1-L1152" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34;Tools (notably `xpSpace`) for processing and presenting experiment data.&#34;&#34;&#34;

import collections
import copy
import logging
import os
import shutil
import warnings
from datetime import datetime
from pathlib import Path

import colorama
import dill
import matplotlib as mpl
import numpy as np
import struct_tools
from matplotlib import cm, ticker
from mpl_tools import place
from patlib.std import nonchalance, set_tmp
from struct_tools import DotDict
from tabulate import tabulate
from tqdm.auto import tqdm

import dapper.tools.remote.uplink as uplink
from dapper.dpr_config import rc
from dapper.stats import align_col, unpack_uqs
from dapper.tools.colors import color_text, stripe
from dapper.tools.rounding import UncertainQtty
from dapper.tools.viz import axis_scale_by_array
from dapper.xp_launch import XP_TIMESTAMP_TEMPLATE, collapse_str, xpList

mpl_logger = logging.getLogger(&#39;matplotlib&#39;)


class NoneDict(DotDict):
    &#34;&#34;&#34;DotDict with getattr fallback (None).&#34;&#34;&#34;

    def __getattr__(self, name):
        return None


NO_KEY = (&#34;da_method&#34;, &#34;xSect&#34;, &#34;upd_a&#34;)
def make_label(coord, no_key=NO_KEY, exclude=()):  # noqa
    &#34;&#34;&#34;Make label from coord.&#34;&#34;&#34;
    dct = {a: v for a, v in coord.items() if v != None}
    lbl = &#39;&#39;
    for k, v in dct.items():
        if k not in exclude:
            if any(x in k for x in no_key):
                lbl = lbl + f&#39; {v}&#39;
            else:
                lbl = lbl + f&#39; {collapse_str(k,7)}:{v}&#39;
    return lbl[1:]


def default_styles(coord, baseline_legends=False):
    &#34;&#34;&#34;Quick and dirty (but somewhat robust) styling.&#34;&#34;&#34;
    style = DotDict(ms=8)
    style.label = make_label(coord)

    if coord.da_method == &#34;Climatology&#34;:
        style.ls = &#34;:&#34;
        style.c = &#34;k&#34;
        if not baseline_legends:
            style.label = None

    elif coord.da_method == &#34;OptInterp&#34;:
        style.ls = &#34;:&#34;
        style.c = .7*np.ones(3)
        style.label = &#34;Opt. Interp.&#34;
        if not baseline_legends:
            style.label = None

    elif coord.da_method == &#34;Var3D&#34;:
        style.ls = &#34;:&#34;
        style.c = .5*np.ones(3)
        style.label = &#34;3D-Var&#34;
        if not baseline_legends:
            style.label = None

    elif coord.da_method == &#34;EnKF&#34;:
        style.marker = &#34;*&#34;
        style.c = &#34;C1&#34;

    elif coord.da_method == &#34;PartFilt&#34;:
        style.marker = &#34;X&#34;
        style.c = &#34;C2&#34;

    else:
        style.marker = &#34;.&#34;

    return style


def rel_index(elem, lst, default=None):
    &#34;&#34;&#34;`lst.index(elem) / len(lst)` with fallback.&#34;&#34;&#34;
    try:
        return lst.index(elem) / len(lst)
    except ValueError:
        if default == None:
            raise
        return default


def discretize_cmap(cmap, N, val0=0, val1=1, name=None):
    &#34;&#34;&#34;Discretize `cmap` so that it partitions `[0, 1]` into `N` segments.

    I.e. `cmap(k/N) == cmap(k/N + eps)`.

    Also provide the ScalarMappable `sm`
    that maps range(N) to the segment centers,
    as will be reflected by `cb = fig.colorbar(sm)`.
    You can then re-label the ticks using
    `cb.set_ticks(np.arange(N)); cb.set_ticklabels([&#34;A&#34;,&#34;B&#34;,&#34;C&#34;,...])`.
    &#34;&#34;&#34;
    # cmap(k/N)
    from_list = mpl.colors.LinearSegmentedColormap.from_list
    colors = cmap(np.linspace(val0, val1, N))
    cmap = from_list(name, colors, N)
    # sm
    cNorm = mpl.colors.Normalize(-.5, -.5+N)
    sm = mpl.cm.ScalarMappable(cNorm, cmap)
    return cmap, sm


def cm_bond(cmap, xp_dict, axis, vmin=0, vmax=0):
    &#34;&#34;&#34;Map cmap for `coord.axis ∈ [0, len(ticks)]`.&#34;&#34;&#34;
    def link(coord):
        &#34;&#34;&#34;Essentially: `cmap(ticks.index(coord.axis))`&#34;&#34;&#34;
        if hasattr(coord, axis):
            ticks = xp_dict.ticks[axis]
            cNorm = mpl.colors.Normalize(vmin, vmax + len(ticks))
            ScMap = cm.ScalarMappable(cNorm, cmap).to_rgba
            index = ticks.index(getattr(coord, axis))
            return ScMap(index)
        else:
            return cmap(0.5)
    return link


def in_idx(coord, indices, xp_dict, axis):
    &#34;&#34;&#34;Essentially: `coord.axis in ticks[indices]`.&#34;&#34;&#34;
    if hasattr(coord, axis):
        ticks = np.array(xp_dict.ticks[axis])[indices]
        return getattr(coord, axis) in ticks
    else:
        return True


def find_latest_run(root: Path):
    &#34;&#34;&#34;Find the latest experiment (dir containing many)&#34;&#34;&#34;
    def parse(d):
        try:
            return datetime.strptime(d.name, XP_TIMESTAMP_TEMPLATE)
        except ValueError:
            return None
    dd = [e for e in (parse(d) for d in root.iterdir()) if e is not None]
    d = max(dd)
    d = datetime.strftime(d, XP_TIMESTAMP_TEMPLATE)
    return d


def load_HMM(save_as):
    save_as = Path(save_as).expanduser()
    HMM = dill.load(open(save_as/&#34;xp.com&#34;, &#34;rb&#34;))[&#34;HMM&#34;]
    return HMM


def load_xps(save_as):
    &#34;&#34;&#34;Load `xps` (as a simple list) from dir.&#34;&#34;&#34;
    save_as = Path(save_as).expanduser()
    files = [d/&#34;xp&#34; for d in uplink.list_job_dirs(save_as)]

    def load_any(filepath):
        &#34;&#34;&#34;Load any/all `xp&#39;s` from `filepath`.&#34;&#34;&#34;
        with open(filepath, &#34;rb&#34;) as F:
            # If experiment crashed, then xp will be empty
            try:
                data = dill.load(F)
            except EOFError:
                return []
            # Always return list
            try:
                return data[&#34;xps&#34;]
            except KeyError:
                return [data[&#34;xp&#34;]]

    print(&#34;Loading %d files from %s&#34; % (len(files), save_as))
    xps = []  # NB: progbar wont clean up properly w/ list compr.
    for f in tqdm(files, desc=&#34;Loading&#34;):
        xps.extend(load_any(f))

    if len(xps) &lt; len(files):
        print(f&#34;{len(files)-len(xps)} files could not be loaded.&#34;)

    return xps


def save_xps(xps, save_as, nDir=100):
    &#34;&#34;&#34;Split xps and save in save_as/i for i in range(nDir).

    Example
    -------
    Rename attr n_iter to nIter:
    &gt;&gt;&gt; proj_name = &#34;Stein&#34;
    &gt;&gt;&gt; dd = rc.dirs.data / proj_name
    &gt;&gt;&gt; save_as = dd / &#34;run_2020-09-22__19:36:13&#34;

    &gt;&gt;&gt; for save_as in dd.iterdir():  # doctest: +SKIP
    ...     save_as = dd / save_as
    ...
    ...     xps = load_xps(save_as)
    ...     HMM = load_HMM(save_as)
    ...
    ...     for xp in xps:
    ...         if hasattr(xp,&#34;n_iter&#34;):
    ...             xp.nIter = xp.n_iter
    ...             del xp.n_iter
    ...
    ...     overwrite_xps(xps, save_as)
    &#34;&#34;&#34;
    save_as = Path(save_as).expanduser()
    save_as.mkdir(parents=False, exist_ok=False)

    splitting = np.array_split(xps, nDir)
    for i, sub_xps in enumerate(tqdm(splitting, desc=&#34;Saving&#34;)):
        if len(sub_xps):
            iDir = save_as / str(i)
            os.mkdir(iDir)
            with open(iDir/&#34;xp&#34;, &#34;wb&#34;) as F:
                dill.dump({&#39;xps&#39;: sub_xps}, F)


def overwrite_xps(xps, save_as, nDir=100):
    &#34;&#34;&#34;Save xps in save_as, but safely (by first saving to tmp).&#34;&#34;&#34;
    save_xps(xps, save_as/&#34;tmp&#34;, nDir)

    # Delete
    for d in tqdm(uplink.list_job_dirs(save_as),
                  desc=&#34;Deleting old&#34;):
        shutil.rmtree(d)

    # Mv up from tmp/ -- goes quick, coz there are not many.
    for d in os.listdir(save_as/&#34;tmp&#34;):
        shutil.move(save_as/&#34;tmp&#34;/d, save_as/d)

    shutil.rmtree(save_as/&#34;tmp&#34;)


def reduce_inodes(save_as, nDir=100):
    &#34;&#34;&#34;Reduce the number of `xp` dirs

    by packing multiple `xp`s into lists (`xps`).

    This reduces the **number** of files (inodes) on the system,
    which limits storage capacity (along with **size**).

    It also deletes files &#34;xp.var&#34; and &#34;out&#34;
    (which tends to be relatively large coz of the progbar).
    This is probably also the reason that the loading time is sometimes reduced.
    &#34;&#34;&#34;
    overwrite_xps(load_xps(save_as), save_as, nDir)


class SparseSpace(dict):
    &#34;&#34;&#34;Subclass of `dict` that enforces key conformity to a given `namedtuple`.

    Like a normal `dict`, it can hold any type of objects.
    But, since the keys must conform, they effectively follow a coordinate system,
    so that the `dict` becomes a vector **space**.

    The coordinate system is specified by the `axes`:
    a list of keys defining the `namedtuple` of `self.Coord`.

    In intended usage, this space is highly sparse,
    meaning there are many coordinates with no entry.
    Indeed, as a data format for nd-arrays, it may be called
    &#34;coordinate list representation&#34;, used e.g. by `scipy.sparse.coo_matrix`.

    Thus, operations across (potentially multiple) axes,
    such as optimization or averaging, should be carried out by iterating
    -- not over the axes -- but over the the list of items.

    The most important method is `nest`,
    which is used (by `xpSpace.table_tree`) to print and plot results.

    In addition, `__getitem__` is very flexible, allowing accessing by:

    - The actual key, a `self.Coord` object. Returns single item.
    - A `dict` to match against (part of) the coordinates. Returns subspace.
    - An `int`. Returns `list(self)[key]`.
    - A list of any of the above. Returns list.

    This flexibility can cause bugs, but it&#39;s probably still worth it.
    Also see `__call__`, `get_for`, and `coords_matching`, for further convenience.

    Inspired by

    - https://stackoverflow.com/a/7728830
    - https://stackoverflow.com/q/3387691

    Example:
    &gt;&gt;&gt; dct = xpSpace([&#34;x&#34;, &#34;y&#34;, &#34;z&#34;])
    &gt;&gt;&gt; dct[(1, 2, 3)] = &#34;point 1&#34;
    &gt;&gt;&gt; dct[1, 2, 3] == dct[(1, 2, 3)] == dct[dct.Coord(1, 2, 3)] == &#34;point 1&#34;
    True

    This dict only has three dimensions/axes, so this fails:
    &gt;&gt;&gt; dct[(1, 2, 3, 4)]
    Traceback (most recent call last):
    ...
    KeyError: (1, 2, 3, 4)

    Individual coordinates can be anything. For example `None`:
    &gt;&gt;&gt; dct[(1, 2, None)] = &#34;point 2&#34;
    &#34;&#34;&#34;

    @property
    def axes(self):
        return self.Coord._fields

    def __init__(self, axes):
        &#34;&#34;&#34;Usually initialized through `xpSpace`.

        Parameters
        ----------
        axes: list
            The attributes defining the coordinate system.
        &#34;&#34;&#34;
        # Define coordinate system
        self.Coord = collections.namedtuple(&#39;Coord&#39;, axes)

        # Dont print keys in str
        self.Coord.__str__  = lambda c: &#34;(&#34; + &#34;, &#34;.join(str(v) for v in c) + &#34;)&#34;
        # Only show ... of Coord(...)
        self.Coord.repr2 = lambda c: repr(c).replace(&#34;Coord&#34;, &#34;&#34;).strip(&#34;()&#34;)

    def update(self, items):
        &#34;&#34;&#34;Update dict, using the custom `__setitem__` to ensure key conformity.

        NB: the `kwargs` syntax is not supported because it only works for keys that
        consist of (a single) string, which is not very interesting for SparseSpace.
        &#34;&#34;&#34;
        # See https://stackoverflow.com/a/2588648
        # and https://stackoverflow.com/a/2390997
        try:
            items = items.items()
        except AttributeError:
            pass
        for k, v in items:
            self[k] = v

    def __setitem__(self, key, val):
        &#34;&#34;&#34;Setitem ensuring coordinate conforms.&#34;&#34;&#34;
        try:
            key = self.Coord(*key)
        except TypeError:
            raise TypeError(
                f&#34;The key {key!r} did not fit the coord. system &#34;
                f&#34;which has axes {self.axes}&#34;)
        super().__setitem__(key, val)

    def __getitem__(self, key):
        &#34;&#34;&#34;Flexible indexing.&#34;&#34;&#34;
        # List of items (by a list of indices).
        # Also see get_for().
        if isinstance(key, list):
            return [self[k] for k in key]

        # Single (by integer) or list (by Slice)
        # Note: NOT validating np.int64 here catches quite a few bugs.
        elif isinstance(key, int) or isinstance(key, slice):
            return [*self.values()][key]

        # Subspace (by dict, ie. an informal, partial coordinate)
        elif isinstance(key, dict):
            outer = self.nest(outer_axes=list(key))  # nest
            coord = outer.Coord(*key.values())       # create coord
            inner = outer[coord]                     # chose subspace
            return inner

        # Single item (by Coord object, coz an integer (eg)
        # gets interpreted (above) as a list index)
        else:
            # NB: Dont&#39;t use isinstance(key, self.Coord)
            # coz it fails when the namedtuple (Coord) has been
            # instantiated in different places (but with equal params).
            # Also see bugs.python.org/issue7796
            return super().__getitem__(key)

    def __call__(self, **kwargs):
        &#34;&#34;&#34;Convenient syntax to get/access items.

        Example
        -------
        &gt;&gt;&gt; xp_dict(da_method=&#34;EnKF&#34;, infl=1, seed=3)  # doctest: +SKIP
        &#34;&#34;&#34;
        return self.__getitem__(kwargs)

    def get_for(self, ticks, default=None):
        &#34;&#34;&#34;Almost `[self.get(Coord(x)) for x in ticks]`.

        NB: using the &#34;naive&#34; thing: `[self[x] for x in ticks]`
        would probably be a BUG coz integer `x` gets interpreted as indices
        for the internal list.
        &#34;&#34;&#34;
        singleton = not hasattr(ticks[0], &#34;__iter__&#34;)
        def coord(xyz): return self.Coord(xyz if singleton else xyz)
        return [self.get(coord(x), default) for x in ticks]

    def coord_from_attrs(self, entry):
        &#34;&#34;&#34;Form a `coord` for this `xpSpace` by extracting attrs. from `obj`.

        **If** the entries of `self` have attributes matching their `coord`s,
        then this can be seen as the inverse of `__getitem__`. I.e.

            self.coord_from_attrs(self[coord]) == coord
        &#34;&#34;&#34;
        coord = (getattr(entry, a, None) for a in self.axes)
        return self.Coord(*coord)

    def coords_matching(self, **kwargs):
        &#34;&#34;&#34;Get all `coord`s matching kwargs.

        Unlike `__getitem__(**kwargs)`,

        - A list is returned, not a subspace.
        - This list constains keys (coords), not values.
        - The coords refer to the original space, not the subspace.

        The last point is especially useful for `SparseSpace.label_xSection`.
        &#34;&#34;&#34;
        def embed(coord):
            return {**kwargs, **coord._asdict()}
        return [self.Coord(**embed(x)) for x in self[kwargs]]

        # Old implementation.
        # - I prefer the new version for its re-use of __getitem__&#39;s
        #   nesting, evidencing their mutual relationship)
        # - Note that unlike xpList.inds(): missingval shenanigans
        #   are here unnecessary coz each coordinate is complete.
        # match  = lambda x: all(getattr(x,k)==kwargs[k] for k in kwargs)
        # return [x for x in self if match(x)]

    def __repr__(self):
        txt  = f&#34;&lt;{self.__class__.__name__}&gt;&#34;
        txt += &#34; with Coord/axes: &#34;
        try:
            txt += &#34;(and ticks): &#34; + str(struct_tools.AlignedDict(self.ticks))
        except AttributeError:
            txt += str(self.axes) + &#34;\n&#34;

        # Note: print(xpList(self)) produces a more human-readable table,
        # but requires prep_table(), which we don&#39;t really want to call again
        # (it&#39;s only called in from_list, not (necessarily) in any nested spaces)
        L = 2
        keys = [str(k) for k in self]
        if 2*L &lt; len(keys):
            keys = keys[:L] + [&#34;...&#34;] + keys[-L:]
        keys = &#34;[\n  &#34; + &#34;,\n  &#34;.join(keys) + &#34;\n]&#34;
        return txt + f&#34;populated by {len(self)} keys: {keys}&#34;

    def nest(self, inner_axes=None, outer_axes=None):
        &#34;&#34;&#34;Project along `inner_acces` to yield a new `xpSpace` with axes `outer_axes`

        The entries of this `xpSpace` are themselves `xpSpace`s, with axes `inner_axes`,
        each one regrouping the entries with the same (projected) coordinate.

        Note: is also called by `__getitem__(key)` if `key` is dict.
        &#34;&#34;&#34;
        # Default: a singleton outer space,
        # with everything contained in the inner (projection) space.
        if inner_axes is None and outer_axes is None:
            outer_axes = ()

        # Validate axes
        if inner_axes is None:
            assert outer_axes is not None
            inner_axes = struct_tools.complement(self.axes, outer_axes)
        else:
            assert outer_axes is None
            outer_axes = struct_tools.complement(self.axes, inner_axes)

        # Fill spaces
        outer_space = self.__class__(outer_axes)
        for coord, entry in self.items():
            # Lookup subspace coord
            outer_coord = outer_space.coord_from_attrs(coord)
            try:
                # Get subspace
                inner_space = outer_space[outer_coord]
            except KeyError:
                # Create subspace, embed
                inner_space = self.__class__(inner_axes)
                outer_space[outer_coord] = inner_space
            # Add entry to subspace, similar to .fill()
            inner_space[inner_space.coord_from_attrs(coord)] = entry

        return outer_space

    def intersect_axes(self, attrs):
        &#34;&#34;&#34;Rm those `a` in `attrs` that are not in `self.axes`.

        This allows errors in the axes allotment, for ease-of-use.
        &#34;&#34;&#34;
        absent = struct_tools.complement(attrs, self.axes)
        if absent:
            print(color_text(&#34;Warning:&#34;, colorama.Fore.RED),
                  &#34;The requested attributes&#34;,
                  color_text(str(absent), colorama.Fore.RED),
                  (&#34;were not found among the&#34;
                   &#34; xpSpace axes (attrs. used as coordinates&#34;
                   &#34; for the set of experiments).&#34;
                   &#34; This may be no problem if the attr. is redundant&#34;
                   &#34; for the coord-sys.&#34;
                   &#34; However, if it is caused by confusion or mis-spelling,&#34;
                   &#34; then it is likely to cause mis-interpretation&#34;
                   &#34; of the shown results.&#34;))
            attrs = struct_tools.complement(attrs, absent)
        return attrs

    def append_axis(self, axis):
        self.__init__(self.axes+(axis,))
        for coord in list(self):
            entry = self.pop(coord)
            self[coord + (None,)] = entry

    def label_xSection(self, label, *NoneAttrs, **sub_coord):
        &#34;&#34;&#34;Insert duplicate entries for the given cross-section.

        Works by adding the attr. `xSection` to the axes of `SparseSpace`,
        and setting it to `label` for entries matching `sub_coord`,
        reflecting the &#34;constance/constraint/fixation&#34; this represents.
        This distinguishes the entries in this fixed-affine subspace,
        preventing them from being gobbled up by the operations of `nest`.

        If you wish, you can specify the `NoneAttrs`,
        which are consequently set to None for the duplicated entries,
        preventing them from being shown in plot labels and tuning panels.
        &#34;&#34;&#34;
        if &#34;xSect&#34; not in self.axes:
            self.append_axis(&#39;xSect&#39;)

        for coord in self.coords_matching(**self.intersect_axes(sub_coord)):
            entry = copy.deepcopy(self[coord])
            coord = coord._replace(xSect=label)
            coord = coord._replace(**{a: None for a in NoneAttrs})
            self[coord] = entry


AXES_ROLES = dict(outer=None, inner=None, mean=None, optim=None)


class xpSpace(SparseSpace):
    &#34;&#34;&#34;Functionality to facilitate working with `xps` and their results.

    `xpSpace.from_list` initializes a `SparseSpace` from a list
    of objects, typically experiments referred to as `xp`s, by

    - computing the relevant `axes` from the attributes, and
    - filling the dict by `xp`s.
    - computing and writing the attribute `ticks`.

    Using `xpSpace.from_list(xps)` creates a SparseSpace holding `xp`s.
    However, the nested `xpSpace`s output by `xpSpace.table_tree` will hold
    objects of type `UncertainQtty`,
    coz `xpSpace.table_tree` calls `mean` calls `get_stat(statkey)`.

    The main use of `xpSpace` is through `xpSpace.print` &amp; `xpSpace.plot`,
    both of which call `xpSpace.table_tree` to nest the axes of the `SparseSpace`.
    &#34;&#34;&#34;

    _ordering = dict(
        rot       = &#39;as_found&#39;,
        da_method = &#39;as_found&#39;,
    )

    @classmethod
    def from_list(cls, xps, ordering=None):
        &#34;&#34;&#34;Init xpSpace from xpList.&#34;&#34;&#34;

        def make_ticks(axes):
            &#34;&#34;&#34;Unique &amp; sort, for each axis (individually) in axes.&#34;&#34;&#34;
            for ax_name, arr in axes.items():
                ticks = set(arr)  # unique (jumbles order)
                order = {**cls._ordering, **(ordering or {})}
                order = order.get(ax_name, &#39;default&#39;).lower()

                # Sort key
                if callable(order):
                    key = order
                elif &#39;as_found&#39; in order:
                    key = arr.index
                else:
                    def key(x):
                        return x

                # Place None&#39;s at the end
                def key_safe(x):
                    return (x is None), key(x)

                # Sort
                ticks = sorted(ticks, key=key_safe)
                # Reverse
                if isinstance(order, str) and &#34;rev&#34; in order:
                    ticks = ticks[::-1]
                # Assign
                axes[ax_name] = ticks

        # Define and fill SparseSpace
        xp_list = xpList(xps)
        axes = xp_list.prep_table(nomerge=[&#39;xSect&#39;])[0]
        self = cls(axes)
        self.fill(xps)

        make_ticks(axes)
        # Note: this attr (ticks) will not be propagated through nest().
        # That is fine. Otherwise we should have to prune the ticks
        # (if they are to be useful), which we don&#39;t want to do.
        self.ticks = axes

        return self

    def fill(self, xps):
        &#34;&#34;&#34;Mass insertion.&#34;&#34;&#34;
        self.update([(self.coord_from_attrs(xp), xp) for xp in xps])

    def squeeze(self):
        &#34;&#34;&#34;Eliminate unnecessary axes/dimensions.&#34;&#34;&#34;
        squeezed = xpSpace(xpList(self).prep_table()[0])
        squeezed.fill(self)
        return squeezed

    def get_stat(self, statkey=&#34;rmse.a&#34;):
        &#34;&#34;&#34;Make `xpSpace` with identical `keys`, but values `xp.avrgs.statkey`.&#34;&#34;&#34;
        # Init a new xpDict to hold stat
        avrgs = self.__class__(self.axes)

        found_anything = False
        for coord, xp in self.items():
            val = getattr(xp.avrgs, statkey, None)
            avrgs[coord] = val
            found_anything = found_anything or (val is not None)

        if not found_anything:
            raise AttributeError(
                f&#34;The stat.&#39;{statkey}&#39; was not found among any of the xp&#39;s.&#34;)

        return avrgs

    def mean(self, axes=None):
        # Note: The case `axes=()` should work w/o special treatment.
        if axes is None:
            return self

        nested = self.nest(axes)
        for coord, space in nested.items():

            def getval(uq): return uq.val if isinstance(uq, UncertainQtty) else uq
            vals = [getval(uq) for uq in space.values()]

            # Don&#39;t use nanmean! It would give false impressions.
            mu = np.mean(vals)

            with warnings.catch_warnings():
                warnings.simplefilter(&#34;ignore&#34;, category=RuntimeWarning)
                # Don&#39;t print warnings caused by N=1.
                # It already correctly yield nan&#39;s.
                var = np.var(vals, ddof=1)

            N = len(vals)
            uq = UncertainQtty(mu, np.sqrt(var/N))
            uq.nTotal   = N
            uq.nFail    = N - np.isfinite(vals).sum()
            uq.nSuccess = N - uq.nFail

            nested[coord] = uq
        return nested

    def tune(self, axes=None, costfun=None):
        &#34;&#34;&#34;Get (compile/tabulate) a stat. optimised wrt. tuning params.&#34;&#34;&#34;
        # Define cost-function
        costfun = (costfun or &#39;increasing&#39;).lower()
        if &#39;increas&#39; in costfun:
            costfun = (lambda x: +x)
        elif &#39;decreas&#39; in costfun:
            costfun = (lambda x: -x)
        else:
            assert callable(costfun)  # custom

        # Note: The case `axes=()` should work w/o special treatment.
        if axes is None:
            return self

        nested = self.nest(axes)
        for coord, space in nested.items():

            # Find optimal value and coord within space
            MIN = np.inf
            for inner_coord, uq in space.items():
                cost = costfun(uq.val)
                if cost &lt;= MIN:
                    MIN                = cost
                    uq_opt             = uq
                    uq_opt.tuned_coord = inner_coord

            nested[coord] = uq_opt

        return nested

    def validate_axes(self, axes):
        &#34;&#34;&#34;Validate axes.

        Note: This does not convert None to (),
              allowing None to remain special.
              Use `axis or ()` wherever tuples are required.
        &#34;&#34;&#34;
        roles = {}  # &#34;inv&#34;
        for role in set(axes) | set(AXES_ROLES):
            assert role in AXES_ROLES, f&#34;Invalid role {role!r}&#34;
            aa = axes.get(role, AXES_ROLES[role])

            if aa is None:
                pass  # Purposely special
            else:
                # Ensure iterable
                if isinstance(aa, str) or not hasattr(aa, &#34;__iter__&#34;):
                    aa = (aa,)

                aa = self.intersect_axes(aa)

                for axis in aa:

                    # Ensure unique
                    if axis in roles:
                        raise TypeError(
                            f&#34;An axis (here {axis!r}) cannot be assigned to 2&#34;
                            f&#34; roles (here {role!r} and {roles[axis]!r}).&#34;)
                    else:
                        roles[axis] = role
            axes[role] = aa
        return axes

    def table_tree(self, statkey, axes, *, costfun=None):
        &#34;&#34;&#34;Hierarchical nest(): xp_dict&gt;outer&gt;inner&gt;mean&gt;optim.

        as specified by `axes`. Returns this new xpSpace.

        - print_1d / plot_1d (respectively) separate
          tables / panel(row)s for `axes[&#39;outer&#39;]`, and
          columns/ x-axis      for `axes[&#39;inner&#39;]`.

        - The `axes[&#39;mean&#39;]` and `axes[&#39;optim&#39;]` get eliminated
          by the mean()/tune() operations.

        Note: cannot support multiple statkeys
              because it&#39;s not (obviously) meaningful
              when optimizing over tuning_axes.
        &#34;&#34;&#34;
        axes = self.validate_axes(axes)

        def mean_tune(xp_dict):
            &#34;&#34;&#34;Take mean, then tune.

            Note: the SparseDict implementation should be sufficiently
            &#34;uncluttered&#34; that mean_tune() (or a few of its code lines)
            could be called anywhere above/between/below
            the `nest()`ing of `outer` or `inner`.
            These possibile call locations are commented in the code.
            &#34;&#34;&#34;
            uq_dict = xp_dict.get_stat(statkey)
            uq_dict = uq_dict.mean(axes[&#39;mean&#39;])
            uq_dict = uq_dict.tune(axes[&#39;optim&#39;], costfun)
            return uq_dict

        self = mean_tune(self)
        # Prefer calling mean_tune() [also see its docstring]
        # before doing outer/inner nesting. This is because then the axes of
        # a row (xpSpace) should not include mean&amp;optim, and thus:
        #  - Column header/coords may be had directly as row.keys(),
        #    without extraction by coord_from_attrs() from (e.g.) row[0].
        #  - Don&#39;t need to propagate mean&amp;optim axes down to the row level.
        #    which would require defining rows by the nesting:
        #    rows = table.nest(outer_axes=struct_tools.complement(table.axes,
        #        *(axes[&#39;inner&#39;] or ()),
        #        *(axes[&#39;mean&#39;]  or ()),
        #        *(axes[&#39;optim&#39;] or ()) ))
        #  - Each level of the output from table_tree
        #    is a smaller (and more manageable) dict.

        tables = self.nest(outer_axes=axes[&#39;outer&#39;])
        for table_coord, table in tables.items():
            # table = mean_tune(table)

            # Should not be used (nesting as rows is more natural,
            # and is required for getting distinct/row_keys).
            # cols = table.nest(outer_axes=axes[&#39;inner&#39;])

            rows = table.nest(inner_axes=axes[&#39;inner&#39;] or ())

            # Overwrite table by its nesting as rows
            tables[table_coord] = rows

            # for row_coord, row in rows.items():
            # rows[row_coord] = mean_tune(row)

        return axes, tables

    def tickz(self, axis_name):
        &#34;&#34;&#34;Axis ticks without None&#34;&#34;&#34;
        return [x for x in self.ticks[axis_name] if x is not None]

    def print(self, statkey=&#34;rmse.a&#34;, axes=AXES_ROLES,  # noqa
              subcols=True, decimals=None, costfun=None,
              squeeze_labels=True, colorize=True):
        &#34;&#34;&#34;Print tables of results.

        Parameters
        ----------
        statkey: str
            The statistic to extract from the `xp.avrgs` for each `xp`.
        axes: dict
            Allots (maps) the axes/dimensions of `xpSpace` to different
            roles in the printing of the table.

            - Herein, the &#34;role&#34; `outer` should list the axes/attributes
              used to define the splitting of the results into *separate tables*:
              one table for each distinct combination of attributes.
            - Similarly , the role `inner` determines which attributes
              split a table into its columns.
            - `mean` lists the attributes over which the mean is taken
              (for that row &amp; column)
            - `optim` lists the attributes used over which the optimum
               is searched for (after taking the mean).

            Example:

                dict(outer=&#39;da_method&#39;, inner=&#39;N&#39;, mean=&#39;seed&#39;,
                     optim=(&#39;infl&#39;,&#39;loc_rad&#39;))

            Equivalently, use `mean=(&#34;seed&#34;,)`.
            It is acceptible to not specify anything, e.g. `mean=()` or `mean=None`.
        subcols: bool
            If `True`, then subcolumns are added to indicate

            - `1σ`: the confidence interval. If `mean=None` is used, this simply reports
              the value `.prec` of the `statkey`, providing this is an `UncertainQtty`.
              Otherwise, it is computed as `sqrt(var(xps)/N)`,
              where `xps` is the set of statistic gathered over the `mean` axis.
            - `*(optim)`: the optimal point (among all `optim` attributes),
              as defined by `costfun`.
            - `☠`: the number of failures (non-finite values) at that point.
            - `✓`: the number of successes that go into the value
        decimals: int
            Number of decimals to print.
            If `None`, this is determined for each statistic by its uncertainty.
        costfun: str or function
            Use `&#39;increasing&#39;` (default) or `&#39;decreasing&#39;` to indicate that the optimum
            is defined as the lowest or highest value of the `statkey` found.
        squeeze_labels: bool
            Don&#39;t include redundant attributes in the line labels.
            Caution: `get_style` will not be able to access the eliminated attrs.
        colorize: bool
            Add color to tables for readability.
        &#34;&#34;&#34;
        # Inform axes[&#34;mean&#34;]
        if axes.get(&#39;mean&#39;, None):
            print(f&#34;Averages (in time and) over {axes[&#39;mean&#39;]}.&#34;)
        else:
            print(&#34;Averages in time only&#34;
                  &#34; (=&gt; the 1σ estimates may be unreliable).&#34;)

        axes, tables = self.table_tree(statkey, axes, costfun=costfun)

        def make_cols(rows, cc, subcols, h2):
            &#34;&#34;&#34;Subcolumns: align, justify, join.&#34;&#34;&#34;
            # Define subcol formats
            if subcols:
                templ = &#34;{val} ±{prec}&#34;
                templ += &#34;&#34; if axes[&#39;optim&#39;] is None else &#34; *{tuned_coord}&#34;
                templ += &#34;&#34; if  axes[&#39;mean&#39;] is None else &#34; {nFail} {nSuccess}&#34;  # noqa
                aligns = dict(prec=&#34;&lt;&#34;, tuned_coord=&#34;&lt;&#34;)
                labels = dict(val=statkey, prec=&#34;1σ&#34;,
                              tuned_coord=axes[&#34;optim&#34;],
                              nFail=&#34;☠&#34;, nSuccess=&#34;✓&#34;)

            def align(column):
                col = unpack_uqs(column, decimals)
                if subcols:
                    for key in list(col):
                        if key in templ:
                            subcolmn = [labels.get(key, key)] + col[key]
                            col[key] = align_col(subcolmn, just=aligns.get(key, &#34;&gt;&#34;))
                        else:
                            del col[key]
                    col = [templ.format(**row) for row in struct_tools.transps(col)]
                else:
                    col = align_col([statkey] + col[&#34;val&#34;])
                return col

            def super_header(col_coord, idx, col):
                header, matter = col[0], col[1:]
                if idx:
                    cc = str(col_coord).strip(&#34;()&#34;)
                else:
                    cc = col_coord.repr2()
                cc = cc.replace(&#34;, &#34;, &#34;,&#34;)
                cc = cc.center(len(header), &#34;_&#34;)  # +1 width for wide chars like ✔️
                return [cc + &#34;\n&#34; + header] + matter

            # Transpose
            columns = [list(x) for x in zip(*rows)]

            # Format column
            for j, (col_coord, column) in enumerate(zip(cc, columns)):
                col = align(column)
                if h2:
                    col = super_header(col_coord, j, col)
                columns[j] = col

            # Un-transpose
            rows = [list(x) for x in zip(*columns)]

            return rows

        for table_coord, table in tables.items():

            # Get table&#39;s column coords/ticks (cc).
            # cc is really a set, but we use dict for ordering.
            # cc = self.ticks[axes[&#34;inner&#34;]]  # may be &gt; needed
            # cc = table[0].keys()            # may be &lt; needed
            cc = {c: None for row in table.values() for c in row}
            # Could also do cc = table.squeeze() but is it worth it?

            # Convert table (rows) into rows (lists) of equal length
            rows = [[row.get(c, None) for c in cc] for row in table.values()]

            h2 = &#34;\n&#34; if len(cc) &gt; 1 else &#34;&#34;  # super-header?
            rows = make_cols(rows, cc, subcols, h2)

            if squeeze_labels:
                table = table.squeeze()

            # Prepend left-side (attr) table
            # Header
            rows[0] = [h2+k for k in table.axes] + [h2+&#39;⑊&#39;] + rows[0]
            # Matter
            for i, (key, row) in enumerate(zip(table, rows[1:])):
                rows[i+1] = [*key] + [&#39;|&#39;] + row

            # Print
            print(&#34;\n&#34;, end=&#34;&#34;)
            if axes[&#39;outer&#39;]:
                table_title = &#34;Table for &#34; + table_coord.repr2()
                if colorize:
                    clrs = colorama.Back.YELLOW, colorama.Fore.BLACK
                    table_title = color_text(table_title, *clrs)
                print(table_title)
            headers, *rows = rows
            t = tabulate(rows, headers).replace(&#39;␣&#39;, &#39; &#39;)
            if colorize:
                t = stripe(t, slice(2, None))
            print(t)

    def plot(self, statkey=&#34;rmse.a&#34;, axes=AXES_ROLES, get_style=default_styles,
             fignum=None, figsize=None, panels=None,
             title2=None, costfun=None, unique_labels=True,
             squeeze_labels=True):
        &#34;&#34;&#34;Plot (tables of) results.

        Analagously to `xpSpace.print`,
        the averages are grouped by `axis[&#34;inner&#34;]`,
        which here plays the role of the x-axis.

        The averages can also be grouped by `axis[&#34;outer&#34;]`,
        producing a figure with multiple (columns of) panels.

        The optimal points/parameters/attributes are plotted in smaller panels
        below the main plot. This can be turned off by providing the figure
        axes through the `panels` argument.

        The parameters `statkey`, `axes`, `costfun`, `sqeeze_labels`
        are documented in `xpSpace.print`.

        Parameters
        ----------
        get_style: function
            A function that takes an object, and returns a dict of line styles,
            usually as a function of the object&#39;s attributes.
        title2: str
            Figure title (in addition to the defaults).
        unique_labels: bool
            Only show a given label once.
        &#34;&#34;&#34;
        def plot1(panelcol, row, style):
            &#34;&#34;&#34;Plot a given line (row) in the main panel and the optim panels.

            Involves: Sort, insert None&#39;s, handle constant lines.
            &#34;&#34;&#34;
            # Make a full row (yy) of vals, whether is_constant or not.
            # row.is_constant = (len(row)==1 and next(iter(row))==row.Coord(None))
            row.is_constant = all(x == row.Coord(None) for x in row)
            yy = [row[0] if row.is_constant else y for y in row.get_for(xticks)]

            # Plot main
            row.vals = [getattr(y, &#39;val&#39;, None) for y in yy]
            row.handles = {}
            row.handles[&#34;main_panel&#34;] = panelcol[0].plot(xticks, row.vals, **style)[0]

            # Plot tuning params
            row.tuned_coords = {}  # Store ordered, &#34;transposed&#34; argmins
            argmins = [getattr(y, &#39;tuned_coord&#39;, None) for y in yy]
            for a, panel in zip(axes[&#34;optim&#34;], panelcol[1:]):
                yy = [getattr(coord, a, None) for coord in argmins]
                row.tuned_coords[a] = yy

                # Plotting all None&#39;s sets axes units (like any plotting call)
                # which can cause trouble if the axes units were actually supposed
                # to be categorical (eg upd_a), but this is only revealed later.
                if not all(y == None for y in yy):
                    row.handles[a] = panel.plot(xticks, yy, **style)

        # Nest axes through table_tree()
        assert len(axes[&#34;inner&#34;]) == 1, &#34;You must chose the abscissa.&#34;
        axes, tables = self.table_tree(statkey, axes, costfun=costfun)
        xticks = self.tickz(axes[&#34;inner&#34;][0])

        # Create figure panels
        if panels is None:
            nrows   = len(axes[&#39;optim&#39;] or ()) + 1
            ncols   = len(tables)
            maxW    = 12.7  # my mac screen
            figsize = figsize or (min(5*ncols, maxW), 7)
            gs      = dict(
                height_ratios=[6]+[1]*(nrows-1),
                hspace=0.05, wspace=0.05,
                # eyeballed:
                left=0.15/(1+np.log(ncols)),
                right=0.97, bottom=0.06, top=0.9)
            # Create
            _, panels = place.freshfig(num=fignum, figsize=figsize,
                                       nrows=nrows, sharex=True,
                                       ncols=ncols, sharey=&#39;row&#39;,
                                       gridspec_kw=gs, squeeze=False)
        else:
            panels = np.atleast_2d(panels)

        # Fig. Title
        fig = panels[0, 0].figure
        fig_title = &#34;Averages wrt. time&#34;
        if axes[&#34;mean&#34;] is not None:
            fig_title += &#34; and &#34; + &#34;, &#34;.join([repr(c) for c in axes[&#39;mean&#39;]])
        if title2 is not None:
            with nonchalance():
                title2 = title2.relative_to(rc.dirs[&#34;data&#34;])
            fig_title += &#34;\n&#34; + str(title2)
        fig.suptitle(fig_title)

        # Loop outer
        label_register = set()  # mv inside loop to get legend on each panel
        for table_panels, (table_coord, table) in zip(panels.T, tables.items()):
            table.panels = table_panels
            title = &#34;&#34; if axes[&#34;outer&#34;] is None else table_coord.repr2()

            if squeeze_labels:
                distinct = xpList(table.keys()).prep_table()[0]
            else:
                distinct = table.axes

            # Plot
            for coord, row in table.items():

                coord = NoneDict(struct_tools.intersect(coord._asdict(), distinct))
                style = get_style(coord)

                # Rm duplicate labels
                if unique_labels:
                    if style.get(&#34;label&#34;, None) in label_register:
                        del style[&#34;label&#34;]
                    else:
                        label_register.add(style[&#34;label&#34;])

                plot1(table.panels, row, style)

            # Beautify
            panel0 = table.panels[0]
            # panel0.set_title(title)
            panel0.text(.5, 1, title, fontsize=12, ha=&#34;center&#34;, va=&#34;bottom&#34;,
                        transform=panel0.transAxes, bbox=dict(
                            facecolor=&#39;lightyellow&#39;, edgecolor=&#39;k&#39;,
                            alpha=0.99, boxstyle=&#34;round,pad=0.25&#34;,
                            # NB: padding makes label spill into axes
                        ))
            if panel0.is_first_col():
                panel0.set_ylabel(statkey)
            with set_tmp(mpl_logger, &#39;level&#39;, 99):  # silence &#34;no label&#34; msg
                panel0.legend()
            table.panels[-1].set_xlabel(axes[&#34;inner&#34;][0])
            # Tuning panels:
            for a, panel in zip(axes[&#34;optim&#34;] or (), table.panels[1:]):
                if panel.is_first_col():
                    panel.set_ylabel(f&#34;Optim.\n{a}&#34;)

        tables.fig = fig
        tables.xp_dict = self
        tables.axes_roles = axes
        return tables


def default_fig_adjustments(tables, xticks_from_data=False):
    &#34;&#34;&#34;Beautify. These settings do not generalize well.&#34;&#34;&#34;
    # Get axs as 2d-array
    axs = np.array([table.panels for table in tables.values()]).T

    # Main panels (top row) only:
    sensible_f = ticker.FormatStrFormatter(&#39;%g&#39;)
    for ax in axs[0, :]:  # noqa
        for direction in [&#39;y&#39;, &#39;x&#39;]:
            if axs.shape[1] &lt; 6:
                eval(f&#34;ax.set_{direction}scale(&#39;log&#39;)&#34;)
                eval(f&#34;ax.{direction}axis&#34;).set_minor_formatter(sensible_f)
            eval(f&#34;ax.{direction}axis&#34;).set_major_formatter(sensible_f)

    # Set xticks
    if xticks_from_data:
        ax = tables[1].panels[0]
        # Log-scale overrules any custom ticks. Restore control
        ax.xaxis.set_major_formatter(ticker.ScalarFormatter())
        ax.xaxis.set_minor_formatter(ticker.NullFormatter())
        ax.set_xticks(tables.xp_dict.tickz(tables.axes_roles[&#34;inner&#34;][0]))

    # Tuning panels only
    table = tables[0]
    for a, panel in zip(tables.axes_roles[&#34;optim&#34;] or (), table.panels[1:]):
        yy = tables.xp_dict.tickz(a)
        axis_scale_by_array(panel, yy, &#34;y&#34;)
        # set_ymargin doesn&#39;t work for wonky scales. Do so manually:
        alpha = len(yy)/10
        y0, y1, y2, y3 = yy[0], yy[1], yy[-2], yy[-1]
        panel.set_ylim(y0-alpha*(y1-y0), y3+alpha*(y3-y2))

    # All panels
    for ax in axs.ravel():
        for direction in [&#39;y&#39;, &#39;x&#39;]:
            if axs.shape[1] &lt; 6:
                ax.grid(True, which=&#34;minor&#34;, axis=direction)

    # Not strictly compatible with gridspec height_ratios,
    # (throws warning), but still works ok.
    with warnings.catch_warnings():
        warnings.simplefilter(&#34;ignore&#34;, category=UserWarning)
        axs[0, 0].figure.tight_layout()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dapper.xp_process.make_label"><code class="name flex">
<span>def <span class="ident">make_label</span></span>(<span>coord, no_key=('da_method', 'xSect', 'upd_a'), exclude=())</span>
</code></dt>
<dd>
<div class="desc"><p>Make label from coord.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L43-L53" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def make_label(coord, no_key=NO_KEY, exclude=()):  # noqa
    &#34;&#34;&#34;Make label from coord.&#34;&#34;&#34;
    dct = {a: v for a, v in coord.items() if v != None}
    lbl = &#39;&#39;
    for k, v in dct.items():
        if k not in exclude:
            if any(x in k for x in no_key):
                lbl = lbl + f&#39; {v}&#39;
            else:
                lbl = lbl + f&#39; {collapse_str(k,7)}:{v}&#39;
    return lbl[1:]</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.default_styles"><code class="name flex">
<span>def <span class="ident">default_styles</span></span>(<span>coord, baseline_legends=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Quick and dirty (but somewhat robust) styling.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L56-L92" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def default_styles(coord, baseline_legends=False):
    &#34;&#34;&#34;Quick and dirty (but somewhat robust) styling.&#34;&#34;&#34;
    style = DotDict(ms=8)
    style.label = make_label(coord)

    if coord.da_method == &#34;Climatology&#34;:
        style.ls = &#34;:&#34;
        style.c = &#34;k&#34;
        if not baseline_legends:
            style.label = None

    elif coord.da_method == &#34;OptInterp&#34;:
        style.ls = &#34;:&#34;
        style.c = .7*np.ones(3)
        style.label = &#34;Opt. Interp.&#34;
        if not baseline_legends:
            style.label = None

    elif coord.da_method == &#34;Var3D&#34;:
        style.ls = &#34;:&#34;
        style.c = .5*np.ones(3)
        style.label = &#34;3D-Var&#34;
        if not baseline_legends:
            style.label = None

    elif coord.da_method == &#34;EnKF&#34;:
        style.marker = &#34;*&#34;
        style.c = &#34;C1&#34;

    elif coord.da_method == &#34;PartFilt&#34;:
        style.marker = &#34;X&#34;
        style.c = &#34;C2&#34;

    else:
        style.marker = &#34;.&#34;

    return style</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.rel_index"><code class="name flex">
<span>def <span class="ident">rel_index</span></span>(<span>elem, lst, default=None)</span>
</code></dt>
<dd>
<div class="desc"><p><code>lst.index(elem) / len(lst)</code> with fallback.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L95-L102" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def rel_index(elem, lst, default=None):
    &#34;&#34;&#34;`lst.index(elem) / len(lst)` with fallback.&#34;&#34;&#34;
    try:
        return lst.index(elem) / len(lst)
    except ValueError:
        if default == None:
            raise
        return default</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.discretize_cmap"><code class="name flex">
<span>def <span class="ident">discretize_cmap</span></span>(<span>cmap, N, val0=0, val1=1, name=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Discretize <code>cmap</code> so that it partitions <code>[0, 1]</code> into <code>N</code> segments.</p>
<p>I.e. <code>cmap(k/N) == cmap(k/N + eps)</code>.</p>
<p>Also provide the ScalarMappable <code>sm</code>
that maps range(N) to the segment centers,
as will be reflected by <code>cb = fig.colorbar(sm)</code>.
You can then re-label the ticks using
<code>cb.set_ticks(np.arange(N)); cb.set_ticklabels(["A","B","C",...])</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L105-L123" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def discretize_cmap(cmap, N, val0=0, val1=1, name=None):
    &#34;&#34;&#34;Discretize `cmap` so that it partitions `[0, 1]` into `N` segments.

    I.e. `cmap(k/N) == cmap(k/N + eps)`.

    Also provide the ScalarMappable `sm`
    that maps range(N) to the segment centers,
    as will be reflected by `cb = fig.colorbar(sm)`.
    You can then re-label the ticks using
    `cb.set_ticks(np.arange(N)); cb.set_ticklabels([&#34;A&#34;,&#34;B&#34;,&#34;C&#34;,...])`.
    &#34;&#34;&#34;
    # cmap(k/N)
    from_list = mpl.colors.LinearSegmentedColormap.from_list
    colors = cmap(np.linspace(val0, val1, N))
    cmap = from_list(name, colors, N)
    # sm
    cNorm = mpl.colors.Normalize(-.5, -.5+N)
    sm = mpl.cm.ScalarMappable(cNorm, cmap)
    return cmap, sm</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.cm_bond"><code class="name flex">
<span>def <span class="ident">cm_bond</span></span>(<span>cmap, xp_dict, axis, vmin=0, vmax=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Map cmap for <code>coord.axis ∈ [0, len(ticks)]</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L126-L138" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def cm_bond(cmap, xp_dict, axis, vmin=0, vmax=0):
    &#34;&#34;&#34;Map cmap for `coord.axis ∈ [0, len(ticks)]`.&#34;&#34;&#34;
    def link(coord):
        &#34;&#34;&#34;Essentially: `cmap(ticks.index(coord.axis))`&#34;&#34;&#34;
        if hasattr(coord, axis):
            ticks = xp_dict.ticks[axis]
            cNorm = mpl.colors.Normalize(vmin, vmax + len(ticks))
            ScMap = cm.ScalarMappable(cNorm, cmap).to_rgba
            index = ticks.index(getattr(coord, axis))
            return ScMap(index)
        else:
            return cmap(0.5)
    return link</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.in_idx"><code class="name flex">
<span>def <span class="ident">in_idx</span></span>(<span>coord, indices, xp_dict, axis)</span>
</code></dt>
<dd>
<div class="desc"><p>Essentially: <code>coord.axis in ticks[indices]</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L141-L147" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def in_idx(coord, indices, xp_dict, axis):
    &#34;&#34;&#34;Essentially: `coord.axis in ticks[indices]`.&#34;&#34;&#34;
    if hasattr(coord, axis):
        ticks = np.array(xp_dict.ticks[axis])[indices]
        return getattr(coord, axis) in ticks
    else:
        return True</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.find_latest_run"><code class="name flex">
<span>def <span class="ident">find_latest_run</span></span>(<span>root: pathlib.Path)</span>
</code></dt>
<dd>
<div class="desc"><p>Find the latest experiment (dir containing many)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L150-L160" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def find_latest_run(root: Path):
    &#34;&#34;&#34;Find the latest experiment (dir containing many)&#34;&#34;&#34;
    def parse(d):
        try:
            return datetime.strptime(d.name, XP_TIMESTAMP_TEMPLATE)
        except ValueError:
            return None
    dd = [e for e in (parse(d) for d in root.iterdir()) if e is not None]
    d = max(dd)
    d = datetime.strftime(d, XP_TIMESTAMP_TEMPLATE)
    return d</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.load_HMM"><code class="name flex">
<span>def <span class="ident">load_HMM</span></span>(<span>save_as)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L163-L166" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def load_HMM(save_as):
    save_as = Path(save_as).expanduser()
    HMM = dill.load(open(save_as/&#34;xp.com&#34;, &#34;rb&#34;))[&#34;HMM&#34;]
    return HMM</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.load_xps"><code class="name flex">
<span>def <span class="ident">load_xps</span></span>(<span>save_as)</span>
</code></dt>
<dd>
<div class="desc"><p>Load <code>xps</code> (as a simple list) from dir.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L169-L196" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def load_xps(save_as):
    &#34;&#34;&#34;Load `xps` (as a simple list) from dir.&#34;&#34;&#34;
    save_as = Path(save_as).expanduser()
    files = [d/&#34;xp&#34; for d in uplink.list_job_dirs(save_as)]

    def load_any(filepath):
        &#34;&#34;&#34;Load any/all `xp&#39;s` from `filepath`.&#34;&#34;&#34;
        with open(filepath, &#34;rb&#34;) as F:
            # If experiment crashed, then xp will be empty
            try:
                data = dill.load(F)
            except EOFError:
                return []
            # Always return list
            try:
                return data[&#34;xps&#34;]
            except KeyError:
                return [data[&#34;xp&#34;]]

    print(&#34;Loading %d files from %s&#34; % (len(files), save_as))
    xps = []  # NB: progbar wont clean up properly w/ list compr.
    for f in tqdm(files, desc=&#34;Loading&#34;):
        xps.extend(load_any(f))

    if len(xps) &lt; len(files):
        print(f&#34;{len(files)-len(xps)} files could not be loaded.&#34;)

    return xps</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.save_xps"><code class="name flex">
<span>def <span class="ident">save_xps</span></span>(<span>xps, save_as, nDir=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Split xps and save in save_as/i for i in range(nDir).</p>
<h2 id="example">Example</h2>
<p>Rename attr n_iter to nIter:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; proj_name = &quot;Stein&quot;
&gt;&gt;&gt; dd = rc.dirs.data / proj_name
&gt;&gt;&gt; save_as = dd / &quot;run_2020-09-22__19:36:13&quot;
</code></pre>
<pre><code class="language-python-repl">&gt;&gt;&gt; for save_as in dd.iterdir():  # doctest: +SKIP
...     save_as = dd / save_as
...
...     xps = load_xps(save_as)
...     HMM = load_HMM(save_as)
...
...     for xp in xps:
...         if hasattr(xp,&quot;n_iter&quot;):
...             xp.nIter = xp.n_iter
...             del xp.n_iter
...
...     overwrite_xps(xps, save_as)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L199-L231" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def save_xps(xps, save_as, nDir=100):
    &#34;&#34;&#34;Split xps and save in save_as/i for i in range(nDir).

    Example
    -------
    Rename attr n_iter to nIter:
    &gt;&gt;&gt; proj_name = &#34;Stein&#34;
    &gt;&gt;&gt; dd = rc.dirs.data / proj_name
    &gt;&gt;&gt; save_as = dd / &#34;run_2020-09-22__19:36:13&#34;

    &gt;&gt;&gt; for save_as in dd.iterdir():  # doctest: +SKIP
    ...     save_as = dd / save_as
    ...
    ...     xps = load_xps(save_as)
    ...     HMM = load_HMM(save_as)
    ...
    ...     for xp in xps:
    ...         if hasattr(xp,&#34;n_iter&#34;):
    ...             xp.nIter = xp.n_iter
    ...             del xp.n_iter
    ...
    ...     overwrite_xps(xps, save_as)
    &#34;&#34;&#34;
    save_as = Path(save_as).expanduser()
    save_as.mkdir(parents=False, exist_ok=False)

    splitting = np.array_split(xps, nDir)
    for i, sub_xps in enumerate(tqdm(splitting, desc=&#34;Saving&#34;)):
        if len(sub_xps):
            iDir = save_as / str(i)
            os.mkdir(iDir)
            with open(iDir/&#34;xp&#34;, &#34;wb&#34;) as F:
                dill.dump({&#39;xps&#39;: sub_xps}, F)</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.overwrite_xps"><code class="name flex">
<span>def <span class="ident">overwrite_xps</span></span>(<span>xps, save_as, nDir=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Save xps in save_as, but safely (by first saving to tmp).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L234-L247" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def overwrite_xps(xps, save_as, nDir=100):
    &#34;&#34;&#34;Save xps in save_as, but safely (by first saving to tmp).&#34;&#34;&#34;
    save_xps(xps, save_as/&#34;tmp&#34;, nDir)

    # Delete
    for d in tqdm(uplink.list_job_dirs(save_as),
                  desc=&#34;Deleting old&#34;):
        shutil.rmtree(d)

    # Mv up from tmp/ -- goes quick, coz there are not many.
    for d in os.listdir(save_as/&#34;tmp&#34;):
        shutil.move(save_as/&#34;tmp&#34;/d, save_as/d)

    shutil.rmtree(save_as/&#34;tmp&#34;)</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.reduce_inodes"><code class="name flex">
<span>def <span class="ident">reduce_inodes</span></span>(<span>save_as, nDir=100)</span>
</code></dt>
<dd>
<div class="desc"><p>Reduce the number of <code>xp</code> dirs</p>
<p>by packing multiple <code>xp</code>s into lists (<code>xps</code>).</p>
<p>This reduces the <strong>number</strong> of files (inodes) on the system,
which limits storage capacity (along with <strong>size</strong>).</p>
<p>It also deletes files "xp.var" and "out"
(which tends to be relatively large coz of the progbar).
This is probably also the reason that the loading time is sometimes reduced.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L250-L262" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def reduce_inodes(save_as, nDir=100):
    &#34;&#34;&#34;Reduce the number of `xp` dirs

    by packing multiple `xp`s into lists (`xps`).

    This reduces the **number** of files (inodes) on the system,
    which limits storage capacity (along with **size**).

    It also deletes files &#34;xp.var&#34; and &#34;out&#34;
    (which tends to be relatively large coz of the progbar).
    This is probably also the reason that the loading time is sometimes reduced.
    &#34;&#34;&#34;
    overwrite_xps(load_xps(save_as), save_as, nDir)</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.default_fig_adjustments"><code class="name flex">
<span>def <span class="ident">default_fig_adjustments</span></span>(<span>tables, xticks_from_data=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Beautify. These settings do not generalize well.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L1110-L1152" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def default_fig_adjustments(tables, xticks_from_data=False):
    &#34;&#34;&#34;Beautify. These settings do not generalize well.&#34;&#34;&#34;
    # Get axs as 2d-array
    axs = np.array([table.panels for table in tables.values()]).T

    # Main panels (top row) only:
    sensible_f = ticker.FormatStrFormatter(&#39;%g&#39;)
    for ax in axs[0, :]:  # noqa
        for direction in [&#39;y&#39;, &#39;x&#39;]:
            if axs.shape[1] &lt; 6:
                eval(f&#34;ax.set_{direction}scale(&#39;log&#39;)&#34;)
                eval(f&#34;ax.{direction}axis&#34;).set_minor_formatter(sensible_f)
            eval(f&#34;ax.{direction}axis&#34;).set_major_formatter(sensible_f)

    # Set xticks
    if xticks_from_data:
        ax = tables[1].panels[0]
        # Log-scale overrules any custom ticks. Restore control
        ax.xaxis.set_major_formatter(ticker.ScalarFormatter())
        ax.xaxis.set_minor_formatter(ticker.NullFormatter())
        ax.set_xticks(tables.xp_dict.tickz(tables.axes_roles[&#34;inner&#34;][0]))

    # Tuning panels only
    table = tables[0]
    for a, panel in zip(tables.axes_roles[&#34;optim&#34;] or (), table.panels[1:]):
        yy = tables.xp_dict.tickz(a)
        axis_scale_by_array(panel, yy, &#34;y&#34;)
        # set_ymargin doesn&#39;t work for wonky scales. Do so manually:
        alpha = len(yy)/10
        y0, y1, y2, y3 = yy[0], yy[1], yy[-2], yy[-1]
        panel.set_ylim(y0-alpha*(y1-y0), y3+alpha*(y3-y2))

    # All panels
    for ax in axs.ravel():
        for direction in [&#39;y&#39;, &#39;x&#39;]:
            if axs.shape[1] &lt; 6:
                ax.grid(True, which=&#34;minor&#34;, axis=direction)

    # Not strictly compatible with gridspec height_ratios,
    # (throws warning), but still works ok.
    with warnings.catch_warnings():
        warnings.simplefilter(&#34;ignore&#34;, category=UserWarning)
        axs[0, 0].figure.tight_layout()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dapper.xp_process.NoneDict"><code class="flex name class">
<span>class <span class="ident">NoneDict</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>DotDict with getattr fallback (None).</p>
<p>Init like a normal dict.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L35-L39" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class NoneDict(DotDict):
    &#34;&#34;&#34;DotDict with getattr fallback (None).&#34;&#34;&#34;

    def __getattr__(self, name):
        return None</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>struct_tools.DotDict</li>
<li>struct_tools.AlignedDict</li>
<li>builtins.dict</li>
</ul>
</dd>
<dt id="dapper.xp_process.SparseSpace"><code class="flex name class">
<span>class <span class="ident">SparseSpace</span></span>
<span>(</span><span>axes)</span>
</code></dt>
<dd>
<div class="desc"><p>Subclass of <code>dict</code> that enforces key conformity to a given <code>namedtuple</code>.</p>
<p>Like a normal <code>dict</code>, it can hold any type of objects.
But, since the keys must conform, they effectively follow a coordinate system,
so that the <code>dict</code> becomes a vector <strong>space</strong>.</p>
<p>The coordinate system is specified by the <code>axes</code>:
a list of keys defining the <code>namedtuple</code> of <code>self.Coord</code>.</p>
<p>In intended usage, this space is highly sparse,
meaning there are many coordinates with no entry.
Indeed, as a data format for nd-arrays, it may be called
"coordinate list representation", used e.g. by <code>scipy.sparse.coo_matrix</code>.</p>
<p>Thus, operations across (potentially multiple) axes,
such as optimization or averaging, should be carried out by iterating
&ndash; not over the axes &ndash; but over the the list of items.</p>
<p>The most important method is <code>nest</code>,
which is used (by <code><a title="dapper.xp_process.xpSpace.table_tree" href="#dapper.xp_process.xpSpace.table_tree">xpSpace.table_tree()</a></code>) to print and plot results.</p>
<p>In addition, <code>__getitem__</code> is very flexible, allowing accessing by:</p>
<ul>
<li>The actual key, a <code>self.Coord</code> object. Returns single item.</li>
<li>A <code>dict</code> to match against (part of) the coordinates. Returns subspace.</li>
<li>An <code>int</code>. Returns <code>list(self)[key]</code>.</li>
<li>A list of any of the above. Returns list.</li>
</ul>
<p>This flexibility can cause bugs, but it's probably still worth it.
Also see <code>__call__</code>, <code>get_for</code>, and <code>coords_matching</code>, for further convenience.</p>
<p>Inspired by</p>
<ul>
<li><a href="https://stackoverflow.com/a/7728830">https://stackoverflow.com/a/7728830</a></li>
<li><a href="https://stackoverflow.com/q/3387691">https://stackoverflow.com/q/3387691</a></li>
</ul>
<p>Example:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; dct = xpSpace([&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])
&gt;&gt;&gt; dct[(1, 2, 3)] = &quot;point 1&quot;
&gt;&gt;&gt; dct[1, 2, 3] == dct[(1, 2, 3)] == dct[dct.Coord(1, 2, 3)] == &quot;point 1&quot;
True
</code></pre>
<p>This dict only has three dimensions/axes, so this fails:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; dct[(1, 2, 3, 4)]
Traceback (most recent call last):
...
KeyError: (1, 2, 3, 4)
</code></pre>
<p>Individual coordinates can be anything. For example <code>None</code>:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; dct[(1, 2, None)] = &quot;point 2&quot;
</code></pre>
<p>Usually initialized through <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>axes</code></strong> :&ensp;<code>list</code></dt>
<dd>The attributes defining the coordinate system.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L265-L548" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class SparseSpace(dict):
    &#34;&#34;&#34;Subclass of `dict` that enforces key conformity to a given `namedtuple`.

    Like a normal `dict`, it can hold any type of objects.
    But, since the keys must conform, they effectively follow a coordinate system,
    so that the `dict` becomes a vector **space**.

    The coordinate system is specified by the `axes`:
    a list of keys defining the `namedtuple` of `self.Coord`.

    In intended usage, this space is highly sparse,
    meaning there are many coordinates with no entry.
    Indeed, as a data format for nd-arrays, it may be called
    &#34;coordinate list representation&#34;, used e.g. by `scipy.sparse.coo_matrix`.

    Thus, operations across (potentially multiple) axes,
    such as optimization or averaging, should be carried out by iterating
    -- not over the axes -- but over the the list of items.

    The most important method is `nest`,
    which is used (by `xpSpace.table_tree`) to print and plot results.

    In addition, `__getitem__` is very flexible, allowing accessing by:

    - The actual key, a `self.Coord` object. Returns single item.
    - A `dict` to match against (part of) the coordinates. Returns subspace.
    - An `int`. Returns `list(self)[key]`.
    - A list of any of the above. Returns list.

    This flexibility can cause bugs, but it&#39;s probably still worth it.
    Also see `__call__`, `get_for`, and `coords_matching`, for further convenience.

    Inspired by

    - https://stackoverflow.com/a/7728830
    - https://stackoverflow.com/q/3387691

    Example:
    &gt;&gt;&gt; dct = xpSpace([&#34;x&#34;, &#34;y&#34;, &#34;z&#34;])
    &gt;&gt;&gt; dct[(1, 2, 3)] = &#34;point 1&#34;
    &gt;&gt;&gt; dct[1, 2, 3] == dct[(1, 2, 3)] == dct[dct.Coord(1, 2, 3)] == &#34;point 1&#34;
    True

    This dict only has three dimensions/axes, so this fails:
    &gt;&gt;&gt; dct[(1, 2, 3, 4)]
    Traceback (most recent call last):
    ...
    KeyError: (1, 2, 3, 4)

    Individual coordinates can be anything. For example `None`:
    &gt;&gt;&gt; dct[(1, 2, None)] = &#34;point 2&#34;
    &#34;&#34;&#34;

    @property
    def axes(self):
        return self.Coord._fields

    def __init__(self, axes):
        &#34;&#34;&#34;Usually initialized through `xpSpace`.

        Parameters
        ----------
        axes: list
            The attributes defining the coordinate system.
        &#34;&#34;&#34;
        # Define coordinate system
        self.Coord = collections.namedtuple(&#39;Coord&#39;, axes)

        # Dont print keys in str
        self.Coord.__str__  = lambda c: &#34;(&#34; + &#34;, &#34;.join(str(v) for v in c) + &#34;)&#34;
        # Only show ... of Coord(...)
        self.Coord.repr2 = lambda c: repr(c).replace(&#34;Coord&#34;, &#34;&#34;).strip(&#34;()&#34;)

    def update(self, items):
        &#34;&#34;&#34;Update dict, using the custom `__setitem__` to ensure key conformity.

        NB: the `kwargs` syntax is not supported because it only works for keys that
        consist of (a single) string, which is not very interesting for SparseSpace.
        &#34;&#34;&#34;
        # See https://stackoverflow.com/a/2588648
        # and https://stackoverflow.com/a/2390997
        try:
            items = items.items()
        except AttributeError:
            pass
        for k, v in items:
            self[k] = v

    def __setitem__(self, key, val):
        &#34;&#34;&#34;Setitem ensuring coordinate conforms.&#34;&#34;&#34;
        try:
            key = self.Coord(*key)
        except TypeError:
            raise TypeError(
                f&#34;The key {key!r} did not fit the coord. system &#34;
                f&#34;which has axes {self.axes}&#34;)
        super().__setitem__(key, val)

    def __getitem__(self, key):
        &#34;&#34;&#34;Flexible indexing.&#34;&#34;&#34;
        # List of items (by a list of indices).
        # Also see get_for().
        if isinstance(key, list):
            return [self[k] for k in key]

        # Single (by integer) or list (by Slice)
        # Note: NOT validating np.int64 here catches quite a few bugs.
        elif isinstance(key, int) or isinstance(key, slice):
            return [*self.values()][key]

        # Subspace (by dict, ie. an informal, partial coordinate)
        elif isinstance(key, dict):
            outer = self.nest(outer_axes=list(key))  # nest
            coord = outer.Coord(*key.values())       # create coord
            inner = outer[coord]                     # chose subspace
            return inner

        # Single item (by Coord object, coz an integer (eg)
        # gets interpreted (above) as a list index)
        else:
            # NB: Dont&#39;t use isinstance(key, self.Coord)
            # coz it fails when the namedtuple (Coord) has been
            # instantiated in different places (but with equal params).
            # Also see bugs.python.org/issue7796
            return super().__getitem__(key)

    def __call__(self, **kwargs):
        &#34;&#34;&#34;Convenient syntax to get/access items.

        Example
        -------
        &gt;&gt;&gt; xp_dict(da_method=&#34;EnKF&#34;, infl=1, seed=3)  # doctest: +SKIP
        &#34;&#34;&#34;
        return self.__getitem__(kwargs)

    def get_for(self, ticks, default=None):
        &#34;&#34;&#34;Almost `[self.get(Coord(x)) for x in ticks]`.

        NB: using the &#34;naive&#34; thing: `[self[x] for x in ticks]`
        would probably be a BUG coz integer `x` gets interpreted as indices
        for the internal list.
        &#34;&#34;&#34;
        singleton = not hasattr(ticks[0], &#34;__iter__&#34;)
        def coord(xyz): return self.Coord(xyz if singleton else xyz)
        return [self.get(coord(x), default) for x in ticks]

    def coord_from_attrs(self, entry):
        &#34;&#34;&#34;Form a `coord` for this `xpSpace` by extracting attrs. from `obj`.

        **If** the entries of `self` have attributes matching their `coord`s,
        then this can be seen as the inverse of `__getitem__`. I.e.

            self.coord_from_attrs(self[coord]) == coord
        &#34;&#34;&#34;
        coord = (getattr(entry, a, None) for a in self.axes)
        return self.Coord(*coord)

    def coords_matching(self, **kwargs):
        &#34;&#34;&#34;Get all `coord`s matching kwargs.

        Unlike `__getitem__(**kwargs)`,

        - A list is returned, not a subspace.
        - This list constains keys (coords), not values.
        - The coords refer to the original space, not the subspace.

        The last point is especially useful for `SparseSpace.label_xSection`.
        &#34;&#34;&#34;
        def embed(coord):
            return {**kwargs, **coord._asdict()}
        return [self.Coord(**embed(x)) for x in self[kwargs]]

        # Old implementation.
        # - I prefer the new version for its re-use of __getitem__&#39;s
        #   nesting, evidencing their mutual relationship)
        # - Note that unlike xpList.inds(): missingval shenanigans
        #   are here unnecessary coz each coordinate is complete.
        # match  = lambda x: all(getattr(x,k)==kwargs[k] for k in kwargs)
        # return [x for x in self if match(x)]

    def __repr__(self):
        txt  = f&#34;&lt;{self.__class__.__name__}&gt;&#34;
        txt += &#34; with Coord/axes: &#34;
        try:
            txt += &#34;(and ticks): &#34; + str(struct_tools.AlignedDict(self.ticks))
        except AttributeError:
            txt += str(self.axes) + &#34;\n&#34;

        # Note: print(xpList(self)) produces a more human-readable table,
        # but requires prep_table(), which we don&#39;t really want to call again
        # (it&#39;s only called in from_list, not (necessarily) in any nested spaces)
        L = 2
        keys = [str(k) for k in self]
        if 2*L &lt; len(keys):
            keys = keys[:L] + [&#34;...&#34;] + keys[-L:]
        keys = &#34;[\n  &#34; + &#34;,\n  &#34;.join(keys) + &#34;\n]&#34;
        return txt + f&#34;populated by {len(self)} keys: {keys}&#34;

    def nest(self, inner_axes=None, outer_axes=None):
        &#34;&#34;&#34;Project along `inner_acces` to yield a new `xpSpace` with axes `outer_axes`

        The entries of this `xpSpace` are themselves `xpSpace`s, with axes `inner_axes`,
        each one regrouping the entries with the same (projected) coordinate.

        Note: is also called by `__getitem__(key)` if `key` is dict.
        &#34;&#34;&#34;
        # Default: a singleton outer space,
        # with everything contained in the inner (projection) space.
        if inner_axes is None and outer_axes is None:
            outer_axes = ()

        # Validate axes
        if inner_axes is None:
            assert outer_axes is not None
            inner_axes = struct_tools.complement(self.axes, outer_axes)
        else:
            assert outer_axes is None
            outer_axes = struct_tools.complement(self.axes, inner_axes)

        # Fill spaces
        outer_space = self.__class__(outer_axes)
        for coord, entry in self.items():
            # Lookup subspace coord
            outer_coord = outer_space.coord_from_attrs(coord)
            try:
                # Get subspace
                inner_space = outer_space[outer_coord]
            except KeyError:
                # Create subspace, embed
                inner_space = self.__class__(inner_axes)
                outer_space[outer_coord] = inner_space
            # Add entry to subspace, similar to .fill()
            inner_space[inner_space.coord_from_attrs(coord)] = entry

        return outer_space

    def intersect_axes(self, attrs):
        &#34;&#34;&#34;Rm those `a` in `attrs` that are not in `self.axes`.

        This allows errors in the axes allotment, for ease-of-use.
        &#34;&#34;&#34;
        absent = struct_tools.complement(attrs, self.axes)
        if absent:
            print(color_text(&#34;Warning:&#34;, colorama.Fore.RED),
                  &#34;The requested attributes&#34;,
                  color_text(str(absent), colorama.Fore.RED),
                  (&#34;were not found among the&#34;
                   &#34; xpSpace axes (attrs. used as coordinates&#34;
                   &#34; for the set of experiments).&#34;
                   &#34; This may be no problem if the attr. is redundant&#34;
                   &#34; for the coord-sys.&#34;
                   &#34; However, if it is caused by confusion or mis-spelling,&#34;
                   &#34; then it is likely to cause mis-interpretation&#34;
                   &#34; of the shown results.&#34;))
            attrs = struct_tools.complement(attrs, absent)
        return attrs

    def append_axis(self, axis):
        self.__init__(self.axes+(axis,))
        for coord in list(self):
            entry = self.pop(coord)
            self[coord + (None,)] = entry

    def label_xSection(self, label, *NoneAttrs, **sub_coord):
        &#34;&#34;&#34;Insert duplicate entries for the given cross-section.

        Works by adding the attr. `xSection` to the axes of `SparseSpace`,
        and setting it to `label` for entries matching `sub_coord`,
        reflecting the &#34;constance/constraint/fixation&#34; this represents.
        This distinguishes the entries in this fixed-affine subspace,
        preventing them from being gobbled up by the operations of `nest`.

        If you wish, you can specify the `NoneAttrs`,
        which are consequently set to None for the duplicated entries,
        preventing them from being shown in plot labels and tuning panels.
        &#34;&#34;&#34;
        if &#34;xSect&#34; not in self.axes:
            self.append_axis(&#39;xSect&#39;)

        for coord in self.coords_matching(**self.intersect_axes(sub_coord)):
            entry = copy.deepcopy(self[coord])
            coord = coord._replace(xSect=label)
            coord = coord._replace(**{a: None for a in NoneAttrs})
            self[coord] = entry</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="dapper.xp_process.SparseSpace.axes"><code class="name">var <span class="ident">axes</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L318-L320" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@property
def axes(self):
    return self.Coord._fields</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.xp_process.SparseSpace.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self, items)</span>
</code></dt>
<dd>
<div class="desc"><p>Update dict, using the custom <code>__setitem__</code> to ensure key conformity.</p>
<p>NB: the <code>kwargs</code> syntax is not supported because it only works for keys that
consist of (a single) string, which is not very interesting for SparseSpace.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L338-L351" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def update(self, items):
    &#34;&#34;&#34;Update dict, using the custom `__setitem__` to ensure key conformity.

    NB: the `kwargs` syntax is not supported because it only works for keys that
    consist of (a single) string, which is not very interesting for SparseSpace.
    &#34;&#34;&#34;
    # See https://stackoverflow.com/a/2588648
    # and https://stackoverflow.com/a/2390997
    try:
        items = items.items()
    except AttributeError:
        pass
    for k, v in items:
        self[k] = v</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.get_for"><code class="name flex">
<span>def <span class="ident">get_for</span></span>(<span>self, ticks, default=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Almost <code>[self.get(Coord(x)) for x in ticks]</code>.</p>
<p>NB: using the "naive" thing: <code>[self[x] for x in ticks]</code>
would probably be a BUG coz integer <code>x</code> gets interpreted as indices
for the internal list.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L400-L409" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_for(self, ticks, default=None):
    &#34;&#34;&#34;Almost `[self.get(Coord(x)) for x in ticks]`.

    NB: using the &#34;naive&#34; thing: `[self[x] for x in ticks]`
    would probably be a BUG coz integer `x` gets interpreted as indices
    for the internal list.
    &#34;&#34;&#34;
    singleton = not hasattr(ticks[0], &#34;__iter__&#34;)
    def coord(xyz): return self.Coord(xyz if singleton else xyz)
    return [self.get(coord(x), default) for x in ticks]</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.coord_from_attrs"><code class="name flex">
<span>def <span class="ident">coord_from_attrs</span></span>(<span>self, entry)</span>
</code></dt>
<dd>
<div class="desc"><p>Form a <code>coord</code> for this <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code> by extracting attrs. from <code>obj</code>.</p>
<p><strong>If</strong> the entries of <code>self</code> have attributes matching their <code>coord</code>s,
then this can be seen as the inverse of <code>__getitem__</code>. I.e.</p>
<pre><code>self.coord_from_attrs(self[coord]) == coord
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L411-L420" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def coord_from_attrs(self, entry):
    &#34;&#34;&#34;Form a `coord` for this `xpSpace` by extracting attrs. from `obj`.

    **If** the entries of `self` have attributes matching their `coord`s,
    then this can be seen as the inverse of `__getitem__`. I.e.

        self.coord_from_attrs(self[coord]) == coord
    &#34;&#34;&#34;
    coord = (getattr(entry, a, None) for a in self.axes)
    return self.Coord(*coord)</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.coords_matching"><code class="name flex">
<span>def <span class="ident">coords_matching</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Get all <code>coord</code>s matching kwargs.</p>
<p>Unlike <code>__getitem__(**kwargs)</code>,</p>
<ul>
<li>A list is returned, not a subspace.</li>
<li>This list constains keys (coords), not values.</li>
<li>The coords refer to the original space, not the subspace.</li>
</ul>
<p>The last point is especially useful for <code><a title="dapper.xp_process.SparseSpace.label_xSection" href="#dapper.xp_process.SparseSpace.label_xSection">SparseSpace.label_xSection()</a></code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L422-L443" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def coords_matching(self, **kwargs):
    &#34;&#34;&#34;Get all `coord`s matching kwargs.

    Unlike `__getitem__(**kwargs)`,

    - A list is returned, not a subspace.
    - This list constains keys (coords), not values.
    - The coords refer to the original space, not the subspace.

    The last point is especially useful for `SparseSpace.label_xSection`.
    &#34;&#34;&#34;
    def embed(coord):
        return {**kwargs, **coord._asdict()}
    return [self.Coord(**embed(x)) for x in self[kwargs]]

    # Old implementation.
    # - I prefer the new version for its re-use of __getitem__&#39;s
    #   nesting, evidencing their mutual relationship)
    # - Note that unlike xpList.inds(): missingval shenanigans
    #   are here unnecessary coz each coordinate is complete.
    # match  = lambda x: all(getattr(x,k)==kwargs[k] for k in kwargs)
    # return [x for x in self if match(x)]</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.nest"><code class="name flex">
<span>def <span class="ident">nest</span></span>(<span>self, inner_axes=None, outer_axes=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Project along <code>inner_acces</code> to yield a new <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code> with axes <code>outer_axes</code></p>
<p>The entries of this <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code> are themselves <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code>s, with axes <code>inner_axes</code>,
each one regrouping the entries with the same (projected) coordinate.</p>
<p>Note: is also called by <code>__getitem__(key)</code> if <code>key</code> is dict.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L463-L499" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def nest(self, inner_axes=None, outer_axes=None):
    &#34;&#34;&#34;Project along `inner_acces` to yield a new `xpSpace` with axes `outer_axes`

    The entries of this `xpSpace` are themselves `xpSpace`s, with axes `inner_axes`,
    each one regrouping the entries with the same (projected) coordinate.

    Note: is also called by `__getitem__(key)` if `key` is dict.
    &#34;&#34;&#34;
    # Default: a singleton outer space,
    # with everything contained in the inner (projection) space.
    if inner_axes is None and outer_axes is None:
        outer_axes = ()

    # Validate axes
    if inner_axes is None:
        assert outer_axes is not None
        inner_axes = struct_tools.complement(self.axes, outer_axes)
    else:
        assert outer_axes is None
        outer_axes = struct_tools.complement(self.axes, inner_axes)

    # Fill spaces
    outer_space = self.__class__(outer_axes)
    for coord, entry in self.items():
        # Lookup subspace coord
        outer_coord = outer_space.coord_from_attrs(coord)
        try:
            # Get subspace
            inner_space = outer_space[outer_coord]
        except KeyError:
            # Create subspace, embed
            inner_space = self.__class__(inner_axes)
            outer_space[outer_coord] = inner_space
        # Add entry to subspace, similar to .fill()
        inner_space[inner_space.coord_from_attrs(coord)] = entry

    return outer_space</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.intersect_axes"><code class="name flex">
<span>def <span class="ident">intersect_axes</span></span>(<span>self, attrs)</span>
</code></dt>
<dd>
<div class="desc"><p>Rm those <code>a</code> in <code>attrs</code> that are not in <code>self.axes</code>.</p>
<p>This allows errors in the axes allotment, for ease-of-use.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L501-L520" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def intersect_axes(self, attrs):
    &#34;&#34;&#34;Rm those `a` in `attrs` that are not in `self.axes`.

    This allows errors in the axes allotment, for ease-of-use.
    &#34;&#34;&#34;
    absent = struct_tools.complement(attrs, self.axes)
    if absent:
        print(color_text(&#34;Warning:&#34;, colorama.Fore.RED),
              &#34;The requested attributes&#34;,
              color_text(str(absent), colorama.Fore.RED),
              (&#34;were not found among the&#34;
               &#34; xpSpace axes (attrs. used as coordinates&#34;
               &#34; for the set of experiments).&#34;
               &#34; This may be no problem if the attr. is redundant&#34;
               &#34; for the coord-sys.&#34;
               &#34; However, if it is caused by confusion or mis-spelling,&#34;
               &#34; then it is likely to cause mis-interpretation&#34;
               &#34; of the shown results.&#34;))
        attrs = struct_tools.complement(attrs, absent)
    return attrs</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.append_axis"><code class="name flex">
<span>def <span class="ident">append_axis</span></span>(<span>self, axis)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L522-L526" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def append_axis(self, axis):
    self.__init__(self.axes+(axis,))
    for coord in list(self):
        entry = self.pop(coord)
        self[coord + (None,)] = entry</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.SparseSpace.label_xSection"><code class="name flex">
<span>def <span class="ident">label_xSection</span></span>(<span>self, label, *NoneAttrs, **sub_coord)</span>
</code></dt>
<dd>
<div class="desc"><p>Insert duplicate entries for the given cross-section.</p>
<p>Works by adding the attr. <code>xSection</code> to the axes of <code><a title="dapper.xp_process.SparseSpace" href="#dapper.xp_process.SparseSpace">SparseSpace</a></code>,
and setting it to <code>label</code> for entries matching <code>sub_coord</code>,
reflecting the "constance/constraint/fixation" this represents.
This distinguishes the entries in this fixed-affine subspace,
preventing them from being gobbled up by the operations of <code>nest</code>.</p>
<p>If you wish, you can specify the <code>NoneAttrs</code>,
which are consequently set to None for the duplicated entries,
preventing them from being shown in plot labels and tuning panels.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L528-L548" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def label_xSection(self, label, *NoneAttrs, **sub_coord):
    &#34;&#34;&#34;Insert duplicate entries for the given cross-section.

    Works by adding the attr. `xSection` to the axes of `SparseSpace`,
    and setting it to `label` for entries matching `sub_coord`,
    reflecting the &#34;constance/constraint/fixation&#34; this represents.
    This distinguishes the entries in this fixed-affine subspace,
    preventing them from being gobbled up by the operations of `nest`.

    If you wish, you can specify the `NoneAttrs`,
    which are consequently set to None for the duplicated entries,
    preventing them from being shown in plot labels and tuning panels.
    &#34;&#34;&#34;
    if &#34;xSect&#34; not in self.axes:
        self.append_axis(&#39;xSect&#39;)

    for coord in self.coords_matching(**self.intersect_axes(sub_coord)):
        entry = copy.deepcopy(self[coord])
        coord = coord._replace(xSect=label)
        coord = coord._replace(**{a: None for a in NoneAttrs})
        self[coord] = entry</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dapper.xp_process.xpSpace"><code class="flex name class">
<span>class <span class="ident">xpSpace</span></span>
<span>(</span><span>axes)</span>
</code></dt>
<dd>
<div class="desc"><p>Functionality to facilitate working with <code>xps</code> and their results.</p>
<p><code><a title="dapper.xp_process.xpSpace.from_list" href="#dapper.xp_process.xpSpace.from_list">xpSpace.from_list()</a></code> initializes a <code><a title="dapper.xp_process.SparseSpace" href="#dapper.xp_process.SparseSpace">SparseSpace</a></code> from a list
of objects, typically experiments referred to as <code>xp</code>s, by</p>
<ul>
<li>computing the relevant <code>axes</code> from the attributes, and</li>
<li>filling the dict by <code>xp</code>s.</li>
<li>computing and writing the attribute <code>ticks</code>.</li>
</ul>
<p>Using <code><a title="dapper.xp_process.xpSpace.from_list" href="#dapper.xp_process.xpSpace.from_list">xpSpace.from_list()</a>(xps)</code> creates a SparseSpace holding <code>xp</code>s.
However, the nested <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code>s output by <code><a title="dapper.xp_process.xpSpace.table_tree" href="#dapper.xp_process.xpSpace.table_tree">xpSpace.table_tree()</a></code> will hold
objects of type <code>UncertainQtty</code>,
coz <code><a title="dapper.xp_process.xpSpace.table_tree" href="#dapper.xp_process.xpSpace.table_tree">xpSpace.table_tree()</a></code> calls <code>mean</code> calls <code>get_stat(statkey)</code>.</p>
<p>The main use of <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code> is through <code><a title="dapper.xp_process.xpSpace.print" href="#dapper.xp_process.xpSpace.print">xpSpace.print()</a></code> &amp; <code><a title="dapper.xp_process.xpSpace.plot" href="#dapper.xp_process.xpSpace.plot">xpSpace.plot()</a></code>,
both of which call <code><a title="dapper.xp_process.xpSpace.table_tree" href="#dapper.xp_process.xpSpace.table_tree">xpSpace.table_tree()</a></code> to nest the axes of the <code><a title="dapper.xp_process.SparseSpace" href="#dapper.xp_process.SparseSpace">SparseSpace</a></code>.</p>
<p>Usually initialized through <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>axes</code></strong> :&ensp;<code>list</code></dt>
<dd>The attributes defining the coordinate system.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L554-L1107" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class xpSpace(SparseSpace):
    &#34;&#34;&#34;Functionality to facilitate working with `xps` and their results.

    `xpSpace.from_list` initializes a `SparseSpace` from a list
    of objects, typically experiments referred to as `xp`s, by

    - computing the relevant `axes` from the attributes, and
    - filling the dict by `xp`s.
    - computing and writing the attribute `ticks`.

    Using `xpSpace.from_list(xps)` creates a SparseSpace holding `xp`s.
    However, the nested `xpSpace`s output by `xpSpace.table_tree` will hold
    objects of type `UncertainQtty`,
    coz `xpSpace.table_tree` calls `mean` calls `get_stat(statkey)`.

    The main use of `xpSpace` is through `xpSpace.print` &amp; `xpSpace.plot`,
    both of which call `xpSpace.table_tree` to nest the axes of the `SparseSpace`.
    &#34;&#34;&#34;

    _ordering = dict(
        rot       = &#39;as_found&#39;,
        da_method = &#39;as_found&#39;,
    )

    @classmethod
    def from_list(cls, xps, ordering=None):
        &#34;&#34;&#34;Init xpSpace from xpList.&#34;&#34;&#34;

        def make_ticks(axes):
            &#34;&#34;&#34;Unique &amp; sort, for each axis (individually) in axes.&#34;&#34;&#34;
            for ax_name, arr in axes.items():
                ticks = set(arr)  # unique (jumbles order)
                order = {**cls._ordering, **(ordering or {})}
                order = order.get(ax_name, &#39;default&#39;).lower()

                # Sort key
                if callable(order):
                    key = order
                elif &#39;as_found&#39; in order:
                    key = arr.index
                else:
                    def key(x):
                        return x

                # Place None&#39;s at the end
                def key_safe(x):
                    return (x is None), key(x)

                # Sort
                ticks = sorted(ticks, key=key_safe)
                # Reverse
                if isinstance(order, str) and &#34;rev&#34; in order:
                    ticks = ticks[::-1]
                # Assign
                axes[ax_name] = ticks

        # Define and fill SparseSpace
        xp_list = xpList(xps)
        axes = xp_list.prep_table(nomerge=[&#39;xSect&#39;])[0]
        self = cls(axes)
        self.fill(xps)

        make_ticks(axes)
        # Note: this attr (ticks) will not be propagated through nest().
        # That is fine. Otherwise we should have to prune the ticks
        # (if they are to be useful), which we don&#39;t want to do.
        self.ticks = axes

        return self

    def fill(self, xps):
        &#34;&#34;&#34;Mass insertion.&#34;&#34;&#34;
        self.update([(self.coord_from_attrs(xp), xp) for xp in xps])

    def squeeze(self):
        &#34;&#34;&#34;Eliminate unnecessary axes/dimensions.&#34;&#34;&#34;
        squeezed = xpSpace(xpList(self).prep_table()[0])
        squeezed.fill(self)
        return squeezed

    def get_stat(self, statkey=&#34;rmse.a&#34;):
        &#34;&#34;&#34;Make `xpSpace` with identical `keys`, but values `xp.avrgs.statkey`.&#34;&#34;&#34;
        # Init a new xpDict to hold stat
        avrgs = self.__class__(self.axes)

        found_anything = False
        for coord, xp in self.items():
            val = getattr(xp.avrgs, statkey, None)
            avrgs[coord] = val
            found_anything = found_anything or (val is not None)

        if not found_anything:
            raise AttributeError(
                f&#34;The stat.&#39;{statkey}&#39; was not found among any of the xp&#39;s.&#34;)

        return avrgs

    def mean(self, axes=None):
        # Note: The case `axes=()` should work w/o special treatment.
        if axes is None:
            return self

        nested = self.nest(axes)
        for coord, space in nested.items():

            def getval(uq): return uq.val if isinstance(uq, UncertainQtty) else uq
            vals = [getval(uq) for uq in space.values()]

            # Don&#39;t use nanmean! It would give false impressions.
            mu = np.mean(vals)

            with warnings.catch_warnings():
                warnings.simplefilter(&#34;ignore&#34;, category=RuntimeWarning)
                # Don&#39;t print warnings caused by N=1.
                # It already correctly yield nan&#39;s.
                var = np.var(vals, ddof=1)

            N = len(vals)
            uq = UncertainQtty(mu, np.sqrt(var/N))
            uq.nTotal   = N
            uq.nFail    = N - np.isfinite(vals).sum()
            uq.nSuccess = N - uq.nFail

            nested[coord] = uq
        return nested

    def tune(self, axes=None, costfun=None):
        &#34;&#34;&#34;Get (compile/tabulate) a stat. optimised wrt. tuning params.&#34;&#34;&#34;
        # Define cost-function
        costfun = (costfun or &#39;increasing&#39;).lower()
        if &#39;increas&#39; in costfun:
            costfun = (lambda x: +x)
        elif &#39;decreas&#39; in costfun:
            costfun = (lambda x: -x)
        else:
            assert callable(costfun)  # custom

        # Note: The case `axes=()` should work w/o special treatment.
        if axes is None:
            return self

        nested = self.nest(axes)
        for coord, space in nested.items():

            # Find optimal value and coord within space
            MIN = np.inf
            for inner_coord, uq in space.items():
                cost = costfun(uq.val)
                if cost &lt;= MIN:
                    MIN                = cost
                    uq_opt             = uq
                    uq_opt.tuned_coord = inner_coord

            nested[coord] = uq_opt

        return nested

    def validate_axes(self, axes):
        &#34;&#34;&#34;Validate axes.

        Note: This does not convert None to (),
              allowing None to remain special.
              Use `axis or ()` wherever tuples are required.
        &#34;&#34;&#34;
        roles = {}  # &#34;inv&#34;
        for role in set(axes) | set(AXES_ROLES):
            assert role in AXES_ROLES, f&#34;Invalid role {role!r}&#34;
            aa = axes.get(role, AXES_ROLES[role])

            if aa is None:
                pass  # Purposely special
            else:
                # Ensure iterable
                if isinstance(aa, str) or not hasattr(aa, &#34;__iter__&#34;):
                    aa = (aa,)

                aa = self.intersect_axes(aa)

                for axis in aa:

                    # Ensure unique
                    if axis in roles:
                        raise TypeError(
                            f&#34;An axis (here {axis!r}) cannot be assigned to 2&#34;
                            f&#34; roles (here {role!r} and {roles[axis]!r}).&#34;)
                    else:
                        roles[axis] = role
            axes[role] = aa
        return axes

    def table_tree(self, statkey, axes, *, costfun=None):
        &#34;&#34;&#34;Hierarchical nest(): xp_dict&gt;outer&gt;inner&gt;mean&gt;optim.

        as specified by `axes`. Returns this new xpSpace.

        - print_1d / plot_1d (respectively) separate
          tables / panel(row)s for `axes[&#39;outer&#39;]`, and
          columns/ x-axis      for `axes[&#39;inner&#39;]`.

        - The `axes[&#39;mean&#39;]` and `axes[&#39;optim&#39;]` get eliminated
          by the mean()/tune() operations.

        Note: cannot support multiple statkeys
              because it&#39;s not (obviously) meaningful
              when optimizing over tuning_axes.
        &#34;&#34;&#34;
        axes = self.validate_axes(axes)

        def mean_tune(xp_dict):
            &#34;&#34;&#34;Take mean, then tune.

            Note: the SparseDict implementation should be sufficiently
            &#34;uncluttered&#34; that mean_tune() (or a few of its code lines)
            could be called anywhere above/between/below
            the `nest()`ing of `outer` or `inner`.
            These possibile call locations are commented in the code.
            &#34;&#34;&#34;
            uq_dict = xp_dict.get_stat(statkey)
            uq_dict = uq_dict.mean(axes[&#39;mean&#39;])
            uq_dict = uq_dict.tune(axes[&#39;optim&#39;], costfun)
            return uq_dict

        self = mean_tune(self)
        # Prefer calling mean_tune() [also see its docstring]
        # before doing outer/inner nesting. This is because then the axes of
        # a row (xpSpace) should not include mean&amp;optim, and thus:
        #  - Column header/coords may be had directly as row.keys(),
        #    without extraction by coord_from_attrs() from (e.g.) row[0].
        #  - Don&#39;t need to propagate mean&amp;optim axes down to the row level.
        #    which would require defining rows by the nesting:
        #    rows = table.nest(outer_axes=struct_tools.complement(table.axes,
        #        *(axes[&#39;inner&#39;] or ()),
        #        *(axes[&#39;mean&#39;]  or ()),
        #        *(axes[&#39;optim&#39;] or ()) ))
        #  - Each level of the output from table_tree
        #    is a smaller (and more manageable) dict.

        tables = self.nest(outer_axes=axes[&#39;outer&#39;])
        for table_coord, table in tables.items():
            # table = mean_tune(table)

            # Should not be used (nesting as rows is more natural,
            # and is required for getting distinct/row_keys).
            # cols = table.nest(outer_axes=axes[&#39;inner&#39;])

            rows = table.nest(inner_axes=axes[&#39;inner&#39;] or ())

            # Overwrite table by its nesting as rows
            tables[table_coord] = rows

            # for row_coord, row in rows.items():
            # rows[row_coord] = mean_tune(row)

        return axes, tables

    def tickz(self, axis_name):
        &#34;&#34;&#34;Axis ticks without None&#34;&#34;&#34;
        return [x for x in self.ticks[axis_name] if x is not None]

    def print(self, statkey=&#34;rmse.a&#34;, axes=AXES_ROLES,  # noqa
              subcols=True, decimals=None, costfun=None,
              squeeze_labels=True, colorize=True):
        &#34;&#34;&#34;Print tables of results.

        Parameters
        ----------
        statkey: str
            The statistic to extract from the `xp.avrgs` for each `xp`.
        axes: dict
            Allots (maps) the axes/dimensions of `xpSpace` to different
            roles in the printing of the table.

            - Herein, the &#34;role&#34; `outer` should list the axes/attributes
              used to define the splitting of the results into *separate tables*:
              one table for each distinct combination of attributes.
            - Similarly , the role `inner` determines which attributes
              split a table into its columns.
            - `mean` lists the attributes over which the mean is taken
              (for that row &amp; column)
            - `optim` lists the attributes used over which the optimum
               is searched for (after taking the mean).

            Example:

                dict(outer=&#39;da_method&#39;, inner=&#39;N&#39;, mean=&#39;seed&#39;,
                     optim=(&#39;infl&#39;,&#39;loc_rad&#39;))

            Equivalently, use `mean=(&#34;seed&#34;,)`.
            It is acceptible to not specify anything, e.g. `mean=()` or `mean=None`.
        subcols: bool
            If `True`, then subcolumns are added to indicate

            - `1σ`: the confidence interval. If `mean=None` is used, this simply reports
              the value `.prec` of the `statkey`, providing this is an `UncertainQtty`.
              Otherwise, it is computed as `sqrt(var(xps)/N)`,
              where `xps` is the set of statistic gathered over the `mean` axis.
            - `*(optim)`: the optimal point (among all `optim` attributes),
              as defined by `costfun`.
            - `☠`: the number of failures (non-finite values) at that point.
            - `✓`: the number of successes that go into the value
        decimals: int
            Number of decimals to print.
            If `None`, this is determined for each statistic by its uncertainty.
        costfun: str or function
            Use `&#39;increasing&#39;` (default) or `&#39;decreasing&#39;` to indicate that the optimum
            is defined as the lowest or highest value of the `statkey` found.
        squeeze_labels: bool
            Don&#39;t include redundant attributes in the line labels.
            Caution: `get_style` will not be able to access the eliminated attrs.
        colorize: bool
            Add color to tables for readability.
        &#34;&#34;&#34;
        # Inform axes[&#34;mean&#34;]
        if axes.get(&#39;mean&#39;, None):
            print(f&#34;Averages (in time and) over {axes[&#39;mean&#39;]}.&#34;)
        else:
            print(&#34;Averages in time only&#34;
                  &#34; (=&gt; the 1σ estimates may be unreliable).&#34;)

        axes, tables = self.table_tree(statkey, axes, costfun=costfun)

        def make_cols(rows, cc, subcols, h2):
            &#34;&#34;&#34;Subcolumns: align, justify, join.&#34;&#34;&#34;
            # Define subcol formats
            if subcols:
                templ = &#34;{val} ±{prec}&#34;
                templ += &#34;&#34; if axes[&#39;optim&#39;] is None else &#34; *{tuned_coord}&#34;
                templ += &#34;&#34; if  axes[&#39;mean&#39;] is None else &#34; {nFail} {nSuccess}&#34;  # noqa
                aligns = dict(prec=&#34;&lt;&#34;, tuned_coord=&#34;&lt;&#34;)
                labels = dict(val=statkey, prec=&#34;1σ&#34;,
                              tuned_coord=axes[&#34;optim&#34;],
                              nFail=&#34;☠&#34;, nSuccess=&#34;✓&#34;)

            def align(column):
                col = unpack_uqs(column, decimals)
                if subcols:
                    for key in list(col):
                        if key in templ:
                            subcolmn = [labels.get(key, key)] + col[key]
                            col[key] = align_col(subcolmn, just=aligns.get(key, &#34;&gt;&#34;))
                        else:
                            del col[key]
                    col = [templ.format(**row) for row in struct_tools.transps(col)]
                else:
                    col = align_col([statkey] + col[&#34;val&#34;])
                return col

            def super_header(col_coord, idx, col):
                header, matter = col[0], col[1:]
                if idx:
                    cc = str(col_coord).strip(&#34;()&#34;)
                else:
                    cc = col_coord.repr2()
                cc = cc.replace(&#34;, &#34;, &#34;,&#34;)
                cc = cc.center(len(header), &#34;_&#34;)  # +1 width for wide chars like ✔️
                return [cc + &#34;\n&#34; + header] + matter

            # Transpose
            columns = [list(x) for x in zip(*rows)]

            # Format column
            for j, (col_coord, column) in enumerate(zip(cc, columns)):
                col = align(column)
                if h2:
                    col = super_header(col_coord, j, col)
                columns[j] = col

            # Un-transpose
            rows = [list(x) for x in zip(*columns)]

            return rows

        for table_coord, table in tables.items():

            # Get table&#39;s column coords/ticks (cc).
            # cc is really a set, but we use dict for ordering.
            # cc = self.ticks[axes[&#34;inner&#34;]]  # may be &gt; needed
            # cc = table[0].keys()            # may be &lt; needed
            cc = {c: None for row in table.values() for c in row}
            # Could also do cc = table.squeeze() but is it worth it?

            # Convert table (rows) into rows (lists) of equal length
            rows = [[row.get(c, None) for c in cc] for row in table.values()]

            h2 = &#34;\n&#34; if len(cc) &gt; 1 else &#34;&#34;  # super-header?
            rows = make_cols(rows, cc, subcols, h2)

            if squeeze_labels:
                table = table.squeeze()

            # Prepend left-side (attr) table
            # Header
            rows[0] = [h2+k for k in table.axes] + [h2+&#39;⑊&#39;] + rows[0]
            # Matter
            for i, (key, row) in enumerate(zip(table, rows[1:])):
                rows[i+1] = [*key] + [&#39;|&#39;] + row

            # Print
            print(&#34;\n&#34;, end=&#34;&#34;)
            if axes[&#39;outer&#39;]:
                table_title = &#34;Table for &#34; + table_coord.repr2()
                if colorize:
                    clrs = colorama.Back.YELLOW, colorama.Fore.BLACK
                    table_title = color_text(table_title, *clrs)
                print(table_title)
            headers, *rows = rows
            t = tabulate(rows, headers).replace(&#39;␣&#39;, &#39; &#39;)
            if colorize:
                t = stripe(t, slice(2, None))
            print(t)

    def plot(self, statkey=&#34;rmse.a&#34;, axes=AXES_ROLES, get_style=default_styles,
             fignum=None, figsize=None, panels=None,
             title2=None, costfun=None, unique_labels=True,
             squeeze_labels=True):
        &#34;&#34;&#34;Plot (tables of) results.

        Analagously to `xpSpace.print`,
        the averages are grouped by `axis[&#34;inner&#34;]`,
        which here plays the role of the x-axis.

        The averages can also be grouped by `axis[&#34;outer&#34;]`,
        producing a figure with multiple (columns of) panels.

        The optimal points/parameters/attributes are plotted in smaller panels
        below the main plot. This can be turned off by providing the figure
        axes through the `panels` argument.

        The parameters `statkey`, `axes`, `costfun`, `sqeeze_labels`
        are documented in `xpSpace.print`.

        Parameters
        ----------
        get_style: function
            A function that takes an object, and returns a dict of line styles,
            usually as a function of the object&#39;s attributes.
        title2: str
            Figure title (in addition to the defaults).
        unique_labels: bool
            Only show a given label once.
        &#34;&#34;&#34;
        def plot1(panelcol, row, style):
            &#34;&#34;&#34;Plot a given line (row) in the main panel and the optim panels.

            Involves: Sort, insert None&#39;s, handle constant lines.
            &#34;&#34;&#34;
            # Make a full row (yy) of vals, whether is_constant or not.
            # row.is_constant = (len(row)==1 and next(iter(row))==row.Coord(None))
            row.is_constant = all(x == row.Coord(None) for x in row)
            yy = [row[0] if row.is_constant else y for y in row.get_for(xticks)]

            # Plot main
            row.vals = [getattr(y, &#39;val&#39;, None) for y in yy]
            row.handles = {}
            row.handles[&#34;main_panel&#34;] = panelcol[0].plot(xticks, row.vals, **style)[0]

            # Plot tuning params
            row.tuned_coords = {}  # Store ordered, &#34;transposed&#34; argmins
            argmins = [getattr(y, &#39;tuned_coord&#39;, None) for y in yy]
            for a, panel in zip(axes[&#34;optim&#34;], panelcol[1:]):
                yy = [getattr(coord, a, None) for coord in argmins]
                row.tuned_coords[a] = yy

                # Plotting all None&#39;s sets axes units (like any plotting call)
                # which can cause trouble if the axes units were actually supposed
                # to be categorical (eg upd_a), but this is only revealed later.
                if not all(y == None for y in yy):
                    row.handles[a] = panel.plot(xticks, yy, **style)

        # Nest axes through table_tree()
        assert len(axes[&#34;inner&#34;]) == 1, &#34;You must chose the abscissa.&#34;
        axes, tables = self.table_tree(statkey, axes, costfun=costfun)
        xticks = self.tickz(axes[&#34;inner&#34;][0])

        # Create figure panels
        if panels is None:
            nrows   = len(axes[&#39;optim&#39;] or ()) + 1
            ncols   = len(tables)
            maxW    = 12.7  # my mac screen
            figsize = figsize or (min(5*ncols, maxW), 7)
            gs      = dict(
                height_ratios=[6]+[1]*(nrows-1),
                hspace=0.05, wspace=0.05,
                # eyeballed:
                left=0.15/(1+np.log(ncols)),
                right=0.97, bottom=0.06, top=0.9)
            # Create
            _, panels = place.freshfig(num=fignum, figsize=figsize,
                                       nrows=nrows, sharex=True,
                                       ncols=ncols, sharey=&#39;row&#39;,
                                       gridspec_kw=gs, squeeze=False)
        else:
            panels = np.atleast_2d(panels)

        # Fig. Title
        fig = panels[0, 0].figure
        fig_title = &#34;Averages wrt. time&#34;
        if axes[&#34;mean&#34;] is not None:
            fig_title += &#34; and &#34; + &#34;, &#34;.join([repr(c) for c in axes[&#39;mean&#39;]])
        if title2 is not None:
            with nonchalance():
                title2 = title2.relative_to(rc.dirs[&#34;data&#34;])
            fig_title += &#34;\n&#34; + str(title2)
        fig.suptitle(fig_title)

        # Loop outer
        label_register = set()  # mv inside loop to get legend on each panel
        for table_panels, (table_coord, table) in zip(panels.T, tables.items()):
            table.panels = table_panels
            title = &#34;&#34; if axes[&#34;outer&#34;] is None else table_coord.repr2()

            if squeeze_labels:
                distinct = xpList(table.keys()).prep_table()[0]
            else:
                distinct = table.axes

            # Plot
            for coord, row in table.items():

                coord = NoneDict(struct_tools.intersect(coord._asdict(), distinct))
                style = get_style(coord)

                # Rm duplicate labels
                if unique_labels:
                    if style.get(&#34;label&#34;, None) in label_register:
                        del style[&#34;label&#34;]
                    else:
                        label_register.add(style[&#34;label&#34;])

                plot1(table.panels, row, style)

            # Beautify
            panel0 = table.panels[0]
            # panel0.set_title(title)
            panel0.text(.5, 1, title, fontsize=12, ha=&#34;center&#34;, va=&#34;bottom&#34;,
                        transform=panel0.transAxes, bbox=dict(
                            facecolor=&#39;lightyellow&#39;, edgecolor=&#39;k&#39;,
                            alpha=0.99, boxstyle=&#34;round,pad=0.25&#34;,
                            # NB: padding makes label spill into axes
                        ))
            if panel0.is_first_col():
                panel0.set_ylabel(statkey)
            with set_tmp(mpl_logger, &#39;level&#39;, 99):  # silence &#34;no label&#34; msg
                panel0.legend()
            table.panels[-1].set_xlabel(axes[&#34;inner&#34;][0])
            # Tuning panels:
            for a, panel in zip(axes[&#34;optim&#34;] or (), table.panels[1:]):
                if panel.is_first_col():
                    panel.set_ylabel(f&#34;Optim.\n{a}&#34;)

        tables.fig = fig
        tables.xp_dict = self
        tables.axes_roles = axes
        return tables</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dapper.xp_process.SparseSpace" href="#dapper.xp_process.SparseSpace">SparseSpace</a></li>
<li>builtins.dict</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="dapper.xp_process.xpSpace.from_list"><code class="name flex">
<span>def <span class="ident">from_list</span></span>(<span>xps, ordering=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Init xpSpace from xpList.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L578-L622" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@classmethod
def from_list(cls, xps, ordering=None):
    &#34;&#34;&#34;Init xpSpace from xpList.&#34;&#34;&#34;

    def make_ticks(axes):
        &#34;&#34;&#34;Unique &amp; sort, for each axis (individually) in axes.&#34;&#34;&#34;
        for ax_name, arr in axes.items():
            ticks = set(arr)  # unique (jumbles order)
            order = {**cls._ordering, **(ordering or {})}
            order = order.get(ax_name, &#39;default&#39;).lower()

            # Sort key
            if callable(order):
                key = order
            elif &#39;as_found&#39; in order:
                key = arr.index
            else:
                def key(x):
                    return x

            # Place None&#39;s at the end
            def key_safe(x):
                return (x is None), key(x)

            # Sort
            ticks = sorted(ticks, key=key_safe)
            # Reverse
            if isinstance(order, str) and &#34;rev&#34; in order:
                ticks = ticks[::-1]
            # Assign
            axes[ax_name] = ticks

    # Define and fill SparseSpace
    xp_list = xpList(xps)
    axes = xp_list.prep_table(nomerge=[&#39;xSect&#39;])[0]
    self = cls(axes)
    self.fill(xps)

    make_ticks(axes)
    # Note: this attr (ticks) will not be propagated through nest().
    # That is fine. Otherwise we should have to prune the ticks
    # (if they are to be useful), which we don&#39;t want to do.
    self.ticks = axes

    return self</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.xp_process.xpSpace.fill"><code class="name flex">
<span>def <span class="ident">fill</span></span>(<span>self, xps)</span>
</code></dt>
<dd>
<div class="desc"><p>Mass insertion.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L624-L626" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def fill(self, xps):
    &#34;&#34;&#34;Mass insertion.&#34;&#34;&#34;
    self.update([(self.coord_from_attrs(xp), xp) for xp in xps])</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.squeeze"><code class="name flex">
<span>def <span class="ident">squeeze</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Eliminate unnecessary axes/dimensions.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L628-L632" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def squeeze(self):
    &#34;&#34;&#34;Eliminate unnecessary axes/dimensions.&#34;&#34;&#34;
    squeezed = xpSpace(xpList(self).prep_table()[0])
    squeezed.fill(self)
    return squeezed</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.get_stat"><code class="name flex">
<span>def <span class="ident">get_stat</span></span>(<span>self, statkey='rmse.a')</span>
</code></dt>
<dd>
<div class="desc"><p>Make <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code> with identical <code>keys</code>, but values <code>xp.avrgs.statkey</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L634-L649" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_stat(self, statkey=&#34;rmse.a&#34;):
    &#34;&#34;&#34;Make `xpSpace` with identical `keys`, but values `xp.avrgs.statkey`.&#34;&#34;&#34;
    # Init a new xpDict to hold stat
    avrgs = self.__class__(self.axes)

    found_anything = False
    for coord, xp in self.items():
        val = getattr(xp.avrgs, statkey, None)
        avrgs[coord] = val
        found_anything = found_anything or (val is not None)

    if not found_anything:
        raise AttributeError(
            f&#34;The stat.&#39;{statkey}&#39; was not found among any of the xp&#39;s.&#34;)

    return avrgs</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.mean"><code class="name flex">
<span>def <span class="ident">mean</span></span>(<span>self, axes=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L651-L678" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def mean(self, axes=None):
    # Note: The case `axes=()` should work w/o special treatment.
    if axes is None:
        return self

    nested = self.nest(axes)
    for coord, space in nested.items():

        def getval(uq): return uq.val if isinstance(uq, UncertainQtty) else uq
        vals = [getval(uq) for uq in space.values()]

        # Don&#39;t use nanmean! It would give false impressions.
        mu = np.mean(vals)

        with warnings.catch_warnings():
            warnings.simplefilter(&#34;ignore&#34;, category=RuntimeWarning)
            # Don&#39;t print warnings caused by N=1.
            # It already correctly yield nan&#39;s.
            var = np.var(vals, ddof=1)

        N = len(vals)
        uq = UncertainQtty(mu, np.sqrt(var/N))
        uq.nTotal   = N
        uq.nFail    = N - np.isfinite(vals).sum()
        uq.nSuccess = N - uq.nFail

        nested[coord] = uq
    return nested</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.tune"><code class="name flex">
<span>def <span class="ident">tune</span></span>(<span>self, axes=None, costfun=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Get (compile/tabulate) a stat. optimised wrt. tuning params.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L680-L709" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def tune(self, axes=None, costfun=None):
    &#34;&#34;&#34;Get (compile/tabulate) a stat. optimised wrt. tuning params.&#34;&#34;&#34;
    # Define cost-function
    costfun = (costfun or &#39;increasing&#39;).lower()
    if &#39;increas&#39; in costfun:
        costfun = (lambda x: +x)
    elif &#39;decreas&#39; in costfun:
        costfun = (lambda x: -x)
    else:
        assert callable(costfun)  # custom

    # Note: The case `axes=()` should work w/o special treatment.
    if axes is None:
        return self

    nested = self.nest(axes)
    for coord, space in nested.items():

        # Find optimal value and coord within space
        MIN = np.inf
        for inner_coord, uq in space.items():
            cost = costfun(uq.val)
            if cost &lt;= MIN:
                MIN                = cost
                uq_opt             = uq
                uq_opt.tuned_coord = inner_coord

        nested[coord] = uq_opt

    return nested</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.validate_axes"><code class="name flex">
<span>def <span class="ident">validate_axes</span></span>(<span>self, axes)</span>
</code></dt>
<dd>
<div class="desc"><p>Validate axes.</p>
<p>Note: This does not convert None to (),
allowing None to remain special.
Use <code>axis or ()</code> wherever tuples are required.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L711-L742" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def validate_axes(self, axes):
    &#34;&#34;&#34;Validate axes.

    Note: This does not convert None to (),
          allowing None to remain special.
          Use `axis or ()` wherever tuples are required.
    &#34;&#34;&#34;
    roles = {}  # &#34;inv&#34;
    for role in set(axes) | set(AXES_ROLES):
        assert role in AXES_ROLES, f&#34;Invalid role {role!r}&#34;
        aa = axes.get(role, AXES_ROLES[role])

        if aa is None:
            pass  # Purposely special
        else:
            # Ensure iterable
            if isinstance(aa, str) or not hasattr(aa, &#34;__iter__&#34;):
                aa = (aa,)

            aa = self.intersect_axes(aa)

            for axis in aa:

                # Ensure unique
                if axis in roles:
                    raise TypeError(
                        f&#34;An axis (here {axis!r}) cannot be assigned to 2&#34;
                        f&#34; roles (here {role!r} and {roles[axis]!r}).&#34;)
                else:
                    roles[axis] = role
        axes[role] = aa
    return axes</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.table_tree"><code class="name flex">
<span>def <span class="ident">table_tree</span></span>(<span>self, statkey, axes, *, costfun=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Hierarchical nest(): xp_dict&gt;outer&gt;inner&gt;mean&gt;optim.</p>
<p>as specified by <code>axes</code>. Returns this new xpSpace.</p>
<ul>
<li>
<p>print_1d / plot_1d (respectively) separate
tables / panel(row)s for <code>axes['outer']</code>, and
columns/ x-axis
for <code>axes['inner']</code>.</p>
</li>
<li>
<p>The <code>axes['mean']</code> and <code>axes['optim']</code> get eliminated
by the mean()/tune() operations.</p>
</li>
</ul>
<p>Note: cannot support multiple statkeys
because it's not (obviously) meaningful
when optimizing over tuning_axes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L744-L807" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def table_tree(self, statkey, axes, *, costfun=None):
    &#34;&#34;&#34;Hierarchical nest(): xp_dict&gt;outer&gt;inner&gt;mean&gt;optim.

    as specified by `axes`. Returns this new xpSpace.

    - print_1d / plot_1d (respectively) separate
      tables / panel(row)s for `axes[&#39;outer&#39;]`, and
      columns/ x-axis      for `axes[&#39;inner&#39;]`.

    - The `axes[&#39;mean&#39;]` and `axes[&#39;optim&#39;]` get eliminated
      by the mean()/tune() operations.

    Note: cannot support multiple statkeys
          because it&#39;s not (obviously) meaningful
          when optimizing over tuning_axes.
    &#34;&#34;&#34;
    axes = self.validate_axes(axes)

    def mean_tune(xp_dict):
        &#34;&#34;&#34;Take mean, then tune.

        Note: the SparseDict implementation should be sufficiently
        &#34;uncluttered&#34; that mean_tune() (or a few of its code lines)
        could be called anywhere above/between/below
        the `nest()`ing of `outer` or `inner`.
        These possibile call locations are commented in the code.
        &#34;&#34;&#34;
        uq_dict = xp_dict.get_stat(statkey)
        uq_dict = uq_dict.mean(axes[&#39;mean&#39;])
        uq_dict = uq_dict.tune(axes[&#39;optim&#39;], costfun)
        return uq_dict

    self = mean_tune(self)
    # Prefer calling mean_tune() [also see its docstring]
    # before doing outer/inner nesting. This is because then the axes of
    # a row (xpSpace) should not include mean&amp;optim, and thus:
    #  - Column header/coords may be had directly as row.keys(),
    #    without extraction by coord_from_attrs() from (e.g.) row[0].
    #  - Don&#39;t need to propagate mean&amp;optim axes down to the row level.
    #    which would require defining rows by the nesting:
    #    rows = table.nest(outer_axes=struct_tools.complement(table.axes,
    #        *(axes[&#39;inner&#39;] or ()),
    #        *(axes[&#39;mean&#39;]  or ()),
    #        *(axes[&#39;optim&#39;] or ()) ))
    #  - Each level of the output from table_tree
    #    is a smaller (and more manageable) dict.

    tables = self.nest(outer_axes=axes[&#39;outer&#39;])
    for table_coord, table in tables.items():
        # table = mean_tune(table)

        # Should not be used (nesting as rows is more natural,
        # and is required for getting distinct/row_keys).
        # cols = table.nest(outer_axes=axes[&#39;inner&#39;])

        rows = table.nest(inner_axes=axes[&#39;inner&#39;] or ())

        # Overwrite table by its nesting as rows
        tables[table_coord] = rows

        # for row_coord, row in rows.items():
        # rows[row_coord] = mean_tune(row)

    return axes, tables</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.tickz"><code class="name flex">
<span>def <span class="ident">tickz</span></span>(<span>self, axis_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Axis ticks without None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L809-L811" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def tickz(self, axis_name):
    &#34;&#34;&#34;Axis ticks without None&#34;&#34;&#34;
    return [x for x in self.ticks[axis_name] if x is not None]</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.print"><code class="name flex">
<span>def <span class="ident">print</span></span>(<span>self, statkey='rmse.a', axes={'outer': None, 'inner': None, 'mean': None, 'optim': None}, subcols=True, decimals=None, costfun=None, squeeze_labels=True, colorize=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Print tables of results.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>statkey</code></strong> :&ensp;<code>str</code></dt>
<dd>The statistic to extract from the <code>xp.avrgs</code> for each <code>xp</code>.</dd>
<dt><strong><code>axes</code></strong> :&ensp;<code>dict</code></dt>
<dd>
<p>Allots (maps) the axes/dimensions of <code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code> to different
roles in the printing of the table.</p>
<ul>
<li>Herein, the "role" <code>outer</code> should list the axes/attributes
used to define the splitting of the results into <em>separate tables</em>:
one table for each distinct combination of attributes.</li>
<li>Similarly , the role <code>inner</code> determines which attributes
split a table into its columns.</li>
<li><code>mean</code> lists the attributes over which the mean is taken
(for that row &amp; column)</li>
<li><code>optim</code> lists the attributes used over which the optimum
is searched for (after taking the mean).</li>
</ul>
<p>Example:</p>
<pre><code>dict(outer='da_method', inner='N', mean='seed',
     optim=('infl','loc_rad'))
</code></pre>
<p>Equivalently, use <code>mean=("seed",)</code>.
It is acceptible to not specify anything, e.g. <code>mean=()</code> or <code>mean=None</code>.</p>
</dd>
<dt><strong><code>subcols</code></strong> :&ensp;<code>bool</code></dt>
<dd>
<p>If <code>True</code>, then subcolumns are added to indicate</p>
<ul>
<li><code>1σ</code>: the confidence interval. If <code>mean=None</code> is used, this simply reports
the value <code>.prec</code> of the <code>statkey</code>, providing this is an <code>UncertainQtty</code>.
Otherwise, it is computed as <code>sqrt(var(xps)/N)</code>,
where <code>xps</code> is the set of statistic gathered over the <code>mean</code> axis.</li>
<li><code>*(optim)</code>: the optimal point (among all <code>optim</code> attributes),
as defined by <code>costfun</code>.</li>
<li><code>☠</code>: the number of failures (non-finite values) at that point.</li>
<li><code>✓</code>: the number of successes that go into the value</li>
</ul>
</dd>
<dt><strong><code>decimals</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of decimals to print.
If <code>None</code>, this is determined for each statistic by its uncertainty.</dd>
<dt><strong><code>costfun</code></strong> :&ensp;<code>str</code> or <code>function</code></dt>
<dd>Use <code>'increasing'</code> (default) or <code>'decreasing'</code> to indicate that the optimum
is defined as the lowest or highest value of the <code>statkey</code> found.</dd>
<dt><strong><code>squeeze_labels</code></strong> :&ensp;<code>bool</code></dt>
<dd>Don't include redundant attributes in the line labels.
Caution: <code>get_style</code> will not be able to access the eliminated attrs.</dd>
<dt><strong><code>colorize</code></strong> :&ensp;<code>bool</code></dt>
<dd>Add color to tables for readability.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L813-L963" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def print(self, statkey=&#34;rmse.a&#34;, axes=AXES_ROLES,  # noqa
          subcols=True, decimals=None, costfun=None,
          squeeze_labels=True, colorize=True):
    &#34;&#34;&#34;Print tables of results.

    Parameters
    ----------
    statkey: str
        The statistic to extract from the `xp.avrgs` for each `xp`.
    axes: dict
        Allots (maps) the axes/dimensions of `xpSpace` to different
        roles in the printing of the table.

        - Herein, the &#34;role&#34; `outer` should list the axes/attributes
          used to define the splitting of the results into *separate tables*:
          one table for each distinct combination of attributes.
        - Similarly , the role `inner` determines which attributes
          split a table into its columns.
        - `mean` lists the attributes over which the mean is taken
          (for that row &amp; column)
        - `optim` lists the attributes used over which the optimum
           is searched for (after taking the mean).

        Example:

            dict(outer=&#39;da_method&#39;, inner=&#39;N&#39;, mean=&#39;seed&#39;,
                 optim=(&#39;infl&#39;,&#39;loc_rad&#39;))

        Equivalently, use `mean=(&#34;seed&#34;,)`.
        It is acceptible to not specify anything, e.g. `mean=()` or `mean=None`.
    subcols: bool
        If `True`, then subcolumns are added to indicate

        - `1σ`: the confidence interval. If `mean=None` is used, this simply reports
          the value `.prec` of the `statkey`, providing this is an `UncertainQtty`.
          Otherwise, it is computed as `sqrt(var(xps)/N)`,
          where `xps` is the set of statistic gathered over the `mean` axis.
        - `*(optim)`: the optimal point (among all `optim` attributes),
          as defined by `costfun`.
        - `☠`: the number of failures (non-finite values) at that point.
        - `✓`: the number of successes that go into the value
    decimals: int
        Number of decimals to print.
        If `None`, this is determined for each statistic by its uncertainty.
    costfun: str or function
        Use `&#39;increasing&#39;` (default) or `&#39;decreasing&#39;` to indicate that the optimum
        is defined as the lowest or highest value of the `statkey` found.
    squeeze_labels: bool
        Don&#39;t include redundant attributes in the line labels.
        Caution: `get_style` will not be able to access the eliminated attrs.
    colorize: bool
        Add color to tables for readability.
    &#34;&#34;&#34;
    # Inform axes[&#34;mean&#34;]
    if axes.get(&#39;mean&#39;, None):
        print(f&#34;Averages (in time and) over {axes[&#39;mean&#39;]}.&#34;)
    else:
        print(&#34;Averages in time only&#34;
              &#34; (=&gt; the 1σ estimates may be unreliable).&#34;)

    axes, tables = self.table_tree(statkey, axes, costfun=costfun)

    def make_cols(rows, cc, subcols, h2):
        &#34;&#34;&#34;Subcolumns: align, justify, join.&#34;&#34;&#34;
        # Define subcol formats
        if subcols:
            templ = &#34;{val} ±{prec}&#34;
            templ += &#34;&#34; if axes[&#39;optim&#39;] is None else &#34; *{tuned_coord}&#34;
            templ += &#34;&#34; if  axes[&#39;mean&#39;] is None else &#34; {nFail} {nSuccess}&#34;  # noqa
            aligns = dict(prec=&#34;&lt;&#34;, tuned_coord=&#34;&lt;&#34;)
            labels = dict(val=statkey, prec=&#34;1σ&#34;,
                          tuned_coord=axes[&#34;optim&#34;],
                          nFail=&#34;☠&#34;, nSuccess=&#34;✓&#34;)

        def align(column):
            col = unpack_uqs(column, decimals)
            if subcols:
                for key in list(col):
                    if key in templ:
                        subcolmn = [labels.get(key, key)] + col[key]
                        col[key] = align_col(subcolmn, just=aligns.get(key, &#34;&gt;&#34;))
                    else:
                        del col[key]
                col = [templ.format(**row) for row in struct_tools.transps(col)]
            else:
                col = align_col([statkey] + col[&#34;val&#34;])
            return col

        def super_header(col_coord, idx, col):
            header, matter = col[0], col[1:]
            if idx:
                cc = str(col_coord).strip(&#34;()&#34;)
            else:
                cc = col_coord.repr2()
            cc = cc.replace(&#34;, &#34;, &#34;,&#34;)
            cc = cc.center(len(header), &#34;_&#34;)  # +1 width for wide chars like ✔️
            return [cc + &#34;\n&#34; + header] + matter

        # Transpose
        columns = [list(x) for x in zip(*rows)]

        # Format column
        for j, (col_coord, column) in enumerate(zip(cc, columns)):
            col = align(column)
            if h2:
                col = super_header(col_coord, j, col)
            columns[j] = col

        # Un-transpose
        rows = [list(x) for x in zip(*columns)]

        return rows

    for table_coord, table in tables.items():

        # Get table&#39;s column coords/ticks (cc).
        # cc is really a set, but we use dict for ordering.
        # cc = self.ticks[axes[&#34;inner&#34;]]  # may be &gt; needed
        # cc = table[0].keys()            # may be &lt; needed
        cc = {c: None for row in table.values() for c in row}
        # Could also do cc = table.squeeze() but is it worth it?

        # Convert table (rows) into rows (lists) of equal length
        rows = [[row.get(c, None) for c in cc] for row in table.values()]

        h2 = &#34;\n&#34; if len(cc) &gt; 1 else &#34;&#34;  # super-header?
        rows = make_cols(rows, cc, subcols, h2)

        if squeeze_labels:
            table = table.squeeze()

        # Prepend left-side (attr) table
        # Header
        rows[0] = [h2+k for k in table.axes] + [h2+&#39;⑊&#39;] + rows[0]
        # Matter
        for i, (key, row) in enumerate(zip(table, rows[1:])):
            rows[i+1] = [*key] + [&#39;|&#39;] + row

        # Print
        print(&#34;\n&#34;, end=&#34;&#34;)
        if axes[&#39;outer&#39;]:
            table_title = &#34;Table for &#34; + table_coord.repr2()
            if colorize:
                clrs = colorama.Back.YELLOW, colorama.Fore.BLACK
                table_title = color_text(table_title, *clrs)
            print(table_title)
        headers, *rows = rows
        t = tabulate(rows, headers).replace(&#39;␣&#39;, &#39; &#39;)
        if colorize:
            t = stripe(t, slice(2, None))
        print(t)</code></pre>
</details>
</dd>
<dt id="dapper.xp_process.xpSpace.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, statkey='rmse.a', axes={'outer': None, 'inner': None, 'mean': None, 'optim': None}, get_style=&lt;function default_styles&gt;, fignum=None, figsize=None, panels=None, title2=None, costfun=None, unique_labels=True, squeeze_labels=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot (tables of) results.</p>
<p>Analagously to <code><a title="dapper.xp_process.xpSpace.print" href="#dapper.xp_process.xpSpace.print">xpSpace.print()</a></code>,
the averages are grouped by <code>axis["inner"]</code>,
which here plays the role of the x-axis.</p>
<p>The averages can also be grouped by <code>axis["outer"]</code>,
producing a figure with multiple (columns of) panels.</p>
<p>The optimal points/parameters/attributes are plotted in smaller panels
below the main plot. This can be turned off by providing the figure
axes through the <code>panels</code> argument.</p>
<p>The parameters <code>statkey</code>, <code>axes</code>, <code>costfun</code>, <code>sqeeze_labels</code>
are documented in <code><a title="dapper.xp_process.xpSpace.print" href="#dapper.xp_process.xpSpace.print">xpSpace.print()</a></code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>get_style</code></strong> :&ensp;<code>function</code></dt>
<dd>A function that takes an object, and returns a dict of line styles,
usually as a function of the object's attributes.</dd>
<dt><strong><code>title2</code></strong> :&ensp;<code>str</code></dt>
<dd>Figure title (in addition to the defaults).</dd>
<dt><strong><code>unique_labels</code></strong> :&ensp;<code>bool</code></dt>
<dd>Only show a given label once.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/nansencenter/DAPPER/blob/master/dapper/xp_process.py#L965-L1107" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def plot(self, statkey=&#34;rmse.a&#34;, axes=AXES_ROLES, get_style=default_styles,
         fignum=None, figsize=None, panels=None,
         title2=None, costfun=None, unique_labels=True,
         squeeze_labels=True):
    &#34;&#34;&#34;Plot (tables of) results.

    Analagously to `xpSpace.print`,
    the averages are grouped by `axis[&#34;inner&#34;]`,
    which here plays the role of the x-axis.

    The averages can also be grouped by `axis[&#34;outer&#34;]`,
    producing a figure with multiple (columns of) panels.

    The optimal points/parameters/attributes are plotted in smaller panels
    below the main plot. This can be turned off by providing the figure
    axes through the `panels` argument.

    The parameters `statkey`, `axes`, `costfun`, `sqeeze_labels`
    are documented in `xpSpace.print`.

    Parameters
    ----------
    get_style: function
        A function that takes an object, and returns a dict of line styles,
        usually as a function of the object&#39;s attributes.
    title2: str
        Figure title (in addition to the defaults).
    unique_labels: bool
        Only show a given label once.
    &#34;&#34;&#34;
    def plot1(panelcol, row, style):
        &#34;&#34;&#34;Plot a given line (row) in the main panel and the optim panels.

        Involves: Sort, insert None&#39;s, handle constant lines.
        &#34;&#34;&#34;
        # Make a full row (yy) of vals, whether is_constant or not.
        # row.is_constant = (len(row)==1 and next(iter(row))==row.Coord(None))
        row.is_constant = all(x == row.Coord(None) for x in row)
        yy = [row[0] if row.is_constant else y for y in row.get_for(xticks)]

        # Plot main
        row.vals = [getattr(y, &#39;val&#39;, None) for y in yy]
        row.handles = {}
        row.handles[&#34;main_panel&#34;] = panelcol[0].plot(xticks, row.vals, **style)[0]

        # Plot tuning params
        row.tuned_coords = {}  # Store ordered, &#34;transposed&#34; argmins
        argmins = [getattr(y, &#39;tuned_coord&#39;, None) for y in yy]
        for a, panel in zip(axes[&#34;optim&#34;], panelcol[1:]):
            yy = [getattr(coord, a, None) for coord in argmins]
            row.tuned_coords[a] = yy

            # Plotting all None&#39;s sets axes units (like any plotting call)
            # which can cause trouble if the axes units were actually supposed
            # to be categorical (eg upd_a), but this is only revealed later.
            if not all(y == None for y in yy):
                row.handles[a] = panel.plot(xticks, yy, **style)

    # Nest axes through table_tree()
    assert len(axes[&#34;inner&#34;]) == 1, &#34;You must chose the abscissa.&#34;
    axes, tables = self.table_tree(statkey, axes, costfun=costfun)
    xticks = self.tickz(axes[&#34;inner&#34;][0])

    # Create figure panels
    if panels is None:
        nrows   = len(axes[&#39;optim&#39;] or ()) + 1
        ncols   = len(tables)
        maxW    = 12.7  # my mac screen
        figsize = figsize or (min(5*ncols, maxW), 7)
        gs      = dict(
            height_ratios=[6]+[1]*(nrows-1),
            hspace=0.05, wspace=0.05,
            # eyeballed:
            left=0.15/(1+np.log(ncols)),
            right=0.97, bottom=0.06, top=0.9)
        # Create
        _, panels = place.freshfig(num=fignum, figsize=figsize,
                                   nrows=nrows, sharex=True,
                                   ncols=ncols, sharey=&#39;row&#39;,
                                   gridspec_kw=gs, squeeze=False)
    else:
        panels = np.atleast_2d(panels)

    # Fig. Title
    fig = panels[0, 0].figure
    fig_title = &#34;Averages wrt. time&#34;
    if axes[&#34;mean&#34;] is not None:
        fig_title += &#34; and &#34; + &#34;, &#34;.join([repr(c) for c in axes[&#39;mean&#39;]])
    if title2 is not None:
        with nonchalance():
            title2 = title2.relative_to(rc.dirs[&#34;data&#34;])
        fig_title += &#34;\n&#34; + str(title2)
    fig.suptitle(fig_title)

    # Loop outer
    label_register = set()  # mv inside loop to get legend on each panel
    for table_panels, (table_coord, table) in zip(panels.T, tables.items()):
        table.panels = table_panels
        title = &#34;&#34; if axes[&#34;outer&#34;] is None else table_coord.repr2()

        if squeeze_labels:
            distinct = xpList(table.keys()).prep_table()[0]
        else:
            distinct = table.axes

        # Plot
        for coord, row in table.items():

            coord = NoneDict(struct_tools.intersect(coord._asdict(), distinct))
            style = get_style(coord)

            # Rm duplicate labels
            if unique_labels:
                if style.get(&#34;label&#34;, None) in label_register:
                    del style[&#34;label&#34;]
                else:
                    label_register.add(style[&#34;label&#34;])

            plot1(table.panels, row, style)

        # Beautify
        panel0 = table.panels[0]
        # panel0.set_title(title)
        panel0.text(.5, 1, title, fontsize=12, ha=&#34;center&#34;, va=&#34;bottom&#34;,
                    transform=panel0.transAxes, bbox=dict(
                        facecolor=&#39;lightyellow&#39;, edgecolor=&#39;k&#39;,
                        alpha=0.99, boxstyle=&#34;round,pad=0.25&#34;,
                        # NB: padding makes label spill into axes
                    ))
        if panel0.is_first_col():
            panel0.set_ylabel(statkey)
        with set_tmp(mpl_logger, &#39;level&#39;, 99):  # silence &#34;no label&#34; msg
            panel0.legend()
        table.panels[-1].set_xlabel(axes[&#34;inner&#34;][0])
        # Tuning panels:
        for a, panel in zip(axes[&#34;optim&#34;] or (), table.panels[1:]):
            if panel.is_first_col():
                panel.set_ylabel(f&#34;Optim.\n{a}&#34;)

    tables.fig = fig
    tables.xp_dict = self
    tables.axes_roles = axes
    return tables</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="dapper.xp_process.SparseSpace" href="#dapper.xp_process.SparseSpace">SparseSpace</a></b></code>:
<ul class="hlist">
<li><code><a title="dapper.xp_process.SparseSpace.coord_from_attrs" href="#dapper.xp_process.SparseSpace.coord_from_attrs">coord_from_attrs</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.coords_matching" href="#dapper.xp_process.SparseSpace.coords_matching">coords_matching</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.get_for" href="#dapper.xp_process.SparseSpace.get_for">get_for</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.intersect_axes" href="#dapper.xp_process.SparseSpace.intersect_axes">intersect_axes</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.label_xSection" href="#dapper.xp_process.SparseSpace.label_xSection">label_xSection</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.nest" href="#dapper.xp_process.SparseSpace.nest">nest</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.update" href="#dapper.xp_process.SparseSpace.update">update</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="DAPPER" href="https://nansencenter.github.io/DAPPER">
<img src="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo_wtxt.png" alt="">
<!-- can add style="width:200px;" to img -->
</a>
</header>
<div class="gcse-search" style="height: 70px"
data-as_oq="inurl:github.com/nansencenter/DAPPER site:nansencenter.github.io/DAPPER"
data-gaCategoryParameter="dapper.xp_process">
</div>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dapper" href="index.html">dapper</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dapper.xp_process.make_label" href="#dapper.xp_process.make_label">make_label</a></code></li>
<li><code><a title="dapper.xp_process.default_styles" href="#dapper.xp_process.default_styles">default_styles</a></code></li>
<li><code><a title="dapper.xp_process.rel_index" href="#dapper.xp_process.rel_index">rel_index</a></code></li>
<li><code><a title="dapper.xp_process.discretize_cmap" href="#dapper.xp_process.discretize_cmap">discretize_cmap</a></code></li>
<li><code><a title="dapper.xp_process.cm_bond" href="#dapper.xp_process.cm_bond">cm_bond</a></code></li>
<li><code><a title="dapper.xp_process.in_idx" href="#dapper.xp_process.in_idx">in_idx</a></code></li>
<li><code><a title="dapper.xp_process.find_latest_run" href="#dapper.xp_process.find_latest_run">find_latest_run</a></code></li>
<li><code><a title="dapper.xp_process.load_HMM" href="#dapper.xp_process.load_HMM">load_HMM</a></code></li>
<li><code><a title="dapper.xp_process.load_xps" href="#dapper.xp_process.load_xps">load_xps</a></code></li>
<li><code><a title="dapper.xp_process.save_xps" href="#dapper.xp_process.save_xps">save_xps</a></code></li>
<li><code><a title="dapper.xp_process.overwrite_xps" href="#dapper.xp_process.overwrite_xps">overwrite_xps</a></code></li>
<li><code><a title="dapper.xp_process.reduce_inodes" href="#dapper.xp_process.reduce_inodes">reduce_inodes</a></code></li>
<li><code><a title="dapper.xp_process.default_fig_adjustments" href="#dapper.xp_process.default_fig_adjustments">default_fig_adjustments</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dapper.xp_process.NoneDict" href="#dapper.xp_process.NoneDict">NoneDict</a></code></h4>
</li>
<li>
<h4><code><a title="dapper.xp_process.SparseSpace" href="#dapper.xp_process.SparseSpace">SparseSpace</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.xp_process.SparseSpace.update" href="#dapper.xp_process.SparseSpace.update">update</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.get_for" href="#dapper.xp_process.SparseSpace.get_for">get_for</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.coord_from_attrs" href="#dapper.xp_process.SparseSpace.coord_from_attrs">coord_from_attrs</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.coords_matching" href="#dapper.xp_process.SparseSpace.coords_matching">coords_matching</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.nest" href="#dapper.xp_process.SparseSpace.nest">nest</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.intersect_axes" href="#dapper.xp_process.SparseSpace.intersect_axes">intersect_axes</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.append_axis" href="#dapper.xp_process.SparseSpace.append_axis">append_axis</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.label_xSection" href="#dapper.xp_process.SparseSpace.label_xSection">label_xSection</a></code></li>
<li><code><a title="dapper.xp_process.SparseSpace.axes" href="#dapper.xp_process.SparseSpace.axes">axes</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dapper.xp_process.xpSpace" href="#dapper.xp_process.xpSpace">xpSpace</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.xp_process.xpSpace.from_list" href="#dapper.xp_process.xpSpace.from_list">from_list</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.fill" href="#dapper.xp_process.xpSpace.fill">fill</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.squeeze" href="#dapper.xp_process.xpSpace.squeeze">squeeze</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.get_stat" href="#dapper.xp_process.xpSpace.get_stat">get_stat</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.mean" href="#dapper.xp_process.xpSpace.mean">mean</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.tune" href="#dapper.xp_process.xpSpace.tune">tune</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.validate_axes" href="#dapper.xp_process.xpSpace.validate_axes">validate_axes</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.table_tree" href="#dapper.xp_process.xpSpace.table_tree">table_tree</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.tickz" href="#dapper.xp_process.xpSpace.tickz">tickz</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.print" href="#dapper.xp_process.xpSpace.print">print</a></code></li>
<li><code><a title="dapper.xp_process.xpSpace.plot" href="#dapper.xp_process.xpSpace.plot">plot</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>